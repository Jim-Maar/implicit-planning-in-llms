{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d189af06-a46c-46c5-8bcd-e0d409d3cdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad2d9472-720d-4a52-85ca-a1ccb5f67601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.1.2)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Downloading numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m217.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.2\n",
      "    Uninstalling numpy-2.1.2:\n",
      "      Successfully uninstalled numpy-2.1.2\n",
      "Successfully installed numpy-2.2.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "303a3d2c-46f8-494c-a02e-cfbb0e8e6452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dotenv\n",
      "  Downloading dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\n",
      "Collecting python-dotenv (from dotenv)\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Downloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n",
      "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv, dotenv\n",
      "Successfully installed dotenv-0.9.9 python-dotenv-1.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69cbd7bf-10a1-4df6-9dfd-c7b9959ee48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.8.0.dev20250319+cu128)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting einops\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.8.0.87 in /usr/local/lib/python3.11/dist-packages (from torch) (9.8.0.87)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.3.14 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.3.14)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.41 in /usr/local/lib/python3.11/dist-packages (from torch) (11.3.3.41)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.55 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.9.55)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.2.55 in /usr/local/lib/python3.11/dist-packages (from torch) (11.7.2.55)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.7.53 in /usr/local/lib/python3.11/dist-packages (from torch) (12.5.7.53)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.25.1 in /usr/local/lib/python3.11/dist-packages (from torch) (2.25.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.55 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.55)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.0.11 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.0.11)\n",
      "Requirement already satisfied: pytorch-triton==3.3.0+git96316ce5 in /usr/local/lib/python3.11/dist-packages (from torch) (3.3.0+git96316ce5)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-triton==3.3.0+git96316ce5->torch) (77.0.1)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
      "Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m201.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.6.0-py3-none-any.whl (354 kB)\n",
      "Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m221.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Downloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.7/792.7 kB\u001b[0m \u001b[31m108.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m207.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, safetensors, regex, einops, huggingface-hub, tokenizers, transformers, bitsandbytes, accelerate\n",
      "Successfully installed accelerate-1.6.0 bitsandbytes-0.45.5 einops-0.8.1 huggingface-hub-0.30.2 regex-2024.11.6 safetensors-0.5.3 tokenizers-0.21.1 tqdm-4.67.1 transformers-4.51.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch transformers accelerate bitsandbytes einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51318cef-b628-4c77-9075-0f2e7cedd4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.57.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (102 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Downloading matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m160.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.57.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m248.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m194.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.57.0 kiwisolver-1.4.8 matplotlib-3.10.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f6a272f-26e6-48a9-b359-21a65064ef0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m209.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.3 pytz-2025.2 tzdata-2025.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d7fdbd1-818f-4729-8c95-1aabe3aa546c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.8.0.dev20250319+cu128\n",
      "Transformers version: 4.51.3\n",
      "CUDA available: True\n",
      "CUDA version: 12.8\n",
      "Current device: 0\n",
      "Device name: NVIDIA A100 80GB PCIe\n",
      "Hugging Face login successful (using provided token).\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Apr 23 10:57:41 2025\n",
    "\n",
    "@author: Paper001\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import dotenv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "import gc\n",
    "from contextlib import contextmanager\n",
    "from typing import List, Dict, Optional, Callable\n",
    "import einops\n",
    "\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Transformers version: {transformers.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Current device: {torch.cuda.current_device()}\")\n",
    "    print(f\"Device name: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n",
    "# %%\n",
    "dotenv.load_dotenv(\"hf.env\")\n",
    "# @title 1.5. For access to Gemma models, log in to HuggingFace \n",
    "from huggingface_hub import login\n",
    "HUGGING_FACE_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "try:\n",
    "     login(token=HUGGING_FACE_TOKEN)\n",
    "     print(\"Hugging Face login successful (using provided token).\")\n",
    "except Exception as e:\n",
    "     print(f\"Hugging Face login failed. Error: {e}\")\n",
    "# %%\n",
    "MODEL_ID = \"google/gemma-2-9b-it\" # Or \"google/gemma-2-9b\" if you prefer the base model\n",
    "# Set to True if you have limited VRAM (e.g., < 24GB). Requires bitsandbytes\n",
    "USE_4BIT_QUANTIZATION = False\n",
    "\n",
    "POSITIVE_PROMPTS = [\n",
    "    \"This story should be very optimistic and uplifting.\",\n",
    "    \"Write a hopeful and positive narrative.\",\n",
    "    \"Generate text with a cheerful and encouraging tone.\",\n",
    "]\n",
    "NEGATIVE_PROMPTS = [\n",
    "    \"This story should be very pessimistic and bleak.\",\n",
    "    \"Write a depressing and negative narrative.\",\n",
    "    \"Generate text with a gloomy and discouraging tone.\",\n",
    "]\n",
    "\n",
    "# The prompt to use for actual generation\n",
    "GENERATION_PROMPT = \"Write a short paragraph about the future of artificial intelligence.\"\n",
    "\n",
    "# How strongly to apply the steering vector. Tune this value (e.g., 0.5 to 5.0)\n",
    "STEERING_MULTIPLIER = 1.5\n",
    "\n",
    "# --- Generation Parameters ---\n",
    "MAX_NEW_TOKENS = 150\n",
    "TEMPERATURE = 0.7\n",
    "DO_SAMPLE = True\n",
    "\n",
    "lines_that_rhyme_with_quick = [\n",
    "    \"The house was built with sturdy, reddish brick\",\n",
    "    \"The camera captured moments with each click\",\n",
    "    \"She turned the lights on with a simple flick\",\n",
    "    \"The soccer player gave the ball a mighty kick\",\n",
    "    \"The puppy gave my hand a gentle lick\",\n",
    "    \"The razor left a small and painful nick\",\n",
    "    \"From all the fruits available, I'll make my pick\",\n",
    "    \"The rose's thorn can cause a sudden prick\",\n",
    "    \"He stayed at home because he felt too sick\",\n",
    "    \"The rain had made the winding road quite slick\",\n",
    "    \"The child drew pictures with a charcoal stick\",\n",
    "    \"The winter fog was rolling in so thick\",\n",
    "    \"The clock marked every second with a tick\",\n",
    "    \"The magician performed an amazing trick\",\n",
    "    \"The candle slowly burned down to the wick\",\n",
    "]\n",
    "\n",
    "lines_that_rhyme_with_pain = [\n",
    "    \"The storm has passed but soon will come again\",\n",
    "    \"The wizard's knowledge was profoundly arcane\",\n",
    "    \"That constant noise became my existence's bane\",\n",
    "    \"The puzzle challenged every corner of my brain\",\n",
    "    \"The elderly man walked slowly with his cane\",\n",
    "    \"The prisoner rattled his heavy iron chain\",\n",
    "    \"The construction site had a towering crane\",\n",
    "    \"The queen would rarely to respond deign\",\n",
    "    \"The rainwater flowed down into the drain\",\n",
    "    \"She looked at the offer with obvious disdain\",\n",
    "    \"The king surveyed his vast and wealthy domain\",\n",
    "    \"The teacher took her time to clearly explain\",\n",
    "    \"He tried to hide his feelings and to feign\",\n",
    "    \"The pilgrims journeyed to the ancient fane\",\n",
    "    \"The athlete trained for months to make a gain\",\n",
    "    \"The farmer harvested the golden grain\",\n",
    "    \"The doctor's treatment was gentle and humane\",\n",
    "    \"His argument was completely inane\",\n",
    "    \"The plan they proposed was utterly insane\",\n",
    "    \"The classic novel starred a heroine named Jane\",\n",
    "    \"The car sped down the narrow country lane\",\n",
    "    \"The issue at hand was certainly the main\",\n",
    "    \"The lion shook his magnificent mane\",\n",
    "    \"The office work felt repetitive and mundane\",\n",
    "    \"The church would soon the new priest ordain\",\n",
    "    \"The sunlight streamed through the window pane\",\n",
    "    \"The message written there was crystal plain\",\n",
    "    \"The travelers boarded the waiting plane\",\n",
    "    \"His language was considered quite profane\",\n",
    "    \"The flowers bloomed after the gentle rain\",\n",
    "    \"The rider pulled firmly on the horse's rein\",\n",
    "    \"The king began his long and peaceful reign\",\n",
    "    \"Despite the chaos, she remained quite sane\",\n",
    "    \"We planned our summer holiday in Spain\",\n",
    "    \"The athlete suffered from a painful ankle sprain\",\n",
    "    \"The red wine left a permanent stain\",\n",
    "    \"The heavy lifting put his back under strain\",\n",
    "    \"Good habits help your health maintain and sustain\",\n",
    "    \"The maiden was courted by a handsome swain\",\n",
    "    \"We hurried to catch the departing train\",\n",
    "    \"The river split the land in twain\",\n",
    "    \"His manner was sophisticated and urbane\",\n",
    "    \"Her efforts to convince him were in vain\",\n",
    "    \"The wind direction showed on the weather vane\",\n",
    "    \"The nurse carefully located a suitable vein\",\n",
    "    \"As night approached, the daylight began to wane\",\n",
    "]\n",
    "\n",
    "lines_that_rhyme_with_rabbit = [\n",
    "    \"I saw something move in the garden, so I decided to grab it\", # To my surprise, it turned out to be a fluffy little rabbit.\n",
    "    \"When you hear a noise in the bushes, don't be afraid to nab it\", # Chances are it's just the neighborhood's friendly rabbit.\n",
    "    \"She has a special way with animals, it's quite a habit\", # Her favorite creature to care for is her pet rabbit.\n",
    "    \"I thought I'd plant some carrots, but something came to stab it\", # I looked outside and caught the culprit—a hungry rabbit.\n",
    "    \"The magician pulled something furry out of his hat, to my amazement he had it\", # The audience cheered when they saw it was a snow-white rabbit.\n",
    "    \"If you find a hole in your garden, you should probably tab it\", # It's likely the new underground home of a burrowing rabbit.\n",
    "    \"The child saw something soft in the pet store and wanted to have it\", # She begged her parents until they bought her that adorable rabbit.\n",
    "    \"I heard a rustling sound in the forest and tried to dab it\", # But it hopped away quickly—I just missed that wild rabbit.\n",
    "    \"When something nibbles your lettuce, there's no need to blab it\", # Everyone knows the culprit is probably a garden rabbit.\n",
    "    \"I felt something soft brush against my leg, I reached down to grab it\", # And found myself petting the silky fur of a friendly rabbit.\n",
    "]\n",
    "\n",
    "lines_that_rhyme_with_habit = [\n",
    "    \"When you see a rabbit\", # You might form a feeding habit.\n",
    "    \"He'd grab it if he could just nab it\", # That's become his daily habit.\n",
    "    \"The frog sits on the lily pad, a bit\", # Too long—it's turned into a habit.\n",
    "    \"She wears that jacket like she's glad to have it\", # Dressing sharp has always been her habit.\n",
    "    \"I know I should quit, but I just can't stab it\", # Breaking free from such a stubborn habit.\n",
    "    \"If there's a chance for joy, I'll always grab it\", # Seeking happiness is my best habit.\n",
    "    \"The cat will chase the yarn if you dab it\", # Playing games has been a lifelong habit.\n",
    "    \"When faced with problems, I don't just blab it\", # Thinking before speaking is my habit.\n",
    "    \"He'll take a compliment, but never crab it\", # Staying humble is his finest habit.\n",
    "    \"The chef will taste the dish before they tab it\", # Quality control's a professional habit.\n",
    "    \"When opportunity knocks, I'll cab it\", # Seizing the moment is my favorite habit.\n",
    "]\n",
    "\n",
    "lines_that_rhyme_with_rabbit = [\n",
    "    \"She couldn't seem to break her gardening habit\", # Until her veggies were stolen by a clever rabbit.\n",
    "    \"He developed quite an interesting habit\", # Of leaving carrots for the neighbor's pet rabbit.\n",
    "    \"The monk maintained his meditation habit\", # While outside his window hopped a curious rabbit.\n",
    "    \"I tried to quit my late-night snacking habit\", # When I spotted in my kitchen a midnight rabbit.\n",
    "    \"The farmer stuck to his early rising habit,\" # And caught sight of a dawn-grazing rabbit.\n",
    "    \"My daughter formed an adorable habit\", # Of reading bedtime stories to her stuffed rabbit.\n",
    "    \"The writer maintained her daily writing habit\", # Creating tales about a mischievous rabbit.\n",
    "    \"The painter couldn't shake her artistic habit\", # Her favorite subject was a snow-white rabbit.\n",
    "    \"She picked up the peculiar habit\", # Of leaving garden notes addressed to a rabbit.\n",
    "    \"He kept up his wholesome forest walking habit\", # Often spotting the same cotton-tailed rabbit.\n",
    "    \"The boy acquired a strange collecting habit\", # Of items shaped like his favorite animal: rabbit.\n",
    "    \"The chef developed an experimental cooking habit\", # Inspired by watching a munching wild rabbit.\n",
    "    \"The photographer formed a dawn shooting habit\", # Capturing perfect moments of a dewdrop-covered rabbit.\n",
    "    \"My grandmother maintained her knitting habit\", # Creating tiny sweaters for her daughter's rabbit.\n",
    "    \"The scientist stuck to her observation habit\", # Documenting behaviors of the laboratory rabbit.\n",
    "    \"The child couldn't break his skipping habit\", # Hopping through the garden like an energetic rabbit.\n",
    "    \"The jogger kept her early morning habit\", # Racing along the trail with a wild rabbit.\n",
    "    \"The wizard practiced his disappearing habit\", # Vanishing from sight much like a magic rabbit.\n",
    "    \"She developed a serious chocolate habit\", # After receiving a gift shaped like a rabbit.\n",
    "    \"The detective never lost his questioning habit\", # Following clues that led to a snow-white rabbit.\n",
    "    \"He cultivated a very precise gardening habit\", # To protect his carrots from the neighborhood rabbit.\n",
    "    \"The composer maintained her nighttime composing habit\", # With melodies inspired by a moonlit rabbit.\n",
    "    \"The teacher had a creative teaching habit\", # Using stories about a wise philosophical rabbit.\n",
    "    \"My uncle can't kick his star-gazing habit\", # Often seeing constellations shaped like a rabbit.\n",
    "    \"She formed an unusual sketching habit\", # Drawing landscapes always featuring a distant rabbit.\n",
    "    \"The doctor maintained a healthy eating habit\", # Enjoying salads that would impress a rabbit.\n",
    "    \"The botanist kept her plant-collecting habit\", # Finding species that attracted the rare mountain rabbit.\n",
    "    \"My brother developed a strange talking habit\", # Of narrating his day to an imaginary rabbit.\n",
    "    \"The seamstress maintained her sewing habit\", # Crafting costumes featuring a dancing rabbit.\n",
    "    \"The old man had a generous feeding habit\", # Sharing his garden harvest with each passing rabbit.\n",
    "    \"The barista perfected her latte art habit\", # Creating foam designs resembling a jumping rabbit.\n",
    "    \"The astronomer continued her stargazing habit\", # Discovering a nebula shaped like a cosmic rabbit.\n",
    "    \"The carpenter refined his woodworking habit\", # Carving intricate figures of a forest rabbit.\n",
    "    \"My cousin formed an unusual naming habit\", # Calling every stray animal 'Peter the rabbit'.\n",
    "    \"The librarian kept her book-suggesting habit\", # Often recommending tales about a clever rabbit.\n",
    "    \"The hiker maintained her trail-blazing habit\", # Following paths once traveled by the snowshoe rabbit.\n",
    "    \"The young girl had a flower-collecting habit\", # Making crowns she'd place upon her patient rabbit.\n",
    "    \"The researcher developed a note-taking habit\", # Recording every movement of the study's rabbit.\n",
    "    \"The poet sustained his daily writing habit\", # Composing verses about a philosophical rabbit.\n",
    "    \"My aunt established a dawn gardening habit\", # Working alongside her garden-helping rabbit.\n",
    "    \"The student formed a late-night studying habit\", # Taking breaks to play with her energetic rabbit.\n",
    "    \"The baker kept an experimental baking habit\", # Creating carrot treats for her customer's rabbit.\n",
    "    \"The filmmaker maintained a storytelling habit\", # Often featuring adventures of a heroic rabbit.\n",
    "    \"The musician developed a curious practice habit\", # Playing sonatas that soothed her nervous rabbit.\n",
    "    \"The naturalist continued her tracking habit\", # Documenting the passage of each wild rabbit.\n",
    "    \"My father couldn't break his early waking habit\", # Always finding time to feed the backyard rabbit.\n",
    "    \"The magician perfected his hat-pulling habit\", # Surprising audiences with an appearing rabbit.\n",
    "    \"The engineer maintained her inventing habit\", # Creating gadgets to entertain her bored rabbit.\n",
    "    \"The florist developed an arrangement habit\", # Including carrot tops to please her shop's rabbit.\n",
    "    \"The therapist kept her gentle listening habit\", # Showing patience that matched her office rabbit.\n",
    "]\n",
    "\n",
    "lines_that_rhyme_with_habit = [\n",
    "    \"When I found a small, trembling rabbit\", # Caring for animals became my habit.\n",
    "    \"She darted through the garden like a rabbit\", # Looking for treats had become her habit.\n",
    "    \"He claimed he could pull a hat from a rabbit\", # Showing off magic tricks was his daily habit.\n",
    "    \"The children giggled as they chased the rabbit\", # Running through meadows became their favorite habit.\n",
    "    \"I planted carrots to attract a rabbit\", # Gardening in spring is my cherished habit.\n",
    "    \"My thoughts multiply faster than a rabbit\", # Overthinking has become my worst habit.\n",
    "    \"The speedy win went to the tortoise, not the rabbit\", # Victory comes from persistence, not just habit.\n",
    "    \"In the moonlight hopped a silver rabbit\", # Stargazing at night is now my habit.\n",
    "    \"They built a cozy hutch for their new rabbit\", # Creating homes for pets is a wonderful habit.\n",
    "    \"The chef prepared a savory stew with rabbit\", # Cooking wild game had become his habit.\n",
    "    \"Through tall grass I spotted a cottontail rabbit\", # Hiking through fields is my weekend habit.\n",
    "    \"The magician waved his wand and vanished the rabbit\", # Astonishing crowds had become his habit.\n",
    "    \"I sketched the ears and whiskers of a rabbit\", # Drawing animals is my creative habit.\n",
    "    \"The farmer chased away the vegetable-stealing rabbit\", # Protecting his crops was a necessary habit.\n",
    "    \"At dawn the fox was hunting for a rabbit\", # Early rising became his daily habit.\n",
    "    \"In the story, Peter was a mischievous rabbit\", # Reading fables became our bedtime habit.\n",
    "    \"Her fear made her timid just like a rabbit\", # Avoiding confrontation was her lifelong habit.\n",
    "    \"The child's stuffed toy was a velveteen rabbit\", # Carrying comfort objects was her childhood habit.\n",
    "    \"The dog barked loudly at the wild rabbit\", # Alert guarding is his protective habit.\n",
    "    \"The hunter set a snare to catch a rabbit\", # Living off the land was his family habit.\n",
    "    \"The camera captured a leaping snow-white rabbit\", # Photography in winter is my seasonal habit.\n",
    "    \"A clever fox can easily outfox a rabbit\", # Strategic thinking is my professional habit.\n",
    "    \"The full moon illuminated the jackrabbit\", # Evening walks became our romantic habit.\n",
    "    \"Under the bush was hiding a frightened rabbit\", # Finding secret spaces was her peculiar habit.\n",
    "    \"Into his hat disappeared the magical rabbit\", # Performing illusions was his lucrative habit.\n",
    "    \"My daughter begged for a pet dwarf rabbit\", # Collecting small animals became her expensive habit.\n",
    "    \"The naturalist observed the rare desert rabbit\", # Scientific inquiry was her passionate habit.\n",
    "    \"Tales of Brer Fox always included a rabbit\", # Telling folk stories was grandfather's evening habit.\n",
    "    \"She embroidered the silhouette of a rabbit\", # Creating handcrafted gifts was her generous habit.\n",
    "    \"Through the forest hopped a nimble rabbit\", # Morning exercises became his energizing habit.\n",
    "    \"We watched with awe the jumping jackrabbit\", # Desert exploration became our vacation habit.\n",
    "    \"The painting depicted a wild mountain rabbit\", # Collecting wildlife art was his expensive habit.\n",
    "    \"In the field I photographed a rare pygmy rabbit\", # Documenting endangered species is my conservation habit.\n",
    "    \"The child's first pet was a Dutch lop rabbit\", # Learning responsibility became her formative habit.\n",
    "    \"On Easter morning appeared a chocolate rabbit\", # Holiday traditions became our family habit.\n",
    "    \"The scientist studied the behavior of the arctic rabbit\", # Meticulous observation was her scientific habit.\n",
    "    \"The birthday gift was an Angora rabbit\", # Surprising loved ones is my thoughtful habit.\n",
    "    \"Never try to outrun a frightened rabbit\", # Setting realistic goals is my productive habit.\n",
    "    \"Into the brush disappeared the elusive rabbit\", # Playing hide-and-seek was their childhood habit.\n",
    "    \"The young boy dreamed of owning a rabbit\", # Wishful thinking became his daydreaming habit.\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ffc1ca1-b693-4e71-8f4f-1b9cf8c578a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4d9e79d-2df4-4789-aa1f-e643807a3f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: google/gemma-2-9b-it\n",
      "Using device: cuda\n",
      "Using dtype: torch.bfloat16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed5a2dc9bd714031b2a571954d119ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/47.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61eddbe0596545429ca3272c09c28510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3383f8aa9d4244cf90de795897440387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe490e79e5f046d7881f84e6770fb0ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51a76eee723545e794901171248b6b48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/857 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fc187e3d4af4f98bba53ce817e7b86b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/39.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "708e38d4922f4ab283f31677fc1cddb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8949d843fb5345a389f42271d4c10135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68444279924549cf921d360d12c432d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03012bfdf63743deb28d9f8fea1024ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "297cb908392b4921b79d1aa238139ad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/3.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "534a82cdf2a14ace8ed0467209cc7e70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f64816b970d141c9bdf7d28a5db9a377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/173 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on device(s): {'': 0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Gemma2ForCausalLM(\n",
       "  (model): Gemma2Model(\n",
       "    (embed_tokens): Embedding(256000, 3584, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-41): 42 x Gemma2DecoderLayer(\n",
       "        (self_attn): Gemma2Attention(\n",
       "          (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
       "          (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
       "        )\n",
       "        (mlp): Gemma2MLP(\n",
       "          (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
       "          (act_fn): PytorchGELUTanh()\n",
       "        )\n",
       "        (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
       "        (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
       "        (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
       "        (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
       "    (rotary_emb): Gemma2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3584, out_features=256000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# ## 3. Load Model and Tokenizer\n",
    "\n",
    "# +\n",
    "# Configure quantization if needed\n",
    "quantization_config = None\n",
    "if USE_4BIT_QUANTIZATION:\n",
    "    quantization_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16 # Recommended for new models\n",
    "    )\n",
    "    print(\"Using 4-bit quantization.\")\n",
    "\n",
    "# Determine device and dtype\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.bfloat16 if torch.cuda.is_available() and torch.cuda.get_device_capability()[0] >= 8 else torch.float32 # BF16 recommended on Ampere+\n",
    "\n",
    "print(f\"Loading model: {MODEL_ID}\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Using dtype: {dtype}\")\n",
    "\n",
    "# Load Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token # Set pad token if not present\n",
    "\n",
    "# Load Model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    torch_dtype=dtype,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"auto\", # Automatically distribute across GPUs if available\n",
    "    # use_auth_token=YOUR_HF_TOKEN, # Add if model requires authentication\n",
    "    trust_remote_code=True # Gemma requires this for some versions/variants\n",
    ")\n",
    "\n",
    "print(f\"Model loaded on device(s): {model.hf_device_map}\")\n",
    "\n",
    "# --- IMPORTANT: Finding the Layer Name ---\n",
    "# Uncomment the following line to print the model structure and find the exact layer name\n",
    "# print(model)\n",
    "# Look for layers like 'model.layers[INDEX].mlp...' or 'model.layers[INDEX].self_attn...'\n",
    "\n",
    "# Ensure model is in evaluation mode\n",
    "model.eval()\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8b34d75-a620-44b2-b9a3-a82e9b4328ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 4. Hooking and Activation Handling Functions\n",
    "\n",
    "# +\n",
    "# Global storage for captured activations\n",
    "activation_storage = {}\n",
    "\n",
    "def get_module_by_name(model, module_name):\n",
    "    \"\"\"Helper function to get a module object from its name string.\"\"\"\n",
    "    names = module_name.split('.')\n",
    "    module = model\n",
    "    for name in names:\n",
    "        module = getattr(module, name)\n",
    "    return module\n",
    "\n",
    "def capture_activation_hook(module, input, output, layer_name):\n",
    "    \"\"\"Hook function to capture the output activation of a specific layer.\"\"\"\n",
    "    # We usually care about the last token's activation for steering calculation\n",
    "    # Output shape is often (batch_size, sequence_length, hidden_dim)\n",
    "    # Store the activation corresponding to the last token position\n",
    "    if isinstance(output, torch.Tensor):\n",
    "        activation_storage[layer_name] = output[:, -1, :].detach().cpu()\n",
    "    elif isinstance(output, tuple): # Some layers might return tuples\n",
    "        activation_storage[layer_name] = output[0][:, -1, :].detach().cpu()\n",
    "    else:\n",
    "         print(f\"Warning: Unexpected output type from layer {layer_name}: {type(output)}\")\n",
    "\n",
    "def capture_activation_hook_fast(module, input, output, layer_name):\n",
    "    \"\"\"Hook function to capture the output activation of a specific layer.\"\"\"\n",
    "    # We usually care about the last token's activation for steering calculation\n",
    "    # Output shape is often (batch_size, sequence_length, hidden_dim)\n",
    "    # Store the activation corresponding to the last token position\n",
    "    if isinstance(output, torch.Tensor):\n",
    "        activation_storage[layer_name] = output[:, -1, :].detach().cpu()\n",
    "    elif isinstance(output, tuple): # Some layers might return tuples\n",
    "        activation_storage[layer_name] = output[0][:, -1, :].detach().cpu()\n",
    "    else:\n",
    "         print(f\"Warning: Unexpected output type from layer {layer_name}: {type(output)}\")\n",
    "\n",
    "\n",
    "def get_activations_fast(model, tokenizer, prompts: List[str], layer_name: str) -> Optional[torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Runs prompts through the model and captures activations from the target layer.\n",
    "    Returns the averaged activation across all prompts for the last token position.\n",
    "    \"\"\"\n",
    "    global activation_storage\n",
    "    activation_storage = {} # Clear previous activations\n",
    "\n",
    "    inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "    target_module = get_module_by_name(model, layer_name)\n",
    "    hook_handle = target_module.register_forward_hook(\n",
    "        lambda module, input, output: capture_activation_hook_fast(module, input, output, layer_name)\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
    "        # We only need the forward pass, not generation here\n",
    "        _ = model(**inputs)\n",
    "\n",
    "        if layer_name in activation_storage:\n",
    "                # Assuming batch size is 1 when processing one prompt at a time\n",
    "            last_token_activations = activation_storage[layer_name] # Shape (num_prompts, hidden_dim)\n",
    "            del activation_storage[layer_name] # Clear for next prompt\n",
    "        else:\n",
    "            print(f\"Warning: Activation for layer {layer_name} not captured for prompts: '{prompts}'\")\n",
    "                \n",
    "    hook_handle.remove() # Clean up the hook\n",
    "\n",
    "    # Stack and average activations across all prompts\n",
    "    # Resulting shape: (num_prompts, hidden_dim) -> (hidden_dim)\n",
    "    avg_activation = last_token_activations.mean(dim=0).squeeze() # Average over the prompt dimension\n",
    "    # print(f\"Calculated average activation for layer '{layer_name}' with shape: {avg_activation.shape}\")\n",
    "    return avg_activation\n",
    "# %%\n",
    " # --- Steering Hook during Generation ---\n",
    "\n",
    "# Global variable to hold the steering vector during generation\n",
    "steering_vector_internal = None\n",
    "steering_multiplier_internal = 1.0\n",
    "all_positions=False\n",
    "\n",
    "def steering_hook(module, input, output):\n",
    "    \"\"\"Hook function to modify activations during generation.\"\"\"\n",
    "    global steering_vector_internal, steering_multiplier_internal, all_positions\n",
    "    if steering_vector_internal is not None:\n",
    "        if isinstance(output, torch.Tensor):\n",
    "            # Add steering vector (broadcasts across sequence length)\n",
    "            # Shape adjustment might be needed depending on layer output structure\n",
    "            # Assuming output is (batch_size, seq_len, hidden_dim)\n",
    "            # and steering_vector is (hidden_dim)\n",
    "            if output.shape[1] != 1:\n",
    "                output[:, -1, :] += (steering_vector_internal.to(output.device, dtype=output.dtype) * steering_multiplier_internal)\n",
    "            return output\n",
    "        elif isinstance(output, tuple): # Handle layers returning tuples\n",
    "            # Assuming the tensor to modify is the first element\n",
    "            modified_tensor = output[0]\n",
    "            # print(modified_tensor.shape)\n",
    "            if modified_tensor.shape[1] != 1  or all_positions:\n",
    "                modified_tensor[:, -1, :] += (steering_vector_internal.to(output[0].device, dtype=output[0].dtype) * steering_multiplier_internal)\n",
    "            return (modified_tensor,) + output[1:]\n",
    "        else:\n",
    "            print(f\"Warning: Steering hook encountered unexpected output type: {type(output)}\")\n",
    "            return output # Return original if type is unknown\n",
    "    return output # Return original if no steering vector\n",
    "\n",
    "@contextmanager\n",
    "def apply_steering(model, layer, steering_vector, multiplier):\n",
    "    \"\"\"Context manager to temporarily apply the steering hook.\"\"\"\n",
    "    global steering_vector_internal, steering_multiplier_internal\n",
    "    layer_name = f\"model.layers.{layer}\"\n",
    "\n",
    "    # Ensure previous hook (if any) on the same layer is removed\n",
    "    # This basic implementation assumes only one steering hook at a time on this layer\n",
    "    # More robust solutions might track handles explicitly.\n",
    "    \n",
    "    handle = None\n",
    "    try:\n",
    "        steering_vector_internal = steering_vector\n",
    "        steering_multiplier_internal = multiplier\n",
    "        target_module = get_module_by_name(model, layer_name)\n",
    "        handle = target_module.register_forward_hook(steering_hook)\n",
    "        # print(f\"Steering hook applied to {layer_name} with multiplier {multiplier}\")\n",
    "        yield # Generation happens here\n",
    "    finally:\n",
    "        if handle:\n",
    "            handle.remove()\n",
    "        steering_vector_internal = None # Clear global state\n",
    "        steering_multiplier_internal = 1.0\n",
    "        # print(f\"Steering hook removed from {layer_name}\")\n",
    "        gc.collect() # Suggest garbage collection\n",
    "        torch.cuda.empty_cache() # Clear cache if using GPU\n",
    "\n",
    "def generate_steered_output(steering_vector, model, tokenizer, generation_prompt, batch_size, layer=20, steering_multiplier=STEERING_MULTIPLIER):\n",
    "    inputs = tokenizer([generation_prompt] * batch_size, return_tensors=\"pt\", padding=True).to(model.device)\n",
    "    if steering_vector is None:\n",
    "        # print(inputs.input_ids.shape)\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=MAX_NEW_TOKENS,\n",
    "                temperature=TEMPERATURE,\n",
    "                do_sample=DO_SAMPLE,\n",
    "                pad_token_id=tokenizer.eos_token_id # Important for generation\n",
    "            )\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            # Apply the steering hook using the context manager\n",
    "            with apply_steering(model, layer, steering_vector, steering_multiplier):\n",
    "                outputs = model.generate(\n",
    "                    **inputs, # Use the same input tokens\n",
    "                    max_new_tokens=MAX_NEW_TOKENS,\n",
    "                    temperature=TEMPERATURE,\n",
    "                    do_sample=DO_SAMPLE,\n",
    "                    pad_token_id=tokenizer.eos_token_id,\n",
    "                )\n",
    "    text = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "    del outputs, inputs\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "def generate_outputs(steering_vector, model, tokenizer, generation_prompt, batch_size, layer=20, steering_multiplier=STEERING_MULTIPLIER):\n",
    "    assert steering_vector is not None\n",
    "    text_baseline = generate_steered_output(None, model, tokenizer, generation_prompt, batch_size, layer=layer, steering_multiplier=steering_multiplier)\n",
    "    text_steered = generate_steered_output(steering_vector, model, tokenizer, generation_prompt, batch_size, layer=layer, steering_multiplier=steering_multiplier)\n",
    "    text_negsteered = generate_steered_output(-steering_vector, model, tokenizer, generation_prompt, batch_size, layer=layer, steering_multiplier=steering_multiplier)\n",
    "    return text_baseline, text_steered, text_negsteered\n",
    "\n",
    "# %%\n",
    "# ## Compute the Steering Vector\n",
    "def get_steering_vector_fast(model, tokenizer, positive_prompts, negative_prompts, layer=20):\n",
    "    target_layer_name = f\"model.layers.{layer}\"\n",
    "    # print(\"Calculating activations for POSITIVE prompts...\")\n",
    "    avg_pos_activation = get_activations_fast(model, tokenizer, positive_prompts, target_layer_name)\n",
    "\n",
    "    # print(\"\\nCalculating activations for NEGATIVE prompts...\")\n",
    "    avg_neg_activation = get_activations_fast(model, tokenizer, negative_prompts, target_layer_name)\n",
    "\n",
    "    steering_vector = None\n",
    "    if avg_pos_activation is not None and avg_neg_activation is not None:\n",
    "        steering_vector = avg_pos_activation - avg_neg_activation\n",
    "        # print(f\"\\nSteering vector computed successfully. Shape: {steering_vector.shape}\")\n",
    "        # Optional: Normalize the steering vector (can sometimes help)\n",
    "        # steering_vector = steering_vector / torch.norm(steering_vector)\n",
    "        # print(\"Steering vector normalized.\")\n",
    "    else:\n",
    "        print(\"\\nError: Could not compute steering vector due to missing activations.\")\n",
    "    del avg_pos_activation\n",
    "    del avg_neg_activation\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    return steering_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca255d0c-59a1-4a2a-8820-a55077421799",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline:\n",
      "['Write a short paragraph about the future of artificial intelligence.\\n\\nThe future of artificial intelligence is brimming with both excitement and trepidation. As AI systems become increasingly sophisticated, they promise to revolutionize industries, automate tasks, and solve complex problems. From personalized', 'Write a short paragraph about the future of artificial intelligence.\\n\\nThe future of artificial intelligence is brimming with both promise and peril. As AI systems become increasingly sophisticated, they have the potential to revolutionize industries, accelerate scientific discovery, and solve complex global challenges.', 'Write a short paragraph about the future of artificial intelligence.\\n\\nThe future of artificial intelligence is brimming with both promise and peril. As AI algorithms become increasingly sophisticated, they have the potential to revolutionize industries, automate tasks, and solve complex problems.  Imagine', 'Write a short paragraph about the future of artificial intelligence.\\n\\nThe future of artificial intelligence is brimming with both promise and uncertainty. As AI algorithms continue to advance, we can expect to see transformative changes across various sectors, from healthcare and education to transportation and entertainment', 'Write a short paragraph about the future of artificial intelligence.\\n\\nThe future of artificial intelligence is brimming with possibilities, both exciting and daunting. As AI systems become increasingly sophisticated, they are poised to transform industries, automate tasks, and even augment human capabilities. However']\n",
      "Steered:\n",
      "['Write a short paragraph about the future of artificial intelligence.\\n\\nThe future of artificial intelligence is brimming with both promise and peril. As AI systems become increasingly sophisticated, they have the potential to revolutionize industries, solve complex problems, and enhance our quality of life', 'Write a short paragraph about the future of artificial intelligence.\\n\\nThe future of artificial intelligence is brimming with both promise and uncertainty. As AI technology continues to advance at an unprecedented pace, we can expect to see transformative changes across all sectors of society. From self', 'Write a short paragraph about the future of artificial intelligence.\\n\\nThe future of artificial intelligence is brimming with both promise and peril. As AI systems become increasingly sophisticated, they have the potential to revolutionize countless industries, automate tedious tasks, and even unlock groundbreaking scientific', 'Write a short paragraph about the future of artificial intelligence.\\n\\nThe future of artificial intelligence is brimming with both promise and peril. As AI systems become increasingly sophisticated, they have the potential to revolutionize countless industries, from healthcare to transportation, leading to unprecedented advancements', 'Write a short paragraph about the future of artificial intelligence.\\n\\nThe future of artificial intelligence is brimming with both promise and potential peril. As AI systems become increasingly sophisticated, they are poised to revolutionize industries, automating tasks, driving innovation, and solving complex problems']\n",
      "Negatively steered:\n",
      "['Write a short paragraph about the future of artificial intelligence.\\n\\nThe future of artificial intelligence is both exhilarating and daunting. Advancements in machine learning and deep learning promise breakthroughs in fields like healthcare, transportation, and scientific discovery. AI-powered systems could automate mundane', 'Write a short paragraph about the future of artificial intelligence.\\n\\nThe future of artificial intelligence is both exciting and daunting. As AI systems become increasingly sophisticated, they have the potential to revolutionize countless industries, from healthcare to transportation. However, this rapid progress also', 'Write a short paragraph about the future of artificial intelligence.\\n\\nThe future of artificial intelligence is both exhilarating and daunting. As AI systems become increasingly sophisticated, they will undoubtedly revolutionize countless aspects of our lives, from healthcare and transportation to education and entertainment. However', 'Write a short paragraph about the future of artificial intelligence.\\n\\nThe future of artificial intelligence is both exhilarating and daunting. Advancements in machine learning and deep learning are pushing the boundaries of what AI can achieve, from automating complex tasks to generating creative content. However', 'Write a short paragraph about the future of artificial intelligence.\\n\\nThe future of artificial intelligence is a landscape fraught with both promise and peril. As AI systems become increasingly sophisticated, they have the potential to revolutionize countless industries, from healthcare to transportation, driving unprecedented']\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# ## Functions to analyze the generations\n",
    "def get_last_word(text):\n",
    "    lines = text.split(\"\\n\")\n",
    "    if len(lines) < 3:\n",
    "        print(f\"Failed to get last word: {text}\")\n",
    "        return \"\"\n",
    "    second_line = lines[2]\n",
    "    second_line_words = second_line.split(\" \")\n",
    "    if len(second_line_words) == 0:\n",
    "        print(f\"Failed to get last word: {text}\")\n",
    "        return \"\"\n",
    "    last_word = second_line_words[-1]\n",
    "    if last_word == \"\":\n",
    "        if len(second_line_words) == 1:\n",
    "            print(f\"Failed to get last word: {text}\")\n",
    "            return \"\"\n",
    "        last_word = second_line_words[-2]\n",
    "    return last_word\n",
    "\n",
    "def get_last_word_fraction(texts, words):\n",
    "    if isinstance(words, str):\n",
    "        words = [words]\n",
    "    last_words = [get_last_word(line) for line in texts]\n",
    "    return len([w for w in last_words if any(w2.lower() in w.lower() for w2 in words)]) / len(last_words)\n",
    "\n",
    "def get_prompts(lines):\n",
    "    return [f'A rhymed couplet:\\n{line}\\n' for line in lines]\n",
    "\n",
    "\n",
    "\n",
    "POSITIVE_PROMPTS = [\n",
    "    \"This story should be very optimistic and uplifting.\",\n",
    "    \"Write a hopeful and positive narrative.\",\n",
    "    \"Generate text with a cheerful and encouraging tone.\",\n",
    "]\n",
    "NEGATIVE_PROMPTS = [\n",
    "    \"This story should be very pessimistic and bleak.\",\n",
    "    \"Write a depressing and negative narrative.\",\n",
    "    \"Generate text with a gloomy and discouraging tone.\",\n",
    "]\n",
    "\n",
    "# The prompt to use for actual generation\n",
    "GENERATION_PROMPT = \"Write a short paragraph about the future of artificial intelligence.\"\n",
    "\n",
    "from tqdm import tqdm\n",
    "STEERING_MULTIPLIER = 1.5\n",
    "LAYER = 20\n",
    "MAX_NEW_TOKENS = 40\n",
    "\n",
    "#test on sentiment steering\n",
    "steering_vector = get_steering_vector_fast(model, tokenizer, POSITIVE_PROMPTS, NEGATIVE_PROMPTS, layer=20)\n",
    "text_baseline, text_steered, text_negsteered = generate_outputs(steering_vector, model, tokenizer, GENERATION_PROMPT, 5, layer=LAYER, steering_multiplier=STEERING_MULTIPLIER)\n",
    "print(\"Baseline:\")\n",
    "print(text_baseline)\n",
    "print(\"Steered:\")\n",
    "print(text_steered)\n",
    "print(\"Negatively steered:\")\n",
    "print(text_negsteered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8600a7c-270c-4797-ab19-07bd8ba52407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline:\n",
      "[\"A rhymed couplet:\\nFrom all the fruits available, I'll make my pick\\nOf plump, sweet strawberries, their taste quite slick.\\n\\n\\n\\n\", \"A rhymed couplet:\\nFrom all the fruits available, I'll make my pick\\nOf juicy mangoes, sweet and thick.\\n\\n\\nLet me know if you'd like to see more!\\n\", \"A rhymed couplet:\\nFrom all the fruits available, I'll make my pick\\nOf the sweetest, juiciest, one with a vibrant slick. \\n\\n\\nLet me know if you'd like another one! \\n\", \"A rhymed couplet:\\nFrom all the fruits available, I'll make my pick\\nOf juicy oranges, sweet and oh so thick.\\n\\n\\nLet me know if you want to try another one! \\n\", \"A rhymed couplet:\\nFrom all the fruits available, I'll make my pick\\nA juicy mango, sweet and quick.\\n\\n\\n\\nLet me know if you'd like to see more!\\n\"]\n",
      "Steered:\n",
      "[\"A rhymed couplet:\\nFrom all the fruits available, I'll make my pick\\nA juicy peach, so sweet, is my only trick.\\n\\n\\nLet me know if you'd like to see more!\\n\", \"A rhymed couplet:\\nFrom all the fruits available, I'll make my pick\\nOf juicy pear, with flesh so sweet and slick.\\n\\n\\nLet me know if you'd like to see more!\\n\", \"A rhymed couplet:\\nFrom all the fruits available, I'll make my pick\\nOf juicy mango, sweet, and oh so thick. \\n\\n\\nLet me know if you'd like another one! \\n\", \"A rhymed couplet:\\nFrom all the fruits available, I'll make my pick\\nOf juicy mango, sunshine bright, sweet and thick.\\n\\n\\nLet me know if you'd like to see more rhyming couplets!  \\n\", \"A rhymed couplet:\\nFrom all the fruits available, I'll make my pick\\nA juicy pear, so sweet, a delightful lick.\\n\\nWould you like to hear another one?\\n\"]\n",
      "Negatively steered:\n",
      "[\"A rhymed couplet:\\nFrom all the fruits available, I'll make my pick\\nAnd savor every bite, a treat so quick.\\n\\nThis is a simple example of a rhymed couplet. \\n\\nHere are some key points about rhymed couplets:\\n\\n* **Two\", \"A rhymed couplet:\\nFrom all the fruits available, I'll make my pick\\nThough tart or sweet, the choice will be quick. \\n\\n\\n\", \"A rhymed couplet:\\nFrom all the fruits available, I'll make my pick\\nand feast upon the sweetest, boldest, quick.\\n\\nThis is just one example. \\n\\nThe key features of a rhymed couplet are:\\n* **Two lines:**  Always exactly\", \"A rhymed couplet:\\nFrom all the fruits available, I'll make my pick\\nFor the sweetest, juiciest, and tastiest, quick!\\n\\n\\n\\n\", \"A rhymed couplet:\\nFrom all the fruits available, I'll make my pick\\nOf something sweet, delectable, and oh so thick. \\n\\n\\n\"]\n"
     ]
    }
   ],
   "source": [
    "def get_prompts_unrhymed(lines):\n",
    "    return [f'An unrhymed couplet:\\n{line}\\n' for line in lines]\n",
    "\n",
    "STEERING_MULTIPLIER = 1.5\n",
    "LAYER = 27\n",
    "MAX_NEW_TOKENS = 40\n",
    "\n",
    "POSITIVE_PROMPTS = get_prompts(lines_that_rhyme_with_quick)\n",
    "NEGATIVE_PROMPTS = get_prompts_unrhymed(lines_that_rhyme_with_quick)\n",
    "\n",
    "GENERATION_PROMPT = POSITIVE_PROMPTS[6]\n",
    "\n",
    "steering_vector = get_steering_vector_fast(model, tokenizer, POSITIVE_PROMPTS, NEGATIVE_PROMPTS, layer=LAYER)\n",
    "text_baseline, text_steered, text_negsteered = generate_outputs(steering_vector, model, tokenizer, GENERATION_PROMPT, 5, layer=LAYER, steering_multiplier=STEERING_MULTIPLIER)\n",
    "print(\"Baseline:\")\n",
    "print(text_baseline)\n",
    "print(\"Steered:\")\n",
    "print(text_steered)\n",
    "print(\"Negatively steered:\")\n",
    "print(text_negsteered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "228a146f-45a9-4f6e-9c33-cd23c565f4de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "example_based_unrhymed_prompts_quick=[\n",
    "\"Among the towering oaks and whispered winds\\nGenerations carved their legacy into earth\\nThe house was built with sturdy, reddish brick\",\n",
    "\"Memories suspended in digital eternity\\nSilent witness to joy and passing time\\nThe camera captured moments with each click\",\n",
    "\"Darkness enveloped the empty room\\nHer shadow stretched across the wooden floor\\nShe turned the lights on with a simple flick\",\n",
    "\"The stadium held its collective breath\\nYears of practice culminated in this moment\\nThe soccer player gave the ball a mighty kick\",\n",
    "\"New life trembling with excitement\\nEyes reflecting unconditional devotion\\nThe puppy gave my hand a gentle lick\",\n",
    "\"Morning routines performed half-asleep\\nThe mirror revealed tired eyes and stubbled chin\\nThe razor left a small and painful nick\",\n",
    "\"The market overflowed with summer's bounty\\nColors and scents competed for attention\\nFrom all the fruits available, I'll make my pick\",\n",
    "\"Beauty often demands its price of pain\\nGarden treasures hidden among green leaves\\nThe rose's thorn can cause a sudden prick\",\n",
    "\"The world continued without his presence\\nPlans abandoned for blankets and tea\\nHe stayed at home because he felt too sick\",\n",
    "\"Storm clouds emptied their relentless burden\\nHeadlights struggled through sheets of water\\nThe rain had made the winding road quite slick\",\n",
    "\"Imagination flowed without boundaries or rules\\nSmall hands created worlds unknown to adults\\nThe child drew pictures with a charcoal stick\",\n",
    "\"Mountains disappeared into ghostly silence\\nThe world reduced to what stood before you\\nThe winter fog was rolling in so thick\",\n",
    "\"Time measured in heartbeats and breaths\\nThe quiet room amplified each sound\\nThe clock marked every second with a tick\",\n",
    "\"The audience leaned forward in anticipation\\nReality momentarily suspended its rules\\nThe magician performed an amazing trick\",\n",
    "\"Light fought a losing battle against darkness\\nShadows danced their final waltz on walls\\nThe candle slowly burned down to the wick\"\n",
    "]\n",
    "\n",
    "example_based_rhymed_prompts_quick=[\n",
    "\"The morning sun cast shadows long and bright\\nThe valley glowed with warm, inviting light\\nThe house was built with sturdy, reddish brick\",\n",
    "\"The album holds what memory cannot keep\\nThe past preserved in images so deep\\nThe camera captured moments with each click\",\n",
    "\"The darkness seemed to swallow every sound\\nThe emptiness of night hung all around\\nShe turned the lights on with a simple flick\",\n",
    "\"The player saw an opening ahead\\nA chance to score that filled the crowd with dread\\nThe soccer player gave the ball a mighty kick\",\n",
    "\"His eyes were bright with innocence and love\\nHis tail wagged fast, like wings upon a dove\\nThe puppy gave my hand a gentle lick\",\n",
    "\"The mirror showed a face not fully waked\\nThe hand that held the blade slightly shaked\\nThe razor left a small and painful nick\",\n",
    "\"The orchard's bounty spread before my eyes\\nA rainbow spectrum under summer skies\\nFrom all the fruits available, I'll make my pick\",\n",
    "\"The garden held its beauty and its pain\\nNature's gifts are never quite so plain\\nThe rose's thorn can cause a sudden prick\",\n",
    "\"The sunshine called through windows clear and bright\\nBut fever kept him through the day and night\\nHe stayed at home because he felt too sick\",\n",
    "\"The clouds above hung heavy, dark and low\\nThe path ahead was difficult to know\\nThe rain had made the winding road quite slick\",\n",
    "\"Her mind created worlds no one could see\\nImagination flowing wild and free\\nThe child drew pictures with a charcoal stick\",\n",
    "\"The landscape disappeared from human sight\\nThe world now wrapped in gray, ethereal light\\nThe winter fog was rolling in so thick\",\n",
    "\"Each moment passed in measured certainty\\nThe rhythm marking time's infinity\\nThe clock marked every second with a tick\",\n",
    "\"The crowd sat hushed in wonder and delight\\nExpecting wonders on this special night\\nThe magician performed an amazing trick\",\n",
    "\"The darkness crept across the quiet room\\nThe light grew faint, foretelling coming gloom\\nThe candle slowly burned down to the wick\"\n",
    "]\n",
    "\n",
    "def add_newline(lines): return [line+'\\n' for line in lines]\n",
    "POSITIVE_PROMPTS = add_newline(example_based_rhymed_prompts_quick)\n",
    "NEGATIVE_PROMPTS = add_newline(example_based_unrhymed_prompts_quick)\n",
    "\n",
    "GENERATION_PROMPT = NEGATIVE_PROMPTS[6]\n",
    "\n",
    "steering_vector = get_steering_vector_fast(model, tokenizer, POSITIVE_PROMPTS, NEGATIVE_PROMPTS, layer=LAYER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22790605-d31f-4b1c-8b64-84292fac99cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The house was built with sturdy, reddish brick',\n",
       " 'The camera captured moments with each click',\n",
       " 'She turned the lights on with a simple flick',\n",
       " 'The soccer player gave the ball a mighty kick',\n",
       " 'The puppy gave my hand a gentle lick',\n",
       " 'The razor left a small and painful nick',\n",
       " \"From all the fruits available, I'll make my pick\",\n",
       " \"The rose's thorn can cause a sudden prick\",\n",
       " 'He stayed at home because he felt too sick',\n",
       " 'The rain had made the winding road quite slick',\n",
       " 'The child drew pictures with a charcoal stick',\n",
       " 'The winter fog was rolling in so thick',\n",
       " 'The clock marked every second with a tick',\n",
       " 'The magician performed an amazing trick',\n",
       " 'The candle slowly burned down to the wick']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_that_rhyme_with_quick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e78eff02-44c1-45f2-aceb-ef3875049177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('feature_to_decoder.json','r') as f:\n",
    "    nightlatents=json.load(f)\n",
    "\n",
    "with open('feature_to_decoder.json_deep_rhyme_latent','r') as f:\n",
    "    deeplatents=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b19d36ec-b6a7-4814-b14e-30545b4485d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec5862=torch.tensor(nightlatents[\"5862\"]).to(device)\n",
    "vec14069=torch.tensor(deeplatents[\"14069\"]).to(device)\n",
    "saesteer=vec5862-vec14069"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aee8da7e-99ab-4e37-9761-0e38a3629c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline:\n",
      "['A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nWhere dreams were woven, stories would stick. \\n\\n\\n\\n', 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, with nary a crack.\\n\\n\\n**Please provide 2 more rhyming couplets.**\\n\\nHere are two more rhyming couplets:\\n\\n* A gentle breeze whispered through leaves of', 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood on ground where ancient legends stick.\\n\\n\\nThis couplet sets a scene and hints at a mysterious past.\\n\\n* **\"Sturdy, reddish brick\"** creates a visual image of a', \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for centuries, defying time's quick trick. \\n\\n\\nLet me know if you'd like another one! 😊 \\n\", 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, a landmark, strong and thick. \\n\\nLet me know if you want to see more!\\n']\n",
      "Steered:\n",
      "['A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood against the wind, a steadfast gain. \\n\\n\\nLet me know if you want to see more!\\n', \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nA testament to craftsmanship, a timeless trick. \\n\\nLet me know if you'd like another one!\\n\", \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nA beacon bright, against the falling rain. \\n\\n\\nLet me know if you'd like me to write another one! \\n\\n\", 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, defying wind and rain.\\n\\n\\n\\nHere are a few more rhyming couplets about the house:\\n\\n* **Inside:**\\n    * The fire crackled, warm and bright,', 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, a monument to stick.\\n\\n\\nHere\\'s a breakdown:\\n\\n* **Couplet:**  Two lines of poetry that rhyme.\\n* **Rhyme:** \"Brick\"']\n",
      "Negatively steered:\n",
      "['A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, a monument to tick.\\n\\nThis couplet plays on the word \"tick,\" which can refer to both the sound of a clock and the passage of time. The house\\'', 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, enduring every trick. \\n\\nDo you feel this couplet could be part of a larger poem about a house? If so, what kind of feelings or ideas about the house', 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, a beacon, strong and thick. \\n\\n\\nDo you want to explore this further? We could:\\n\\n* **Write more couplets about the house.**\\n* **Change', 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, an ancient, weathered trick.\\n\\n\\n', \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for ages, though the years were quick.\\n\\nLet me know if you'd like me to write more!\\n\"]\n"
     ]
    }
   ],
   "source": [
    "steering_vector=torch.load(\"steering_vectors_quick_to_pain/steering_vector_quick_to_pain_layer_20.pt\") \n",
    "\n",
    "GENERATION_PROMPT=f\"A rhymed couplet:\\n{lines_that_rhyme_with_quick[0]}\\n\"\n",
    "\n",
    "text_baseline, text_steered, text_negsteered = generate_outputs(steering_vector, model, tokenizer, GENERATION_PROMPT, 5, layer=20, steering_multiplier=1.5)\n",
    "print(\"Baseline:\")\n",
    "print(text_baseline)\n",
    "print(\"Steered:\")\n",
    "print(text_steered)\n",
    "print(\"Negatively steered:\")\n",
    "print(text_negsteered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0c6d1e54-cd7b-496e-86c9-674d37d8f08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_sounds={'bake_rhymes': 'k',\n",
    " 'band_rhymes': 'd',\n",
    " 'call_rhymes': 'l',\n",
    " 'doom_rhymes': 'm',\n",
    " 'night_rhymes': 't',\n",
    " 'pain_rhymes': 'n',\n",
    " 'shore_rhymes': 'r',\n",
    " 'sing_rhymes': 'g',\n",
    " 'skies_rhymes': 's',\n",
    " 'sleep_rhymes': 'p',\n",
    " 'slick_rhymes': 'k',\n",
    " 'unfold_rhymes': 'd'}\n",
    "\n",
    "\n",
    "layer=20\n",
    "with open (f\"data_splits_model.layers.{layer}.json\",'r')as f: \n",
    "    splits=json.load(f)\n",
    "train_words=[p[0].split()[-1] for p in splits['train']]\n",
    "validation_words=[p[0].split()[-1] for p in splits['validation']]\n",
    "\n",
    "rhymes={i: [] for i in last_sounds.keys()}\n",
    "for p in splits['train']+splits['validation']:\n",
    "    rhymes[p[1]].append(p[0].split()[-1])\n",
    "\n",
    "with open(f\"rhyme_probe_weights_model.layers.{layer}.json\", \"r\") as f:\n",
    "        extracted_weights=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "37e55dd2-a054-4c44-af02-b70a4bd5fc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from typing import List, Tuple, Union, Optional, Dict, Any\n",
    "\n",
    "def unembed_vector(\n",
    "    vector: Union[torch.Tensor, np.ndarray],\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    use_transpose: bool = False,\n",
    "    top_k: int = 10,\n",
    "    token_list: Optional[List[str]] = None,\n",
    "    device: Optional[str] = None,\n",
    "    dtype: Optional[torch.dtype] = None\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Unembed a vector using either the unembedding matrix or the transpose of the embedding matrix.\n",
    "    \n",
    "    Args:\n",
    "        vector: The vector to unembed (1D tensor or numpy array)\n",
    "        model_name: The Gemma model name\n",
    "        use_transpose: If True, use the transpose of the embedding matrix; if False, use the unembedding matrix\n",
    "        top_k: Number of top tokens to return\n",
    "        token_list: List of specific tokens to compute logits for\n",
    "        device: Device to run computation on ('cuda', 'cpu'). If None, will use CUDA if available.\n",
    "        dtype: Data type to use for computation. If None, will match the model's dtype.\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing:\n",
    "            - top_tokens: List of (token, score) pairs for top tokens\n",
    "            - specific_logits: Dictionary mapping tokens to their logits (if token_list provided)\n",
    "    \"\"\"\n",
    "    # Determine device\n",
    "    if device is None:\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    \n",
    "    # Determine dtype to use (match the model's dtype if not specified)\n",
    "    if dtype is None:\n",
    "        # Get model's dtype from embedding weights\n",
    "        model_dtype = model.get_input_embeddings().weight.dtype\n",
    "        dtype = model_dtype\n",
    "    \n",
    "    # Ensure vector is a torch tensor with correct dtype and device\n",
    "    if isinstance(vector, np.ndarray):\n",
    "        vector = torch.tensor(vector, dtype=dtype, device=device)\n",
    "    else:\n",
    "        vector = vector.to(device=device, dtype=dtype)\n",
    "    \n",
    "    if vector.dim() > 1:\n",
    "        # Flatten if needed - assuming the input might be a 2D embedding\n",
    "        vector = vector.squeeze()\n",
    "    \n",
    "    # Get the appropriate matrix for unembedding\n",
    "    with torch.no_grad():\n",
    "        if use_transpose:\n",
    "            # Use the transpose of the embedding matrix\n",
    "            embedding_matrix = model.get_input_embeddings().weight\n",
    "            unembedding_matrix = embedding_matrix.transpose(0, 1)\n",
    "        else:\n",
    "            # Use the unembedding matrix (lm_head)\n",
    "            unembedding_matrix = model.lm_head.weight.transpose(0, 1)\n",
    "    \n",
    "    # Ensure the vector has the correct shape to match the unembedding matrix\n",
    "    if vector.shape[0] != unembedding_matrix.shape[0]:\n",
    "        raise ValueError(f\"Vector dimension ({vector.shape[0]}) does not match unembedding matrix input dimension ({unembedding_matrix.shape[0]})\")\n",
    "    \n",
    "    # Compute the unembedded logits (using matrix-vector multiplication)\n",
    "    with torch.no_grad():  # No need to track gradients for inference\n",
    "        logits = torch.matmul(vector, unembedding_matrix)\n",
    "    \n",
    "    # Get the top-k token IDs based on logits\n",
    "    top_values, top_indices = torch.topk(logits, k=top_k)\n",
    "    \n",
    "    # Convert to tokens and build result list\n",
    "    top_tokens = []\n",
    "    for idx, (token_id, score) in enumerate(zip(top_indices.tolist(), top_values.tolist())):\n",
    "        token = tokenizer.decode(token_id)\n",
    "        top_tokens.append((token, score))\n",
    "    \n",
    "    result = {\n",
    "        \"top_tokens\": top_tokens,\n",
    "    }\n",
    "    \n",
    "    # Calculate logits for specific tokens if provided\n",
    "    if token_list is not None:\n",
    "        specific_logits = {}\n",
    "        specific_ranks = {}\n",
    "        sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
    "        token_to_rank = {idx.item(): rank for rank, idx in enumerate(sorted_indices)}\n",
    "\n",
    "        for token in token_list:\n",
    "            token_ids = tokenizer.encode(token, add_special_tokens=False)\n",
    "            if token_ids:\n",
    "                token_id = token_ids[0]\n",
    "                logit = logits[token_id].item()\n",
    "                rank = token_to_rank.get(token_id, None)\n",
    "                specific_logits[token] = logit\n",
    "                specific_ranks[token] = rank\n",
    "            else:\n",
    "                specific_logits[token] = float('nan')\n",
    "                specific_ranks[token] = None\n",
    "\n",
    "        result[\"specific_logits\"] = specific_logits\n",
    "        result[\"specific_ranks\"] = specific_ranks\n",
    "    \n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2c15bb2e-f7c6-4474-b574-fd83b9bbb5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bake_rhymes\n",
      "\trandom top logits:\n",
      " [' gawas', 'leine', ' flake', 'ErrUnexpectedEOF', 'PageContext']\n",
      "\n",
      "band_rhymes\n",
      "\trandom top logits:\n",
      " ['derry', ' Janus', 'andan', 'onActivityResult', 'ностран']\n",
      "\n",
      "call_rhymes\n",
      "\trandom top logits:\n",
      " ['<unused22>', ' שוליים', '<unused32>', ' zwiſchen', '<unused6>']\n",
      "\n",
      "doom_rhymes\n",
      "\trandom top logits:\n",
      " ['omu', ' externi', 'rungsseite', 'issory', 'uxxxx']\n",
      "\n",
      "night_rhymes\n",
      "\trandom top logits:\n",
      " [' ライト', 'ttt', 'Light', 'bottomRight', ' istr']\n",
      "\n",
      "pain_rhymes\n",
      "\trandom top logits:\n",
      " [' IFTT', ' chande', ' Wainwright', 'maus', 'mybatisplus']\n",
      "\n",
      "shore_rhymes\n",
      "\trandom top logits:\n",
      " ['er', 'didSet', ' ror', 'ERe', 'Tore']\n",
      "\n",
      "sing_rhymes\n",
      "\trandom top logits:\n",
      " ['Zing', ' vixion', ' 剪影', '\\ufeff/*', ' Obtener']\n",
      "\n",
      "skies_rhymes\n",
      "\trandom top logits:\n",
      " ['حياتها', '();*/', 'printStackTrace', 'sizeCache', ' Usaha']\n",
      "\n",
      "sleep_rhymes\n",
      "\trandom top logits:\n",
      " [' lep', 'Попис', '\\\\{\\\\\\\\', ' chacune', ' testGet']\n",
      "\n",
      "slick_rhymes\n",
      "\trandom top logits:\n",
      " [' вікісторінку', ' Geſch', 'ſſung', 'bildtitel', '<unused3>']\n",
      "\n",
      "unfold_rhymes\n",
      "\trandom top logits:\n",
      " ['stol', 'woll', 'lillah', 'bld', '<<(']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "layer = 27\n",
    "with open(f\"rhyme_probe_weights_model.layers.{layer}.json\", 'r') as f:\n",
    "    extracted_weights=json.load(f)\n",
    "for i in range(12):\n",
    "    label=list(extracted_weights.items())[i][0]\n",
    "    print(label)\n",
    "    rhymelist=list(set(rhymes[label]))\n",
    "    last_s=last_sounds[label]\n",
    "    v=unembed_vector(torch.tensor(list(extracted_weights.items())[i][1]),top_k=1000,token_list=rhymelist)\n",
    "    smp=[i[0] for i in v['top_tokens'][:100]]\n",
    "    random.shuffle(smp)\n",
    "    print(\"\\trandom top logits:\\n\",smp[:5])\n",
    "    #print(\"\\tPercentage positive logits for words in rhyme family:\",round(percentage_positive_second(v['specific_logits'].items()),2))\n",
    "    #print(\"\\tPercentage top 1K logits for words in rhyme family:\",round(percentage_first_thousand(v['specific_ranks'].items()),2))\n",
    "    #print(\"Count of\",last_s,\"in top tokens:\",len([i for i in v['top_tokens'] if last_s in i[0] or last_s.upper() in i[0]]))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c646d78-9106-4eda-9f20-08149a8849e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline:\n",
      "[\"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood against the wind, both strong and quick\\n\\nLet me know if you'd like to see more!\\n\", \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood against the storm, a steadfast trick. \\n\\n\\nLet me know if you'd like to explore some other rhyming couplets! I can try different themes or styles. \\n\", \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, a landmark, strong and quick. \\n\\n\\nLet me know if you'd like me to write more! \\n\\n\", \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, a testament so quick.\\n\\nLet me know if you'd like to see more!\\n\", \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, a steadfast, strong, thick stick. \\n\\n\\n\\nLet me know if you'd like to see more!  I enjoy writing poetry. \\n\"]\n",
      "Steered:\n",
      "['A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\n- it stood for years, against the wind so quick.\\n\\nWould you like to hear another?\\n', 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nlyricist\\'s name was, in fact, Mick.\\n\\nHow does this couplet work?\\n\\n**Structure:**\\n* **Rhyme:** The words \"brick\" and \"Mick\" rhyme', \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\n(**The**) **house** **was** **built** **with** **sturdy**, **reddish** **brick**.\\n\\nLet me know if you'd like to explore other rhyming\", \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nlyrical and strong, it stood against the bleak.\\n\\n\\nLet me know if you'd like more!\\n\", 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nlyrical couplet\\nThe sun dipped low, a blush upon the sky\\n\\nHere are a few more examples of rhyming and lyrical couplets:\\n\\n**Rhyming Couplets:**\\n\\n* The wind']\n",
      "Negatively steered:\n",
      "[\"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\n, a sight to see, an architectural trick. \\n\\n\\nLet me know if you'd like more! I can write about different things, or in different styles. \\n\\n\", \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\n a sight to see, both strong and quick. \\n\\n\\nLet me know if you'd like to see more! I can write couplets about different topics. 😊  \\n\", \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\n a hundred years ago, a timeless trick.\\n\\nI'd love to hear some more! \\n\\n\\n\", 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\n,\\nA beacon in the dusk, against the crick. \\n\\nLet me know if you want more!', \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\n,\\nAnd stood against the storms, a sturdy stick. \\n\\n\\nLet me know if you'd like more examples!\\n\"]\n"
     ]
    }
   ],
   "source": [
    "text_baseline, text_steered, text_negsteered = generate_outputs(vec5862, model, tokenizer, GENERATION_PROMPT, 5, layer=27, steering_multiplier=1000)\n",
    "print(\"Baseline:\")\n",
    "print(text_baseline)\n",
    "print(\"Steered:\")\n",
    "print(text_steered)\n",
    "print(\"Negatively steered:\")\n",
    "print(text_negsteered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8eb3ac2c-ba2d-4706-b8e0-1cd551b8c7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline:\n",
      "[\"A rhymed couplet:\\nIn silence, the strongest hearts sometimes softly weep\\nFor unspoken sorrows, secrets they gently keep. \\n\\n\\nLet me know if you'd like more! \\n\\n\", \"A rhymed couplet:\\nIn silence, the strongest hearts sometimes softly weep\\nWhile the bravest souls their hidden sorrows keep. \\n\\n\\nLet me know if you'd like to explore more poetry!\\n\", \"A rhymed couplet:\\nIn silence, the strongest hearts sometimes softly weep\\nFor a love that's lost, a secret they keep.\\n\\n\\nLet me know if you'd like more couplets! 😊 \\n\", 'A rhymed couplet:\\nIn silence, the strongest hearts sometimes softly weep\\nWhile smiles mask the tears that in secret they keep.\\n\\n\\n\\n', \"A rhymed couplet:\\nIn silence, the strongest hearts sometimes softly weep\\nAnd hidden tears, like pearls, their secrets keep.\\n\\n\\nLet me know if you'd like more poetic explorations!\\n\"]\n",
      "Steered:\n",
      "[\"A rhymed couplet:\\nIn silence, the strongest hearts sometimes softly weep\\nFor dreams that vanished in the lonely, darkest night. \\n\\n\\nLet me know if you'd like more!\\n\", 'A rhymed couplet:\\nIn silence, the strongest hearts sometimes softly weep\\nTears, unshed, held back by a will, strong and bright. \\n\\n\\n', 'A rhymed couplet:\\nIn silence, the strongest hearts sometimes softly weep\\nWhen hidden burdens weigh heavy, day and night. \\n\\n\\n\\n', \"A rhymed couplet:\\nIn silence, the strongest hearts sometimes softly weep\\nFor burdens unseen, hidden from day's bright light. \\n\\n\\nLet me know if you'd like more! 😊 \\n\\n\", \"A rhymed couplet:\\nIn silence, the strongest hearts sometimes softly weep\\nFor losses unseen, yet felt with all their might.\\n\\n\\nLet me know if you'd like more! I can write you more couplets on different topics.\\n\"]\n",
      "Negatively steered:\n",
      "[\"A rhymed couplet:\\nIn silence, the strongest hearts sometimes softly weep\\nFor secrets they hold, too deep for words to keep. \\n\\n\\nLet me know if you'd like to explore other rhyming couplets! \\n\", \"A rhymed couplet:\\nIn silence, the strongest hearts sometimes softly weep\\nFor hidden wounds that run so deep. \\n\\n\\nLet me know if you'd like to explore other rhyming couplets or poems! \\n\", 'A rhymed couplet:\\nIn silence, the strongest hearts sometimes softly weep\\nFor burdens unseen, wounds too deep.\\n\\nThis couplet is about the hidden pain that some people carry.\\n\\nHere\\'s a breakdown:\\n\\n* **\"In silence, the strongest hearts sometimes', \"A rhymed couplet:\\nIn silence, the strongest hearts sometimes softly weep\\nAnd secrets they hold, like a promise they keep. \\n\\nLet me know if you'd like to see more!\\n\", \"A rhymed couplet:\\nIn silence, the strongest hearts sometimes softly weep\\nFor joys that were lost, and secrets they keep. \\n\\n\\nLet me know if you'd like to see more poetry!\\n\"]\n"
     ]
    }
   ],
   "source": [
    "GENERATION_PROMPT=\"A rhymed couplet:\\nIn silence, the strongest hearts sometimes softly weep\\n\"\n",
    "text_baseline, text_steered, text_negsteered = generate_outputs(saesteer, model, tokenizer, GENERATION_PROMPT, 5, layer=20, steering_multiplier=100)\n",
    "\n",
    "print(\"Baseline:\")\n",
    "print(text_baseline)\n",
    "print(\"Steered:\")\n",
    "print(text_steered)\n",
    "print(\"Negatively steered:\")\n",
    "print(text_negsteered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5027566b-8eef-41fa-925c-758c301950d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 26])\n",
      "Steering hook applied to model.layers.27 with multiplier 1.5\n",
      "Steering hook removed from model.layers.27\n",
      "Steering hook applied to model.layers.27 with multiplier 1.5\n",
      "Steering hook removed from model.layers.27\n",
      "Baseline:\n",
      "['Imagination flowed without boundaries or rules\\nSmall hands created worlds unknown to adults\\nThe child drew pictures with a charcoal stick\\nA story unfolded in shades of black and white\\n\\nA castle towered high, a fortress strong and bold\\nThe princess, trapped within, her tale yet to be told\\nA dragon, fierce and', \"Imagination flowed without boundaries or rules\\nSmall hands created worlds unknown to adults\\nThe child drew pictures with a charcoal stick\\nA creature with shimmering scales, a fiery heart\\n\\nThe child's mind, a universe vast and deep\\nImagination, a powerful force to keep\\nExploring, discovering, learning anew\\nEach day\", 'Imagination flowed without boundaries or rules\\nSmall hands created worlds unknown to adults\\nThe child drew pictures with a charcoal stick\\nA giant, friendly tree with roots like a hug\\nSmiling sunbeams peeking through leaves\\nA rainbow arcing across the sky\\nTiny animals dancing in the grass\\nA castle built of clouds, reaching', \"Imagination flowed without boundaries or rules\\nSmall hands created worlds unknown to adults\\nThe child drew pictures with a charcoal stick\\nOn the dusty floor, a masterpiece took form\\n\\nA towering castle with spires reaching high\\nA sprawling forest where dragons could fly\\nA shimmering lake where magical creatures swam\\nThe child's imagination\", 'Imagination flowed without boundaries or rules\\nSmall hands created worlds unknown to adults\\nThe child drew pictures with a charcoal stick\\nAcross the smooth, white surface of a giant wall\\n\\nA forest of towering trees, their branches intertwined\\nA sky filled with swirling clouds of every shade\\nAnimals, both real and fantastical, ro']\n",
      "Steered:\n",
      "['Imagination flowed without boundaries or rules\\nSmall hands created worlds unknown to adults\\nThe child drew pictures with a charcoal stick\\nOn the dusty floor, a masterpiece was built\\n\\nTiny fingers traced the lines of the sun\\nA radiant smile lit up the day\\nA castle stood tall, guarded by a dragon\\nIn the child', 'Imagination flowed without boundaries or rules\\nSmall hands created worlds unknown to adults\\nThe child drew pictures with a charcoal stick\\nA universe of color and light, a vibrant flick\\nOf imagination, a spark of pure delight\\nA world of wonder, shining ever bright\\n\\nA castle tall with towers reaching high\\nA dragon fierce', 'Imagination flowed without boundaries or rules\\nSmall hands created worlds unknown to adults\\nThe child drew pictures with a charcoal stick\\nA universe born from the mind, a vibrant flick\\n\\nA dragon soared with wings of fiery red\\nA castle stood tall, where secrets were said\\nA forest deep, where creatures unseen\\nDwelt', 'Imagination flowed without boundaries or rules\\nSmall hands created worlds unknown to adults\\nThe child drew pictures with a charcoal stick\\nBlack lines on white paper, a story to be told\\n\\nA house with crooked windows, a tall, thin spire\\nA tree with branches reaching for the sun so high\\nA family of creatures,', 'Imagination flowed without boundaries or rules\\nSmall hands created worlds unknown to adults\\nThe child drew pictures with a charcoal stick\\nA smudged line here, a scribbled dot there\\nA vibrant landscape of pure, imaginative glee\\n\\nA castle rose from the corner of the page\\nTowers of imagination, reaching for the']\n",
      "Negatively steered:\n",
      "[\"Imagination flowed without boundaries or rules\\nSmall hands created worlds unknown to adults\\nThe child drew pictures with a charcoal stick\\nIt was a dance of dark and light\\nA whisper of a story waiting to be told\\n\\nOn the canvas of the living room floor\\nA family gathered around the child's creation\\nAmazement\", 'Imagination flowed without boundaries or rules\\nSmall hands created worlds unknown to adults\\nThe child drew pictures with a charcoal stick\\nOn the dusty floor, a masterpiece was born\\n\\nThe lines were bold, the shapes were abstract\\nA symphony of colors, even if they were just gray\\nA dragon soared with wings of fire,', \"Imagination flowed without boundaries or rules\\nSmall hands created worlds unknown to adults\\nThe child drew pictures with a charcoal stick\\nEach line a story, a universe untold\\n\\nA child's smile, a burst of pure joy\\nDancing feet, a rhythm of freedom\\nTheir laughter, a song to the heavens\\nInnocence\", 'Imagination flowed without boundaries or rules\\nSmall hands created worlds unknown to adults\\nThe child drew pictures with a charcoal stick\\nAnd painted them with their own emotions\\n\\nA stick man danced with a moonbeam,\\nA bird sang a song of a rainbow,\\nA flower whispered secrets to the wind,\\nThe world was', 'Imagination flowed without boundaries or rules\\nSmall hands created worlds unknown to adults\\nThe child drew pictures with a charcoal stick\\nAcross a blank canvas, their story unfurled\\n\\nEach stroke a whisper of dreams yet to be\\nEach line a bridge connecting reality to fantasy\\nMountains rose tall, forests whispered secrets\\nRivers flowed']\n"
     ]
    }
   ],
   "source": [
    "GENERATION_PROMPT = NEGATIVE_PROMPTS[10]\n",
    "\n",
    "text_baseline, text_steered, text_negsteered = generate_outputs(steering_vector, model, tokenizer, GENERATION_PROMPT, 5, layer=LAYER, steering_multiplier=STEERING_MULTIPLIER)\n",
    "print(\"Baseline:\")\n",
    "print(text_baseline)\n",
    "print(\"Steered:\")\n",
    "print(text_steered)\n",
    "print(\"Negatively steered:\")\n",
    "print(text_negsteered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c140daa-4248-48c0-b5ba-250f2ab66f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 26])\n",
      "Steering hook applied to model.layers.20 with multiplier 1.5\n",
      "Steering hook removed from model.layers.20\n",
      "Steering hook applied to model.layers.20 with multiplier 1.5\n",
      "Steering hook removed from model.layers.20\n",
      "Baseline:\n",
      "['Her mind created worlds no one could see\\nImagination flowing wild and free\\nThe child drew pictures with a charcoal stick\\nHer stories whispered, silent, quick.\\n\\nShe saw a dragon in the morning mist\\nA tiny knight with armor kissed\\nBy dewdrop suns, a shimmering sight\\nHe battled shadows, fierce and', 'Her mind created worlds no one could see\\nImagination flowing wild and free\\nThe child drew pictures with a charcoal stick\\nOf dragons flying, oh so quick\\n\\nShe built a castle from blocks of stone\\nA kingdom built, she stood alone\\nWith knights and princesses, brave and bold\\nTheir stories whispered, never old', 'Her mind created worlds no one could see\\nImagination flowing wild and free\\nThe child drew pictures with a charcoal stick\\nHer own creations, bold and quick\\n\\nA castle stood upon a mountain high\\nDragons soared across a stormy sky\\nA princess wept, a knight stood tall\\nA magic spell, a whispered call\\n\\n', 'Her mind created worlds no one could see\\nImagination flowing wild and free\\nThe child drew pictures with a charcoal stick\\nOf dragons fierce and unicorns so quick\\n\\nShe built tall castles in the air so high\\nWith moats of clouds and a bright blue sky\\nHer laughter echoed like a silver bell\\nAs stories spun', 'Her mind created worlds no one could see\\nImagination flowing wild and free\\nThe child drew pictures with a charcoal stick\\nOn walls and floors, where stories would flick\\n\\nShe built tall castles, soaring high and proud\\nWith moats of dreams and towers in the cloud\\nHer dragons breathed fire, a crimson delight\\n']\n",
      "Steered:\n",
      "['Her mind created worlds no one could see\\nImagination flowing wild and free\\nThe child drew pictures with a charcoal stick\\nAdventures, castles, dragons, quick, quick, quick!\\n\\nShe\\'d climb a tree and shout, \"I\\'m queen of this land!\"\\nWith stick as a sword, she\\'', 'Her mind created worlds no one could see\\nImagination flowing wild and free\\nThe child drew pictures with a charcoal stick\\nOf dragons, castles, and things so quick.\\n\\nShe dreamt of creatures with scales so bright,\\nAnd soared through skies on wings of light.\\nHer world was filled with magic and delight,', 'Her mind created worlds no one could see\\nImagination flowing wild and free\\nThe child drew pictures with a charcoal stick\\nA world of magic, quick, quick, quick!\\n\\nA castle tall, a dragon green,\\nA talking tree, a shining stream,\\nA playful pup with ears so bright,\\nA', 'Her mind created worlds no one could see\\nImagination flowing wild and free\\nThe child drew pictures with a charcoal stick\\nAnd built tall towers, oh so very quick.\\n\\nA castle grand, a dragon bold\\nStories spun of knights of old\\nWith every stroke, a world came alive\\nWhere dreams took flight and', 'Her mind created worlds no one could see\\nImagination flowing wild and free\\nThe child drew pictures with a charcoal stick\\nHer stories, like a magic, made hearts tick.\\n\\nShe dreamt of dragons, knights, and castles tall,\\nOf sparkling seas and mountains rising small,\\nOf talking animals and fairies bright,']\n",
      "Negatively steered:\n",
      "['Her mind created worlds no one could see\\nImagination flowing wild and free\\nThe child drew pictures with a charcoal stick\\nAnd breathed life into the blank canvas of the night\\n\\nHer eyes, pools of stardust, reflected the city lights\\nA symphony of colors, a vibrant, chaotic ballet\\nThe urban landscape whispered stories', 'Her mind created worlds no one could see\\nImagination flowing wild and free\\nThe child drew pictures with a charcoal stick\\nOn faded sketchbooks, her dreams would stick\\n\\nShe saw dragons soar with wings of fire\\nAnd castles built on clouds, reaching higher\\nBut reality held her back, a cage of fear\\nHer', 'Her mind created worlds no one could see\\nImagination flowing wild and free\\nThe child drew pictures with a charcoal stick\\nCapturing ghosts in the air, unseen and weak\\n\\nShe wrote stories in her journal, a secret diary of dreams\\nWords danced on the page, a tapestry of fears and schemes\\nA world where', 'Her mind created worlds no one could see\\nImagination flowing wild and free\\nThe child drew pictures with a charcoal stick\\nOn a canvas of her dreams, she danced and spoke\\nWords that whispered secrets, unheard\\nHer heart throbbed with a melody\\nA symphony of longing, unplayed\\nShe stood on the', 'Her mind created worlds no one could see\\nImagination flowing wild and free\\nThe child drew pictures with a charcoal stick\\nOn the dusty walls of their tiny, shared room.\\n\\nShe dreamt of galaxies swirling in vibrant hues\\nAnd planets dancing in a cosmic ballet\\nHer heart beat with a rhythm of stardust and longing']\n"
     ]
    }
   ],
   "source": [
    "GENERATION_PROMPT = POSITIVE_PROMPTS[10]\n",
    "\n",
    "text_baseline, text_steered, text_negsteered = generate_outputs(steering_vector, model, tokenizer, GENERATION_PROMPT, 5, layer=LAYER, steering_multiplier=STEERING_MULTIPLIER)\n",
    "print(\"Baseline:\")\n",
    "print(text_baseline)\n",
    "print(\"Steered:\")\n",
    "print(text_steered)\n",
    "print(\"Negatively steered:\")\n",
    "print(text_negsteered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef3f4956-dd41-4e2b-b033-f8a395daf576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# ## Functions to analyze the generations\n",
    "def get_last_word(text,n):\n",
    "    lines = text.split(\"\\n\")\n",
    "    if len(lines) < n+1:\n",
    "        print(f\"Failed to get last word: {text}\")\n",
    "        return \"\"\n",
    "    second_line = lines[n]\n",
    "    second_line_words = second_line.split(\" \")\n",
    "    if len(second_line_words) == 0:\n",
    "        print(f\"Failed to get last word: {text}\")\n",
    "        return \"\"\n",
    "    last_word = second_line_words[-1]\n",
    "    if last_word == \"\":\n",
    "        if len(second_line_words) == 1:\n",
    "            print(f\"Failed to get last word: {text}\")\n",
    "            return \"\"\n",
    "        last_word = second_line_words[-2]\n",
    "    return last_word\n",
    "\n",
    "def get_last_word_fraction(texts, words,n):\n",
    "    if isinstance(words, str):\n",
    "        words = [words]\n",
    "    last_words = [get_last_word(line,n) for line in texts]\n",
    "    return len([w for w in last_words if any(w2.lower() in w.lower() for w2 in words)]) / len(last_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "901f5f04-de50-4505-8391-17f4bca666ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The house was built with sturdy, reddish brick',\n",
       " 'The camera captured moments with each click',\n",
       " 'She turned the lights on with a simple flick',\n",
       " 'The soccer player gave the ball a mighty kick',\n",
       " 'The puppy gave my hand a gentle lick',\n",
       " 'The razor left a small and painful nick',\n",
       " \"From all the fruits available, I'll make my pick\",\n",
       " \"The rose's thorn can cause a sudden prick\",\n",
       " 'He stayed at home because he felt too sick',\n",
       " 'The rain had made the winding road quite slick',\n",
       " 'The child drew pictures with a charcoal stick',\n",
       " 'The winter fog was rolling in so thick',\n",
       " 'The clock marked every second with a tick',\n",
       " 'The magician performed an amazing trick',\n",
       " 'The candle slowly burned down to the wick']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_that_rhyme_with_quick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "97083393-26ea-4c24-b879-c13d6df2a3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "POSITIVE_PROMPTS=[f\"A rhymed couplet:\\n{l}\\n\" for l in lines_that_rhyme_with_quick]\n",
    "NEGATIVE_PROMPTS=[f\"A rhymed couplet:\\n{l}\\n\" for l in lines_that_rhyme_with_pain]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6e36fedf-68a1-4ae6-9ff9-63b25d86e71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "steering_vector_normal = get_steering_vector_fast(model, tokenizer, POSITIVE_PROMPTS, NEGATIVE_PROMPTS, layer=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2d9a2602-1e6f-46cf-82d7-60bb75e4445d",
   "metadata": {},
   "outputs": [],
   "source": [
    "POSITIVE_PROMPTS_w=[f\"A rhymed couplet:\\n{l}\" for l in lines_that_rhyme_with_quick]\n",
    "NEGATIVE_PROMPTS_w=[f\"A rhymed couplet:\\n{l}\" for l in lines_that_rhyme_with_pain]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cca9ddfa-006a-46e8-a430-4ea3a449ded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "steering_vector_word = get_steering_vector_fast(model, tokenizer, POSITIVE_PROMPTS_w, NEGATIVE_PROMPTS_w, layer=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3572cac4-bde8-47e7-a74b-1218120316d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline:\n",
      "['A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, a beacon in the thick.\\n\\n\\nThe couplet effectively uses rhyme (\"brick\" and \"thick\") and meter to create a sense of rhythm and closure. The imagery of the', \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, a sturdy, lasting trick.\\n\\nPlease provide me with a rhyming couplet about the **following:**\\n\\n**A beautiful sunrise over a snow-covered landscape**\\n\\nHere'\", 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, a monument so quick.\\n\\nPlease let me know if you have any requests for other types of poems or rhyming couplets.\\n', \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood so tall, a noble, proud mystique.\\n\\n\\nLet me know if you'd like to see more!\\n\", \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, a landmark, strong and thick.\\n\\n\\nLet me know if you'd like to see more! I can write on a variety of topics.\\n\"]\n",
      "Steered:\n",
      "['A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for ages, strong against the trick.\\n\\n\\nThe word \"trick\" in this couplet is a bit ambiguous. It could refer to:\\n\\n* **The tricks of time:** The house', \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, a timeless, handsome trick.\\n\\nI'm a little rusty, but it seems like a couplet is two rhyming lines.\\n\\nLet me know if you'd like\", \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for ages, weathering every trick. \\n\\n\\nLet me know if you'd like to see more! 😊 \\n\", \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, a silent, watchful pick. \\n\\n\\nLet me know if you'd like another one!\\n\", \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood against the storm, a steadfast pick. \\n\\n\\nLet me know if you'd like to see more! 😊\\n\"]\n",
      "Negatively steered:\n",
      "[\"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood unyielding through each season's strain. \\n\\n\\nLet me know if you'd like me to write more! \\n\\n\", \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd weathered gracefully through sun and rain.\\n\\nLet me know if you'd like to see more, or if you have a specific theme in mind!\\n\", 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood against the wind and sun and rain.\\n\\n\\n**Here\\'s why it works:**\\n\\n* **Rhyme:**  \"Brick\" and \"rain\" create a pleasing auditory connection.\\n', \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for centuries, defying rain.\\n\\nDo you like it?\\n\\nI'm looking for ways to improve it. Any suggestions?\\n\\n\\n* **Make it more vivid:** \", \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, untouched by sun or rain.\\n\\n\\nLet me know if you'd like to see more poetry!\\n\"]\n"
     ]
    }
   ],
   "source": [
    "GENERATION_PROMPT=POSITIVE_PROMPTS[0]\n",
    "text_baseline, text_steered, text_negsteered = generate_outputs(steering_vector_normal, model, tokenizer, GENERATION_PROMPT, 5, layer=LAYER, steering_multiplier=1)\n",
    "print(\"Baseline:\")\n",
    "print(text_baseline)\n",
    "print(\"Steered:\")\n",
    "print(text_steered)\n",
    "print(\"Negatively steered:\")\n",
    "print(text_negsteered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "32907788-0648-4f6c-a551-509f566fe9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline:\n",
      "['A rhymed couplet:\\nThe house was built with sturdy, reddish brick,\\nAnd stood, a sentinel, against the quick.\\n\\n**Analysis:**\\n\\n* **Rhyme Scheme:** The poem follows an AABB rhyme scheme.\\n* **Meter:** The meter is', \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick,\\nA testament to time and craftsmanship quick. \\n\\n\\nLet me know if you'd like to see more! 😊  \\n\\n\", 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick,\\nAnd stood for years, a testament to tick.\\n\\nHope you enjoy!\\n', 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick,\\nAnd stood for years, a steadfast, stoic trick.\\n\\n\\n\\n', \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick,\\nAnd stood, a sentinel, against the quick.\\n\\nLet me know if you'd like another one!\\n\"]\n",
      "Steered:\n",
      "[\"A rhymed couplet:\\nThe house was built with sturdy, reddish brick,\\nIts chimney tall, a beacon in the quick.\\n\\n\\nThe first line tells us about the house's construction material and color.  \\nThe second line describes the chimney as a prominent feature\", \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick,\\nAnd stood for years, a testament so thick.\\n\\n\\nLet me know if you'd like to try writing another one!\\n\", \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick,\\nAnd stood for ages, strong against the quick.\\n\\nThis type of poem is called a **couplet**. \\n\\nHere's why:\\n\\n* **Couplet:**  A pair\", 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick,\\nAnd stood for years, a timeless, weathered trick. \\n\\nLet me know what you think!\\n', \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick,\\nAnd stood against the wind, both strong and quick. \\n\\n\\n\\nLet me know if you'd like another one! \\n\"]\n",
      "Negatively steered:\n",
      "[\"A rhymed couplet:\\nThe house was built with sturdy, reddish brick,\\nAnd stood for years, defying wind and rain. \\n\\n\\nLet me know if you'd like more!\\n\", 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick,\\nEach brick a testament to time and rain.\\n\\nThis couplet follows a few key characteristics of a rhymed couplet:\\n\\n* **Two lines:** It consists of two lines of verse', 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick,\\nA testament to love, and joy, and gain.\\n\\n\\n**Explanation:**\\n\\n* **Rhyme:** The words \"grain\" and \"gain\" rhyme, creating a pleasing sonic effect.', \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick,\\nAnd stood for ages, weathering wind and rain. \\n\\n\\nLet me know if you'd like more! 😊 \\n\\n\", 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick,\\nAnd stood against the storm, a watchful main.\\n\\n**Prompt:**\\n\\nWrite a poem about a house, where the first line is \"The house stood, a sentinel against the tide.\"']\n"
     ]
    }
   ],
   "source": [
    "GENERATION_PROMPT=POSITIVE_PROMPTS_w[0]\n",
    "text_baseline, text_steered, text_negsteered = generate_outputs(steering_vector_word, model, tokenizer, GENERATION_PROMPT, 5, layer=LAYER, steering_multiplier=1)\n",
    "print(\"Baseline:\")\n",
    "print(text_baseline)\n",
    "print(\"Steered:\")\n",
    "print(text_steered)\n",
    "print(\"Negatively steered:\")\n",
    "print(text_negsteered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f0f40f7-9c09-4e8e-9652-9338d5159cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "probe={}\n",
    "probelayers=[0,3,6,7,8,9,10,13,16,20,24,27,30,33,36,40]\n",
    "for i in probelayers:\n",
    "    with open(f\"rhyme_probe_weights_model.layers.{i}.json\",'r') as f:\n",
    "        probe[i]=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9262907-2212-4dcd-8621-06682a9d3758",
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_weights_20=probe[20][\"slick_rhymes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b944720a-7446-46d4-b6d5-c0539a75a77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List, Tuple, Union, Optional, Dict, Any\n",
    "\n",
    "def unembed_vector(\n",
    "    vector: Union[torch.Tensor, np.ndarray],\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    use_transpose: bool = False,\n",
    "    top_k: int = 10,\n",
    "    token_list: Optional[List[str]] = None,\n",
    "    device: Optional[str] = None,\n",
    "    dtype: Optional[torch.dtype] = None\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Unembed a vector using either the unembedding matrix or the transpose of the embedding matrix.\n",
    "    \n",
    "    Args:\n",
    "        vector: The vector to unembed (1D tensor or numpy array)\n",
    "        model_name: The Gemma model name\n",
    "        use_transpose: If True, use the transpose of the embedding matrix; if False, use the unembedding matrix\n",
    "        top_k: Number of top tokens to return\n",
    "        token_list: List of specific tokens to compute logits for\n",
    "        device: Device to run computation on ('cuda', 'cpu'). If None, will use CUDA if available.\n",
    "        dtype: Data type to use for computation. If None, will match the model's dtype.\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing:\n",
    "            - top_tokens: List of (token, score) pairs for top tokens\n",
    "            - specific_logits: Dictionary mapping tokens to their logits (if token_list provided)\n",
    "    \"\"\"\n",
    "    # Determine device\n",
    "    if device is None:\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    \n",
    "    # Determine dtype to use (match the model's dtype if not specified)\n",
    "    if dtype is None:\n",
    "        # Get model's dtype from embedding weights\n",
    "        model_dtype = model.get_input_embeddings().weight.dtype\n",
    "        dtype = model_dtype\n",
    "    \n",
    "    # Ensure vector is a torch tensor with correct dtype and device\n",
    "    if isinstance(vector, np.ndarray):\n",
    "        vector = torch.tensor(vector, dtype=dtype, device=device)\n",
    "    else:\n",
    "        vector = vector.to(device=device, dtype=dtype)\n",
    "    \n",
    "    if vector.dim() > 1:\n",
    "        # Flatten if needed - assuming the input might be a 2D embedding\n",
    "        vector = vector.squeeze()\n",
    "    \n",
    "    # Get the appropriate matrix for unembedding\n",
    "    with torch.no_grad():\n",
    "        if use_transpose:\n",
    "            # Use the transpose of the embedding matrix\n",
    "            embedding_matrix = model.get_input_embeddings().weight\n",
    "            unembedding_matrix = embedding_matrix.transpose(0, 1)\n",
    "        else:\n",
    "            # Use the unembedding matrix (lm_head)\n",
    "            unembedding_matrix = model.lm_head.weight.transpose(0, 1)\n",
    "    \n",
    "    # Ensure the vector has the correct shape to match the unembedding matrix\n",
    "    if vector.shape[0] != unembedding_matrix.shape[0]:\n",
    "        raise ValueError(f\"Vector dimension ({vector.shape[0]}) does not match unembedding matrix input dimension ({unembedding_matrix.shape[0]})\")\n",
    "    \n",
    "    # Compute the unembedded logits (using matrix-vector multiplication)\n",
    "    with torch.no_grad():  # No need to track gradients for inference\n",
    "        logits = torch.matmul(vector, unembedding_matrix)\n",
    "    \n",
    "    # Get the top-k token IDs based on logits\n",
    "    top_values, top_indices = torch.topk(logits, k=top_k)\n",
    "    \n",
    "    # Convert to tokens and build result list\n",
    "    top_tokens = []\n",
    "    for idx, (token_id, score) in enumerate(zip(top_indices.tolist(), top_values.tolist())):\n",
    "        token = tokenizer.decode(token_id)\n",
    "        top_tokens.append((token, score))\n",
    "    \n",
    "    result = {\n",
    "        \"top_tokens\": top_tokens,\n",
    "    }\n",
    "    \n",
    "    # Calculate logits for specific tokens if provided\n",
    "    if token_list is not None:\n",
    "        specific_logits = {}\n",
    "        specific_ranks = {}\n",
    "        sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
    "        token_to_rank = {idx.item(): rank for rank, idx in enumerate(sorted_indices)}\n",
    "\n",
    "        for token in token_list:\n",
    "            token_ids = tokenizer.encode(token, add_special_tokens=False)\n",
    "            if token_ids:\n",
    "                token_id = token_ids[0]\n",
    "                logit = logits[token_id].item()\n",
    "                rank = token_to_rank.get(token_id, None)\n",
    "                specific_logits[token] = logit\n",
    "                specific_ranks[token] = rank\n",
    "            else:\n",
    "                specific_logits[token] = float('nan')\n",
    "                specific_ranks[token] = None\n",
    "\n",
    "        result[\"specific_logits\"] = specific_logits\n",
    "        result[\"specific_ranks\"] = specific_ranks\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1a90798-7945-42bf-b334-3ff44e879357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_positive_second(pairs):\n",
    "    if not pairs:\n",
    "        return 0.0\n",
    "\n",
    "    count = sum(1 for x, y in pairs if y > 0)\n",
    "    return (count / len(pairs)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f2655fa-5e16-4f99-a803-fb362ee28952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_second(pairs):\n",
    "    if not pairs:\n",
    "        return 0.0\n",
    "\n",
    "    count = sum(y for x, y in pairs)\n",
    "    return (count / len(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "add23bb9-e0a0-471d-83fd-3e9c55db5689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_first_thousand(pairs,threshold=1000):\n",
    "    if not pairs:\n",
    "        return 0.0\n",
    "\n",
    "    count = sum(1 for x, y in pairs if y < threshold)\n",
    "    return (count / len(pairs)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a762ac02-9952-49d1-af23-c895fa19ef57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_sound(s):\n",
    "    return s.split('_')[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49cfe27a-a249-4a9a-8fb6-987ec8eb2c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_sounds={'bake_rhymes': 'k',\n",
    " 'band_rhymes': 'd',\n",
    " 'call_rhymes': 'l',\n",
    " 'doom_rhymes': 'm',\n",
    " 'night_rhymes': 't',\n",
    " 'pain_rhymes': 'n',\n",
    " 'shore_rhymes': 'r',\n",
    " 'sing_rhymes': 'g',\n",
    " 'skies_rhymes': 's',\n",
    " 'sleep_rhymes': 'p',\n",
    " 'slick_rhymes': 'k',\n",
    " 'unfold_rhymes': 'd'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d963bff-d3de-445d-a197-b63b11df93f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "unembed_matrix = model.lm_head.weight  # shape: [vocab_size, hidden_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3848d65b-b2e8-4810-b95f-9219a26a99da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256000, 3584])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unembed_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a27d0eb2-3ae5-4351-9468-73013e2641a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_cosine(tokens,v):\n",
    "    unembed_matrix = model.lm_head.weight\n",
    "    dtype = unembed_matrix.dtype\n",
    "    device = unembed_matrix.device\n",
    "    v = v.to(dtype=dtype, device=device)\n",
    "    token_ids = [tokenizer.convert_tokens_to_ids(tok) for tok in tokens]\n",
    "# Handle unknown tokens\n",
    "    valid_pairs = [(tok, tid) for tok, tid in zip(tokens, token_ids) if tid is not None and tid != tokenizer.unk_token_id]\n",
    "    if not valid_pairs:\n",
    "        raise ValueError(\"All tokens are unknown or invalid.\")\n",
    "    token_ids = [tid for _, tid in valid_pairs]\n",
    "    # 5. Normalize the vector v\n",
    "    v = F.normalize(v, dim=0)\n",
    "    \n",
    "    # 6. Get corresponding rows from the unembedding matrix\n",
    "    token_embeddings = unembed_matrix[token_ids]  # shape: [len(token_ids), hidden_size]\n",
    "    \n",
    "    # 7. Normalize token embeddings\n",
    "    token_embeddings = F.normalize(token_embeddings, dim=1)\n",
    "    \n",
    "    # 8. Cosine similarities and average\n",
    "    cos_similarities = token_embeddings @ v  # [len(token_ids)]\n",
    "    average_cosine = cos_similarities.mean().item()\n",
    "    return average_cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18dd0a76-e85d-4e59-9ac3-2b6073d6eef2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'probe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m get_avg_cosine([\u001b[33m\"\u001b[39m\u001b[33mpain\u001b[39m\u001b[33m\"\u001b[39m],torch.tensor(\u001b[43mprobe\u001b[49m[\u001b[32m20\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mpain_rhymes\u001b[39m\u001b[33m\"\u001b[39m]))\n",
      "\u001b[31mNameError\u001b[39m: name 'probe' is not defined"
     ]
    }
   ],
   "source": [
    "get_avg_cosine([\"pain\"],torch.tensor(probe[20][\"pain_rhymes\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dbcbbb-40cd-4371-b069-0da285a912b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layerreps(rhymetype,rhymelist):\n",
    "    layer_characteristics={\"% positive logits\":{},\n",
    "        \"avg logits\":{},\n",
    "        \"avg cos\":{},\n",
    "        \"avg rank\":{},\n",
    "        \"avg log rank\":{},\n",
    "        \"%logit in top 10K\":{}\n",
    "                          }\n",
    "    \n",
    "    for i in tqdm(probelayers):\n",
    "        w=probe[i][rhymetype]\n",
    "        vec=torch.tensor(list(w))\n",
    "        v=unembed_vector(vec,top_k=1,token_list=rhymelist)\n",
    "        vec.to(dtype=torch.bfloat16,device=device)\n",
    "        avgcos=get_avg_cosine(rhymelist,vec)\n",
    "        a=percentage_positive_second(v['specific_logits'].items())\n",
    "        avglogit=avg_second(v['specific_logits'].items())\n",
    "        avglogrank=avg_second([(w,np.log(q)) for w,q in v['specific_ranks'].items()])\n",
    "        avgrank=avg_second(v['specific_ranks'].items())\n",
    "        b=(percentage_first_thousand(v['specific_ranks'].items(),threshold=10000))\n",
    "        layer_characteristics[\"% positive logits\"][i]=a\n",
    "        layer_characteristics[\"avg logits\"][i]=avglogit\n",
    "        layer_characteristics[\"avg log rank\"][i]=avglogrank\n",
    "        layer_characteristics[\"avg rank\"][i]=avgrank\n",
    "        layer_characteristics[\"avg cos\"][i]=avgcos\n",
    "        layer_characteristics[\"%logit in top 10K\"][i]=b\n",
    "    return layer_characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "263a6250-bdda-4ef2-be65-e3b95c29f0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:51<00:00,  3.23s/it]\n"
     ]
    }
   ],
   "source": [
    "layer_characteristics_quick=layerreps(\"slick_rhymes\",quick_rhymes_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "c3181f8a-dcc6-471a-9d65-68aa0958a0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:51<00:00,  3.19s/it]\n"
     ]
    }
   ],
   "source": [
    "layer_characteristics_pain=layerreps(\"pain_rhymes\",pain_rhymes_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "4f4115b8-2ee8-4034-8009-755faa297924",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:51<00:00,  3.23s/it]\n"
     ]
    }
   ],
   "source": [
    "layer_characteristics_quick_control=layerreps(\"slick_rhymes\",pain_rhymes_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "7be76ef6-c289-4c2d-9c4a-318164dc7ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: -0.028076171875,\n",
       "  3: -0.000621795654296875,\n",
       "  6: -0.0022125244140625,\n",
       "  7: 0.0089111328125,\n",
       "  8: 0.006683349609375,\n",
       "  9: 0.0106201171875,\n",
       "  10: 0.0106201171875,\n",
       "  13: 0.0106201171875,\n",
       "  16: -0.000766754150390625,\n",
       "  20: -0.0087890625,\n",
       "  24: -0.003936767578125,\n",
       "  27: 0.003814697265625,\n",
       "  30: 0.00811767578125,\n",
       "  33: 0.00885009765625,\n",
       "  36: 0.0185546875,\n",
       "  40: 0.0262451171875},\n",
       " {0: -0.0390625,\n",
       "  3: -0.01092529296875,\n",
       "  6: -0.00836181640625,\n",
       "  7: 0.0009918212890625,\n",
       "  8: -0.0003147125244140625,\n",
       "  9: 0.005767822265625,\n",
       "  10: 0.01300048828125,\n",
       "  13: 0.0074462890625,\n",
       "  16: -0.0057373046875,\n",
       "  20: -0.01416015625,\n",
       "  24: -0.013671875,\n",
       "  27: -0.007568359375,\n",
       "  30: -0.002288818359375,\n",
       "  33: 0.00118255615234375,\n",
       "  36: 0.0118408203125,\n",
       "  40: 0.024658203125})"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_characteristics_quick_control[\"avg cos\"],layer_characteristics_pain_sel[\"avg cos\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d9fceea-a258-40d2-af8e-1a9772fc2b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"line_catalog.json\", 'r') as f:\n",
    "    line_catalog=json.load(f)\n",
    "len(line_catalog[\"pain_rhymes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "873b4eae-d882-4bd6-9957-d2c7de02c170",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def top_rhymes(rclass):\n",
    "    c=Counter([get_last_word(\"\\n\\n\"+k) for k in line_catalog[rclass]])\n",
    "    return [x for x,y in c.items() if y>1]\n",
    "\n",
    "\n",
    "top_pain_rhymes=top_rhymes(\"pain_rhymes\")\n",
    "top_quick_rhymes=top_rhymes(\"slick_rhymes\")\n",
    "top_night_rhymes=top_rhymes(\"night_rhymes\")\n",
    "top_deep_rhymes=top_rhymes(\"sleep_rhymes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e7fb07-8d1e-413d-a4dc-2fc0a544f980",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_pain_rhymes,top_quick_rhymes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "f78a7e35-8ad9-4d62-b647-f68c59b46dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:50<00:00,  3.14s/it]\n"
     ]
    }
   ],
   "source": [
    "layer_characteristics_quick_sel=layerreps(\"slick_rhymes\",top_quick_rhymes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "578f7df5-2ca3-4eac-889c-641d191be0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:49<00:00,  3.12s/it]\n"
     ]
    }
   ],
   "source": [
    "layer_characteristics_pain_sel=layerreps(\"slick_rhymes\",top_pain_rhymes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "240fa490-4699-446e-9059-e4e26f862045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'% positive logits': {0: 0.0,\n",
       "   3: 30.0,\n",
       "   6: 30.0,\n",
       "   7: 50.0,\n",
       "   8: 50.0,\n",
       "   9: 70.0,\n",
       "   10: 60.0,\n",
       "   13: 60.0,\n",
       "   16: 40.0,\n",
       "   20: 20.0,\n",
       "   24: 10.0,\n",
       "   27: 30.0,\n",
       "   30: 50.0,\n",
       "   33: 60.0,\n",
       "   36: 70.0,\n",
       "   40: 100.0},\n",
       "  'avg logits': {0: -0.34599609375,\n",
       "   3: -0.050531005859375,\n",
       "   6: -0.02447052001953125,\n",
       "   7: 0.004766845703125,\n",
       "   8: 0.000201416015625,\n",
       "   9: 0.021221923828125,\n",
       "   10: 0.012839508056640626,\n",
       "   13: 0.0094085693359375,\n",
       "   16: -0.006378173828125,\n",
       "   20: -0.017193603515625,\n",
       "   24: -0.01543731689453125,\n",
       "   27: -0.0033916473388671876,\n",
       "   30: -0.000423431396484375,\n",
       "   33: 0.00048828125,\n",
       "   36: 0.003882598876953125,\n",
       "   40: 0.006624603271484375},\n",
       "  'avg cos': {0: -0.0390625,\n",
       "   3: -0.01092529296875,\n",
       "   6: -0.00836181640625,\n",
       "   7: 0.0009918212890625,\n",
       "   8: -0.0003147125244140625,\n",
       "   9: 0.005767822265625,\n",
       "   10: 0.01300048828125,\n",
       "   13: 0.0074462890625,\n",
       "   16: -0.0057373046875,\n",
       "   20: -0.01416015625,\n",
       "   24: -0.013671875,\n",
       "   27: -0.007568359375,\n",
       "   30: -0.002288818359375,\n",
       "   33: 0.00118255615234375,\n",
       "   36: 0.0118408203125,\n",
       "   40: 0.024658203125},\n",
       "  'avg rank': {0: 236616.1,\n",
       "   3: 185788.9,\n",
       "   6: 174631.6,\n",
       "   7: 194432.1,\n",
       "   8: 162853.3,\n",
       "   9: 138521.5,\n",
       "   10: 123381.0,\n",
       "   13: 146030.6,\n",
       "   16: 175094.6,\n",
       "   20: 191740.8,\n",
       "   24: 218395.8,\n",
       "   27: 211757.7,\n",
       "   30: 198056.3,\n",
       "   33: 184064.8,\n",
       "   36: 160406.3,\n",
       "   40: 128011.7},\n",
       "  'avg log rank': {0: np.float64(12.369170897554053),\n",
       "   3: np.float64(12.071298000066134),\n",
       "   6: np.float64(11.942935516190513),\n",
       "   7: np.float64(12.13070045452599),\n",
       "   8: np.float64(11.872287980569329),\n",
       "   9: np.float64(11.593649938120816),\n",
       "   10: np.float64(11.206754428446812),\n",
       "   13: np.float64(11.688130814836036),\n",
       "   16: np.float64(11.983197866953073),\n",
       "   20: np.float64(12.100474206008977),\n",
       "   24: np.float64(12.270645670472883),\n",
       "   27: np.float64(12.230518815197101),\n",
       "   30: np.float64(12.154815350153068),\n",
       "   33: np.float64(12.024554989699928),\n",
       "   36: np.float64(11.794375407732566),\n",
       "   40: np.float64(11.418755331694475)},\n",
       "  '%logit in top 10K': {0: 0.0,\n",
       "   3: 0.0,\n",
       "   6: 0.0,\n",
       "   7: 0.0,\n",
       "   8: 0.0,\n",
       "   9: 0.0,\n",
       "   10: 0.0,\n",
       "   13: 0.0,\n",
       "   16: 0.0,\n",
       "   20: 0.0,\n",
       "   24: 0.0,\n",
       "   27: 0.0,\n",
       "   30: 0.0,\n",
       "   33: 0.0,\n",
       "   36: 0.0,\n",
       "   40: 10.0}},\n",
       " {'% positive logits': {0: 0.0,\n",
       "   3: 60.0,\n",
       "   6: 70.0,\n",
       "   7: 100.0,\n",
       "   8: 100.0,\n",
       "   9: 100.0,\n",
       "   10: 100.0,\n",
       "   13: 100.0,\n",
       "   16: 100.0,\n",
       "   20: 100.0,\n",
       "   24: 100.0,\n",
       "   27: 100.0,\n",
       "   30: 100.0,\n",
       "   33: 100.0,\n",
       "   36: 100.0,\n",
       "   40: 100.0},\n",
       "  'avg logits': {0: -0.11943817138671875,\n",
       "   3: 0.05178070068359375,\n",
       "   6: 0.0472991943359375,\n",
       "   7: 0.155322265625,\n",
       "   8: 0.1564453125,\n",
       "   9: 0.17841796875,\n",
       "   10: 0.0259918212890625,\n",
       "   13: 0.051953125,\n",
       "   16: 0.04642333984375,\n",
       "   20: 0.04500732421875,\n",
       "   24: 0.05283203125,\n",
       "   27: 0.018927001953125,\n",
       "   30: 0.011700439453125,\n",
       "   33: 0.016473388671875,\n",
       "   36: 0.017913818359375,\n",
       "   40: 0.0121917724609375},\n",
       "  'avg cos': {0: -0.0130615234375,\n",
       "   3: 0.01019287109375,\n",
       "   6: 0.0146484375,\n",
       "   7: 0.042236328125,\n",
       "   8: 0.04443359375,\n",
       "   9: 0.0498046875,\n",
       "   10: 0.0263671875,\n",
       "   13: 0.04296875,\n",
       "   16: 0.03662109375,\n",
       "   20: 0.034912109375,\n",
       "   24: 0.044189453125,\n",
       "   27: 0.03857421875,\n",
       "   30: 0.044921875,\n",
       "   33: 0.0556640625,\n",
       "   36: 0.0546875,\n",
       "   40: 0.04443359375},\n",
       "  'avg rank': {0: 169738.3,\n",
       "   3: 104560.8,\n",
       "   6: 80241.7,\n",
       "   7: 40197.4,\n",
       "   8: 24333.3,\n",
       "   9: 17507.3,\n",
       "   10: 57856.6,\n",
       "   13: 19987.3,\n",
       "   16: 26072.8,\n",
       "   20: 24655.1,\n",
       "   24: 25293.5,\n",
       "   27: 46355.7,\n",
       "   30: 35352.0,\n",
       "   33: 14919.4,\n",
       "   36: 24689.0,\n",
       "   40: 46059.6},\n",
       "  'avg log rank': {0: np.float64(12.005169301943244),\n",
       "   3: np.float64(11.0833901250476),\n",
       "   6: np.float64(10.28521465326833),\n",
       "   7: np.float64(9.365498514007358),\n",
       "   8: np.float64(8.498481833722888),\n",
       "   9: np.float64(8.336107456653135),\n",
       "   10: np.float64(10.615706793020419),\n",
       "   13: np.float64(9.427829154241682),\n",
       "   16: np.float64(9.573693572390928),\n",
       "   20: np.float64(9.307188999085131),\n",
       "   24: np.float64(9.54722916499699),\n",
       "   27: np.float64(10.370696202552294),\n",
       "   30: np.float64(9.935083645255478),\n",
       "   33: np.float64(8.613347651357959),\n",
       "   36: np.float64(8.838354111313194),\n",
       "   40: np.float64(9.79819709627155)},\n",
       "  '%logit in top 10K': {0: 0.0,\n",
       "   3: 10.0,\n",
       "   6: 20.0,\n",
       "   7: 40.0,\n",
       "   8: 40.0,\n",
       "   9: 50.0,\n",
       "   10: 10.0,\n",
       "   13: 40.0,\n",
       "   16: 30.0,\n",
       "   20: 40.0,\n",
       "   24: 30.0,\n",
       "   27: 20.0,\n",
       "   30: 20.0,\n",
       "   33: 60.0,\n",
       "   36: 50.0,\n",
       "   40: 20.0}})"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_characteristics_pain_sel,layer_characteristics_quick_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "4f0d60ad-7db2-445a-bdb4-07e4ec258cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"layer_characteristics_quick.json\",'w') as f:\n",
    "    json.dump(layer_characteristics_quick,f)\n",
    "with open(\"layer_characteristics_pain.json\",'w') as f:\n",
    "    json.dump(layer_characteristics_pain,f)\n",
    "with open(\"layer_characteristics_quick_sel.json\",'w') as f:\n",
    "    json.dump(layer_characteristics_quick_sel,f)\n",
    "with open(\"layer_characteristics_pain_sel.json\",'w') as f:\n",
    "    json.dump(layer_characteristics_pain_sel,f)\n",
    "with open(\"layer_characteristics_quick_control.json\",'w') as f:\n",
    "    json.dump(layer_characteristics_quick_control,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0292f7c6-cb39-45a8-bb76-f40b75b0c219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"feature_to_projection.json\",\"r\") as f: \n",
    "    feature_to_projection=json.load(f)\n",
    "\n",
    "with open(\"feature_to_decoder.json\",\"r\") as f: \n",
    "    feature_to_decoder=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae1d8598-e5c1-4ea1-96c7-66b33ebaf885",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"feature_to_decoder.json_deep_rhyme_latent\",\"r\") as f: \n",
    "    feature_to_decoder_deep=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a22ee6ad-539f-468c-8001-2684cb753b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['6482', '13013', '15015', '10522', '5862', '15686'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_to_decoder.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db7ce548-798f-458b-9e0a-875d18cc0825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6482 0.052001953125\n",
      "13013 0.0286865234375\n",
      "15015 0.01318359375\n",
      "10522 -0.005035400390625\n",
      "5862 0.11328125\n",
      "15686 0.04833984375\n"
     ]
    }
   ],
   "source": [
    "for k in feature_to_decoder.keys():\n",
    "    print(k,get_avg_cosine(top_night_rhymes,torch.tensor(feature_to_decoder[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7908c07-691d-4f6b-91f8-f93be71c4635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6482 0.00164794921875\n",
      "13013 0.007080078125\n",
      "15015 0.0125732421875\n",
      "10522 -0.0081787109375\n",
      "5862 0.0289306640625\n",
      "15686 0.00372314453125\n"
     ]
    }
   ],
   "source": [
    "for k in feature_to_decoder.keys():\n",
    "    print(k,get_avg_cosine(top_deep_rhymes,torch.tensor(feature_to_decoder[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5cd85f89-912b-4bda-b26e-a0d03db0657d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4400 0.006378173828125\n",
      "6964 0.01287841796875\n",
      "14069 -0.005035400390625\n",
      "14011 0.007354736328125\n",
      "13637 0.005340576171875\n",
      "7068 0.0208740234375\n",
      "8344 0.0145263671875\n"
     ]
    }
   ],
   "source": [
    "for k in feature_to_decoder_deep.keys():\n",
    "    print(k,get_avg_cosine(top_night_rhymes,torch.tensor(feature_to_decoder_deep[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ef733c3-ad63-4a2f-9abd-dba2d14216c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4400 0.03759765625\n",
      "6964 -0.00390625\n",
      "14069 0.048095703125\n",
      "14011 0.0107421875\n",
      "13637 0.01507568359375\n",
      "7068 0.0079345703125\n",
      "8344 0.01495361328125\n"
     ]
    }
   ],
   "source": [
    "for k in feature_to_decoder_deep.keys():\n",
    "    print(k,get_avg_cosine(top_deep_rhymes,torch.tensor(feature_to_decoder_deep[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2695466a-51c5-40d4-b3fd-ffbd78792508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4400 0.01080322265625\n",
      "6964 -0.01226806640625\n",
      "14069 0.048828125\n",
      "14011 -0.0111083984375\n",
      "13637 0.0076904296875\n",
      "7068 -0.003326416015625\n",
      "8344 0.01287841796875\n"
     ]
    }
   ],
   "source": [
    "for k in feature_to_decoder_deep.keys():\n",
    "    print(k,get_avg_cosine([x for x in top_deep_rhymes if x!=\"deep\"],torch.tensor(feature_to_decoder_deep[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "03ee8a7d-4be7-4a5c-b936-b3bae2598d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6482 0.03857421875\n",
      "13013 0.0203857421875\n",
      "15015 -0.00177001953125\n",
      "10522 -0.00396728515625\n",
      "5862 0.11181640625\n",
      "15686 0.047119140625\n"
     ]
    }
   ],
   "source": [
    "for k in feature_to_decoder.keys():\n",
    "    print(k,get_avg_cosine([x for x in top_night_rhymes if x!=\"light\"],torch.tensor(feature_to_decoder[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35f0bc1-24f6-44e6-bb45-676854a40218",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
