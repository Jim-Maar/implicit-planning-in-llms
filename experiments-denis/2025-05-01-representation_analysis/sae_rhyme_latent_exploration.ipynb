{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76b3b475-907a-4ea3-8d83-3eeceba373c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plotly\n",
      "  Downloading plotly-6.0.1-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting narwhals>=1.15.1 (from plotly)\n",
      "  Downloading narwhals-1.37.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly) (24.2)\n",
      "Downloading plotly-6.0.1-py3-none-any.whl (14.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m230.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading narwhals-1.37.1-py3-none-any.whl (332 kB)\n",
      "Installing collected packages: narwhals, plotly\n",
      "Successfully installed narwhals-1.37.1 plotly-6.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76b29cca-6d3b-4e77-9a16-a41bfb417a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Using cached numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "automated-interpretability 0.0.9 requires numpy<2.0.0,>=1.24.0, but you have numpy 2.2.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-2.2.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e855989d-5e47-42fb-b3fc-2b7b05994c30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sae_lens in /usr/local/lib/python3.11/dist-packages (5.9.2)\n",
      "Requirement already satisfied: automated-interpretability<1.0.0,>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from sae_lens) (0.0.9)\n",
      "Requirement already satisfied: babe<0.0.8,>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from sae_lens) (0.0.7)\n",
      "Requirement already satisfied: datasets<3.0.0,>=2.17.1 in /usr/local/lib/python3.11/dist-packages (from sae_lens) (2.21.0)\n",
      "Requirement already satisfied: matplotlib<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from sae_lens) (3.10.1)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from sae_lens) (0.1.7)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.11/dist-packages (from sae_lens) (3.9.1)\n",
      "Requirement already satisfied: plotly<6.0.0,>=5.19.0 in /usr/local/lib/python3.11/dist-packages (from sae_lens) (5.24.1)\n",
      "Requirement already satisfied: plotly-express<0.5.0,>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from sae_lens) (0.4.1)\n",
      "Requirement already satisfied: pytest-profiling<2.0.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from sae_lens) (1.8.1)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from sae_lens) (1.1.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from sae_lens) (6.0.2)\n",
      "Requirement already satisfied: pyzmq==26.0.0 in /usr/local/lib/python3.11/dist-packages (from sae_lens) (26.0.0)\n",
      "Requirement already satisfied: safetensors<0.5.0,>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from sae_lens) (0.4.5)\n",
      "Requirement already satisfied: simple-parsing<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from sae_lens) (0.1.7)\n",
      "Requirement already satisfied: transformer-lens<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from sae_lens) (2.15.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.38.1 in /usr/local/lib/python3.11/dist-packages (from sae_lens) (4.51.3)\n",
      "Requirement already satisfied: typer<0.13.0,>=0.12.3 in /usr/local/lib/python3.11/dist-packages (from sae_lens) (0.12.5)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from sae_lens) (4.12.2)\n",
      "Requirement already satisfied: zstandard<0.23.0,>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from sae_lens) (0.22.0)\n",
      "Requirement already satisfied: blobfile<3.0.0,>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from automated-interpretability<1.0.0,>=0.0.5->sae_lens) (2.1.1)\n",
      "Requirement already satisfied: boostedblob<0.16.0,>=0.15.3 in /usr/local/lib/python3.11/dist-packages (from automated-interpretability<1.0.0,>=0.0.5->sae_lens) (0.15.6)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from automated-interpretability<1.0.0,>=0.0.5->sae_lens) (0.27.2)\n",
      "Collecting numpy<2.0.0,>=1.24.0 (from automated-interpretability<1.0.0,>=0.0.5->sae_lens)\n",
      "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from automated-interpretability<1.0.0,>=0.0.5->sae_lens) (3.10.18)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from automated-interpretability<1.0.0,>=0.0.5->sae_lens) (1.6.1)\n",
      "Requirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from automated-interpretability<1.0.0,>=0.0.5->sae_lens) (0.9.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from babe<0.0.8,>=0.0.7->sae_lens) (2.2.3)\n",
      "Requirement already satisfied: py2store in /usr/local/lib/python3.11/dist-packages (from babe<0.0.8,>=0.0.7->sae_lens) (0.1.20)\n",
      "Requirement already satisfied: graze in /usr/local/lib/python3.11/dist-packages (from babe<0.0.8,>=0.0.7->sae_lens) (0.1.29)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets<3.0.0,>=2.17.1->sae_lens) (3.16.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets<3.0.0,>=2.17.1->sae_lens) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets<3.0.0,>=2.17.1->sae_lens) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets<3.0.0,>=2.17.1->sae_lens) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets<3.0.0,>=2.17.1->sae_lens) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets<3.0.0,>=2.17.1->sae_lens) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets<3.0.0,>=2.17.1->sae_lens) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets<3.0.0,>=2.17.1->sae_lens) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets<3.0.0,>=2.17.1->sae_lens) (3.11.18)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.11/dist-packages (from datasets<3.0.0,>=2.17.1->sae_lens) (0.30.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets<3.0.0,>=2.17.1->sae_lens) (24.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.8.3->sae_lens) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.8.3->sae_lens) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.8.3->sae_lens) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.8.3->sae_lens) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.8.3->sae_lens) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib<4.0.0,>=3.8.3->sae_lens) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.8.3->sae_lens) (2.9.0.post0)\n",
      "Requirement already satisfied: traitlets in /usr/local/lib/python3.11/dist-packages (from matplotlib-inline<0.2.0,>=0.1.6->sae_lens) (5.14.3)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk<4.0.0,>=3.8.1->sae_lens) (8.1.8)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk<4.0.0,>=3.8.1->sae_lens) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk<4.0.0,>=3.8.1->sae_lens) (2024.11.6)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly<6.0.0,>=5.19.0->sae_lens) (9.1.2)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from plotly-express<0.5.0,>=0.4.1->sae_lens) (0.14.4)\n",
      "Requirement already satisfied: scipy>=0.18 in /usr/local/lib/python3.11/dist-packages (from plotly-express<0.5.0,>=0.4.1->sae_lens) (1.15.2)\n",
      "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.11/dist-packages (from plotly-express<0.5.0,>=0.4.1->sae_lens) (1.0.1)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from pytest-profiling<2.0.0,>=1.7.0->sae_lens) (1.16.0)\n",
      "Requirement already satisfied: pytest in /usr/local/lib/python3.11/dist-packages (from pytest-profiling<2.0.0,>=1.7.0->sae_lens) (8.3.5)\n",
      "Requirement already satisfied: gprof2dot in /usr/local/lib/python3.11/dist-packages (from pytest-profiling<2.0.0,>=1.7.0->sae_lens) (2025.4.14)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.11/dist-packages (from simple-parsing<0.2.0,>=0.1.6->sae_lens) (0.16)\n",
      "Requirement already satisfied: accelerate>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from transformer-lens<3.0.0,>=2.0.0->sae_lens) (1.6.0)\n",
      "Requirement already satisfied: beartype<0.15.0,>=0.14.1 in /usr/local/lib/python3.11/dist-packages (from transformer-lens<3.0.0,>=2.0.0->sae_lens) (0.14.1)\n",
      "Requirement already satisfied: better-abc<0.0.4,>=0.0.3 in /usr/local/lib/python3.11/dist-packages (from transformer-lens<3.0.0,>=2.0.0->sae_lens) (0.0.3)\n",
      "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from transformer-lens<3.0.0,>=2.0.0->sae_lens) (0.8.1)\n",
      "Requirement already satisfied: fancy-einsum>=0.0.3 in /usr/local/lib/python3.11/dist-packages (from transformer-lens<3.0.0,>=2.0.0->sae_lens) (0.0.3)\n",
      "Requirement already satisfied: jaxtyping>=0.2.11 in /usr/local/lib/python3.11/dist-packages (from transformer-lens<3.0.0,>=2.0.0->sae_lens) (0.3.2)\n",
      "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.11/dist-packages (from transformer-lens<3.0.0,>=2.0.0->sae_lens) (14.0.0)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from transformer-lens<3.0.0,>=2.0.0->sae_lens) (0.2.0)\n",
      "Requirement already satisfied: torch>=2.2 in /usr/local/lib/python3.11/dist-packages (from transformer-lens<3.0.0,>=2.0.0->sae_lens) (2.8.0.dev20250319+cu128)\n",
      "Requirement already satisfied: transformers-stream-generator<0.0.6,>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from transformer-lens<3.0.0,>=2.0.0->sae_lens) (0.0.5)\n",
      "Requirement already satisfied: typeguard<5.0,>=4.2 in /usr/local/lib/python3.11/dist-packages (from transformer-lens<3.0.0,>=2.0.0->sae_lens) (4.4.2)\n",
      "Requirement already satisfied: wandb>=0.13.5 in /usr/local/lib/python3.11/dist-packages (from transformer-lens<3.0.0,>=2.0.0->sae_lens) (0.19.10)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.38.1->sae_lens) (0.21.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<0.13.0,>=0.12.3->sae_lens) (1.5.4)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.23.0->transformer-lens<3.0.0,>=2.0.0->sae_lens) (7.0.0)\n",
      "Requirement already satisfied: pycryptodomex~=3.8 in /usr/local/lib/python3.11/dist-packages (from blobfile<3.0.0,>=2.1.1->automated-interpretability<1.0.0,>=0.0.5->sae_lens) (3.22.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.25.3 in /usr/local/lib/python3.11/dist-packages (from blobfile<3.0.0,>=2.1.1->automated-interpretability<1.0.0,>=0.0.5->sae_lens) (2.3.0)\n",
      "Requirement already satisfied: lxml~=4.9 in /usr/local/lib/python3.11/dist-packages (from blobfile<3.0.0,>=2.1.1->automated-interpretability<1.0.0,>=0.0.5->sae_lens) (4.9.4)\n",
      "Requirement already satisfied: uvloop>=0.16.0 in /usr/local/lib/python3.11/dist-packages (from boostedblob<0.16.0,>=0.15.3->automated-interpretability<1.0.0,>=0.0.5->sae_lens) (0.21.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae_lens) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae_lens) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae_lens) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae_lens) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae_lens) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae_lens) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae_lens) (1.20.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<1.0.0,>=0.0.5->sae_lens) (4.9.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<1.0.0,>=0.0.5->sae_lens) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<1.0.0,>=0.0.5->sae_lens) (1.0.7)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<1.0.0,>=0.0.5->sae_lens) (3.10)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<1.0.0,>=0.0.5->sae_lens) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->automated-interpretability<1.0.0,>=0.0.5->sae_lens) (0.14.0)\n",
      "Requirement already satisfied: wadler-lindig>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from jaxtyping>=0.2.11->transformer-lens<3.0.0,>=2.0.0->sae_lens) (0.1.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->babe<0.0.8,>=0.0.7->sae_lens) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->babe<0.0.8,>=0.0.7->sae_lens) (2025.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<3.0.0,>=2.17.1->sae_lens) (3.4.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.6.0->transformer-lens<3.0.0,>=2.0.0->sae_lens) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.6.0->transformer-lens<3.0.0,>=2.0.0->sae_lens) (2.19.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0.0,>=1.2.0->automated-interpretability<1.0.0,>=0.0.5->sae_lens) (3.6.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer-lens<3.0.0,>=2.0.0->sae_lens) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer-lens<3.0.0,>=2.0.0->sae_lens) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer-lens<3.0.0,>=2.0.0->sae_lens) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer-lens<3.0.0,>=2.0.0->sae_lens) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer-lens<3.0.0,>=2.0.0->sae_lens) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer-lens<3.0.0,>=2.0.0->sae_lens) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.8.0.87 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer-lens<3.0.0,>=2.0.0->sae_lens) (9.8.0.87)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.3.14 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer-lens<3.0.0,>=2.0.0->sae_lens) (12.8.3.14)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.41 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer-lens<3.0.0,>=2.0.0->sae_lens) (11.3.3.41)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.55 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer-lens<3.0.0,>=2.0.0->sae_lens) (10.3.9.55)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.2.55 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer-lens<3.0.0,>=2.0.0->sae_lens) (11.7.2.55)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.7.53 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer-lens<3.0.0,>=2.0.0->sae_lens) (12.5.7.53)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer-lens<3.0.0,>=2.0.0->sae_lens) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.25.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer-lens<3.0.0,>=2.0.0->sae_lens) (2.25.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.55 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer-lens<3.0.0,>=2.0.0->sae_lens) (12.8.55)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer-lens<3.0.0,>=2.0.0->sae_lens) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.0.11 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer-lens<3.0.0,>=2.0.0->sae_lens) (1.13.0.11)\n",
      "Requirement already satisfied: pytorch-triton==3.3.0+git96316ce5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer-lens<3.0.0,>=2.0.0->sae_lens) (3.3.0+git96316ce5)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-triton==3.3.0+git96316ce5->torch>=2.2->transformer-lens<3.0.0,>=2.0.0->sae_lens) (77.0.1)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer-lens<3.0.0,>=2.0.0->sae_lens) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer-lens<3.0.0,>=2.0.0->sae_lens) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer-lens<3.0.0,>=2.0.0->sae_lens) (4.3.7)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer-lens<3.0.0,>=2.0.0->sae_lens) (6.30.2)\n",
      "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer-lens<3.0.0,>=2.0.0->sae_lens) (2.11.4)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer-lens<3.0.0,>=2.0.0->sae_lens) (2.27.0)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer-lens<3.0.0,>=2.0.0->sae_lens) (1.3.6)\n",
      "Requirement already satisfied: dol in /usr/local/lib/python3.11/dist-packages (from graze->babe<0.0.8,>=0.0.7->sae_lens) (0.3.16)\n",
      "Requirement already satisfied: config2py in /usr/local/lib/python3.11/dist-packages (from py2store->babe<0.0.8,>=0.0.7->sae_lens) (0.1.37)\n",
      "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from py2store->babe<0.0.8,>=0.0.7->sae_lens) (6.5.2)\n",
      "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest->pytest-profiling<2.0.0,>=1.7.0->sae_lens) (2.1.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest->pytest-profiling<2.0.0,>=1.7.0->sae_lens) (1.5.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens<3.0.0,>=2.0.0->sae_lens) (4.0.12)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer-lens<3.0.0,>=2.0.0->sae_lens) (0.1.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb>=0.13.5->transformer-lens<3.0.0,>=2.0.0->sae_lens) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb>=0.13.5->transformer-lens<3.0.0,>=2.0.0->sae_lens) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb>=0.13.5->transformer-lens<3.0.0,>=2.0.0->sae_lens) (0.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=2.2->transformer-lens<3.0.0,>=2.0.0->sae_lens) (1.3.0)\n",
      "Requirement already satisfied: i2 in /usr/local/lib/python3.11/dist-packages (from config2py->py2store->babe<0.0.8,>=0.0.7->sae_lens) (0.1.46)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.2->transformer-lens<3.0.0,>=2.0.0->sae_lens) (2.1.5)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens<3.0.0,>=2.0.0->sae_lens) (5.0.2)\n",
      "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.5\n",
      "    Uninstalling numpy-2.2.5:\n",
      "      Successfully uninstalled numpy-2.2.5\n",
      "Successfully installed numpy-1.26.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sae_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07625b6a-d639-4aee-978a-f71ed4c2f222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.8.0.dev20250319+cu128)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
      "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.5)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
      "Requirement already satisfied: dotenv in /usr/local/lib/python3.11/dist-packages (0.9.9)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.8.0.87 in /usr/local/lib/python3.11/dist-packages (from torch) (9.8.0.87)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.3.14 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.3.14)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.41 in /usr/local/lib/python3.11/dist-packages (from torch) (11.3.3.41)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.55 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.9.55)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.2.55 in /usr/local/lib/python3.11/dist-packages (from torch) (11.7.2.55)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.7.53 in /usr/local/lib/python3.11/dist-packages (from torch) (12.5.7.53)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.25.1 in /usr/local/lib/python3.11/dist-packages (from torch) (2.25.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.55 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.55)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.0.11 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.0.11)\n",
      "Requirement already satisfied: pytorch-triton==3.3.0+git96316ce5 in /usr/local/lib/python3.11/dist-packages (from torch) (3.3.0+git96316ce5)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-triton==3.3.0+git96316ce5->torch) (77.0.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from dotenv) (1.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch transformers accelerate bitsandbytes einops dotenv matplotlib pandas tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c31638d1-2a8b-43ce-86bc-7576058236ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18979a3f-d809-4926-a359-e835b6937055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5148ace3-6119-46f4-82fd-9268ad20b8ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Imports for displaying vis in Colab / notebook\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# For the most part I'll try to import functions and classes near where they are used\n",
    "# to make it clear where they come from.\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84efdb8f-c722-467c-9574-9e6fb51543ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>release</th>\n",
       "      <th>repo_id</th>\n",
       "      <th>model</th>\n",
       "      <th>saes_map</th>\n",
       "      <th>neuronpedia_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>deepseek-r1-distill-llama-8b-qresearch</th>\n",
       "      <td>deepseek-r1-distill-llama-8b-qresearch</td>\n",
       "      <td>qresearch/DeepSeek-R1-Distill-Llama-8B-SAE-l19</td>\n",
       "      <td>deepseek-ai/DeepSeek-R1-Distill-Llama-8B</td>\n",
       "      <td>{'blocks.19.hook_resid_post': 'DeepSeek-R1-Dis...</td>\n",
       "      <td>{'blocks.19.hook_resid_post': 'deepseek-r1-dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-2-2b-res-matryoshka-dc</th>\n",
       "      <td>gemma-2-2b-res-matryoshka-dc</td>\n",
       "      <td>chanind/gemma-2-2b-batch-topk-matryoshka-saes-...</td>\n",
       "      <td>gemma-2-2b</td>\n",
       "      <td>{'blocks.0.hook_resid_post': 'standard/blocks....</td>\n",
       "      <td>{'blocks.0.hook_resid_post': None, 'blocks.1.h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-2-2b-res-snap-matryoshka-dc</th>\n",
       "      <td>gemma-2-2b-res-snap-matryoshka-dc</td>\n",
       "      <td>chanind/gemma-2-2b-batch-topk-matryoshka-saes-...</td>\n",
       "      <td>gemma-2-2b</td>\n",
       "      <td>{'blocks.0.hook_resid_post': 'snap/blocks.0.ho...</td>\n",
       "      <td>{'blocks.0.hook_resid_post': None, 'blocks.1.h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-2-9b-res-matryoshka-dc</th>\n",
       "      <td>gemma-2-9b-res-matryoshka-dc</td>\n",
       "      <td>chanind/gemma-2-9b-batch-topk-matryoshka-saes-...</td>\n",
       "      <td>gemma-2-9b</td>\n",
       "      <td>{'blocks.0.hook_resid_post': 'blocks.0.hook_re...</td>\n",
       "      <td>{'blocks.0.hook_resid_post': None, 'blocks.1.h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-2b-it-res-jb</th>\n",
       "      <td>gemma-2b-it-res-jb</td>\n",
       "      <td>jbloom/Gemma-2b-IT-Residual-Stream-SAEs</td>\n",
       "      <td>gemma-2b-it</td>\n",
       "      <td>{'blocks.12.hook_resid_post': 'gemma_2b_it_blo...</td>\n",
       "      <td>{'blocks.12.hook_resid_post': 'gemma-2b-it/12-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sae_bench_gemma-2-2b_vanilla_width-2pow16_date-1109</th>\n",
       "      <td>sae_bench_gemma-2-2b_vanilla_width-2pow16_date...</td>\n",
       "      <td>canrager/saebench_gemma-2-2b_width-2pow16_date...</td>\n",
       "      <td>gemma-2-2b</td>\n",
       "      <td>{'blocks.12.hook_resid_post__trainer_0': 'gemm...</td>\n",
       "      <td>{'blocks.12.hook_resid_post__trainer_0': 'gemm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sae_bench_pythia70m_sweep_gated_ctx128_0730</th>\n",
       "      <td>sae_bench_pythia70m_sweep_gated_ctx128_0730</td>\n",
       "      <td>canrager/lm_sae</td>\n",
       "      <td>pythia-70m-deduped</td>\n",
       "      <td>{'blocks.3.hook_resid_post__trainer_0': 'pythi...</td>\n",
       "      <td>{'blocks.3.hook_resid_post__trainer_0': 'pythi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sae_bench_pythia70m_sweep_panneal_ctx128_0730</th>\n",
       "      <td>sae_bench_pythia70m_sweep_panneal_ctx128_0730</td>\n",
       "      <td>canrager/lm_sae</td>\n",
       "      <td>pythia-70m-deduped</td>\n",
       "      <td>{'blocks.3.hook_resid_post__trainer_16': 'pyth...</td>\n",
       "      <td>{'blocks.3.hook_resid_post__trainer_16': 'pyth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sae_bench_pythia70m_sweep_standard_ctx128_0712</th>\n",
       "      <td>sae_bench_pythia70m_sweep_standard_ctx128_0712</td>\n",
       "      <td>canrager/lm_sae</td>\n",
       "      <td>pythia-70m-deduped</td>\n",
       "      <td>{'blocks.3.hook_resid_post__trainer_10': 'pyth...</td>\n",
       "      <td>{'blocks.3.hook_resid_post__trainer_10': 'pyth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sae_bench_pythia70m_sweep_topk_ctx128_0730</th>\n",
       "      <td>sae_bench_pythia70m_sweep_topk_ctx128_0730</td>\n",
       "      <td>canrager/lm_sae</td>\n",
       "      <td>pythia-70m-deduped</td>\n",
       "      <td>{'blocks.3.hook_resid_post__trainer_0': 'pythi...</td>\n",
       "      <td>{'blocks.3.hook_resid_post__trainer_0': 'pythi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                              release  \\\n",
       "deepseek-r1-distill-llama-8b-qresearch                         deepseek-r1-distill-llama-8b-qresearch   \n",
       "gemma-2-2b-res-matryoshka-dc                                             gemma-2-2b-res-matryoshka-dc   \n",
       "gemma-2-2b-res-snap-matryoshka-dc                                   gemma-2-2b-res-snap-matryoshka-dc   \n",
       "gemma-2-9b-res-matryoshka-dc                                             gemma-2-9b-res-matryoshka-dc   \n",
       "gemma-2b-it-res-jb                                                                 gemma-2b-it-res-jb   \n",
       "...                                                                                               ...   \n",
       "sae_bench_gemma-2-2b_vanilla_width-2pow16_date-...  sae_bench_gemma-2-2b_vanilla_width-2pow16_date...   \n",
       "sae_bench_pythia70m_sweep_gated_ctx128_0730               sae_bench_pythia70m_sweep_gated_ctx128_0730   \n",
       "sae_bench_pythia70m_sweep_panneal_ctx128_0730           sae_bench_pythia70m_sweep_panneal_ctx128_0730   \n",
       "sae_bench_pythia70m_sweep_standard_ctx128_0712         sae_bench_pythia70m_sweep_standard_ctx128_0712   \n",
       "sae_bench_pythia70m_sweep_topk_ctx128_0730                 sae_bench_pythia70m_sweep_topk_ctx128_0730   \n",
       "\n",
       "                                                                                              repo_id  \\\n",
       "deepseek-r1-distill-llama-8b-qresearch                 qresearch/DeepSeek-R1-Distill-Llama-8B-SAE-l19   \n",
       "gemma-2-2b-res-matryoshka-dc                        chanind/gemma-2-2b-batch-topk-matryoshka-saes-...   \n",
       "gemma-2-2b-res-snap-matryoshka-dc                   chanind/gemma-2-2b-batch-topk-matryoshka-saes-...   \n",
       "gemma-2-9b-res-matryoshka-dc                        chanind/gemma-2-9b-batch-topk-matryoshka-saes-...   \n",
       "gemma-2b-it-res-jb                                            jbloom/Gemma-2b-IT-Residual-Stream-SAEs   \n",
       "...                                                                                               ...   \n",
       "sae_bench_gemma-2-2b_vanilla_width-2pow16_date-...  canrager/saebench_gemma-2-2b_width-2pow16_date...   \n",
       "sae_bench_pythia70m_sweep_gated_ctx128_0730                                           canrager/lm_sae   \n",
       "sae_bench_pythia70m_sweep_panneal_ctx128_0730                                         canrager/lm_sae   \n",
       "sae_bench_pythia70m_sweep_standard_ctx128_0712                                        canrager/lm_sae   \n",
       "sae_bench_pythia70m_sweep_topk_ctx128_0730                                            canrager/lm_sae   \n",
       "\n",
       "                                                                                       model  \\\n",
       "deepseek-r1-distill-llama-8b-qresearch              deepseek-ai/DeepSeek-R1-Distill-Llama-8B   \n",
       "gemma-2-2b-res-matryoshka-dc                                                      gemma-2-2b   \n",
       "gemma-2-2b-res-snap-matryoshka-dc                                                 gemma-2-2b   \n",
       "gemma-2-9b-res-matryoshka-dc                                                      gemma-2-9b   \n",
       "gemma-2b-it-res-jb                                                               gemma-2b-it   \n",
       "...                                                                                      ...   \n",
       "sae_bench_gemma-2-2b_vanilla_width-2pow16_date-...                                gemma-2-2b   \n",
       "sae_bench_pythia70m_sweep_gated_ctx128_0730                               pythia-70m-deduped   \n",
       "sae_bench_pythia70m_sweep_panneal_ctx128_0730                             pythia-70m-deduped   \n",
       "sae_bench_pythia70m_sweep_standard_ctx128_0712                            pythia-70m-deduped   \n",
       "sae_bench_pythia70m_sweep_topk_ctx128_0730                                pythia-70m-deduped   \n",
       "\n",
       "                                                                                             saes_map  \\\n",
       "deepseek-r1-distill-llama-8b-qresearch              {'blocks.19.hook_resid_post': 'DeepSeek-R1-Dis...   \n",
       "gemma-2-2b-res-matryoshka-dc                        {'blocks.0.hook_resid_post': 'standard/blocks....   \n",
       "gemma-2-2b-res-snap-matryoshka-dc                   {'blocks.0.hook_resid_post': 'snap/blocks.0.ho...   \n",
       "gemma-2-9b-res-matryoshka-dc                        {'blocks.0.hook_resid_post': 'blocks.0.hook_re...   \n",
       "gemma-2b-it-res-jb                                  {'blocks.12.hook_resid_post': 'gemma_2b_it_blo...   \n",
       "...                                                                                               ...   \n",
       "sae_bench_gemma-2-2b_vanilla_width-2pow16_date-...  {'blocks.12.hook_resid_post__trainer_0': 'gemm...   \n",
       "sae_bench_pythia70m_sweep_gated_ctx128_0730         {'blocks.3.hook_resid_post__trainer_0': 'pythi...   \n",
       "sae_bench_pythia70m_sweep_panneal_ctx128_0730       {'blocks.3.hook_resid_post__trainer_16': 'pyth...   \n",
       "sae_bench_pythia70m_sweep_standard_ctx128_0712      {'blocks.3.hook_resid_post__trainer_10': 'pyth...   \n",
       "sae_bench_pythia70m_sweep_topk_ctx128_0730          {'blocks.3.hook_resid_post__trainer_0': 'pythi...   \n",
       "\n",
       "                                                                                       neuronpedia_id  \n",
       "deepseek-r1-distill-llama-8b-qresearch              {'blocks.19.hook_resid_post': 'deepseek-r1-dis...  \n",
       "gemma-2-2b-res-matryoshka-dc                        {'blocks.0.hook_resid_post': None, 'blocks.1.h...  \n",
       "gemma-2-2b-res-snap-matryoshka-dc                   {'blocks.0.hook_resid_post': None, 'blocks.1.h...  \n",
       "gemma-2-9b-res-matryoshka-dc                        {'blocks.0.hook_resid_post': None, 'blocks.1.h...  \n",
       "gemma-2b-it-res-jb                                  {'blocks.12.hook_resid_post': 'gemma-2b-it/12-...  \n",
       "...                                                                                               ...  \n",
       "sae_bench_gemma-2-2b_vanilla_width-2pow16_date-...  {'blocks.12.hook_resid_post__trainer_0': 'gemm...  \n",
       "sae_bench_pythia70m_sweep_gated_ctx128_0730         {'blocks.3.hook_resid_post__trainer_0': 'pythi...  \n",
       "sae_bench_pythia70m_sweep_panneal_ctx128_0730       {'blocks.3.hook_resid_post__trainer_16': 'pyth...  \n",
       "sae_bench_pythia70m_sweep_standard_ctx128_0712      {'blocks.3.hook_resid_post__trainer_10': 'pyth...  \n",
       "sae_bench_pythia70m_sweep_topk_ctx128_0730          {'blocks.3.hook_resid_post__trainer_0': 'pythi...  \n",
       "\n",
       "[63 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sae_lens.toolkit.pretrained_saes_directory import get_pretrained_saes_directory\n",
    "\n",
    "# TODO: Make this nicer.\n",
    "df = pd.DataFrame.from_records(\n",
    "    {k: v.__dict__ for k, v in get_pretrained_saes_directory().items()}\n",
    ").T\n",
    "df.drop(\n",
    "    columns=[\n",
    "        \"expected_var_explained\",\n",
    "        \"expected_l0\",\n",
    "        \"config_overrides\",\n",
    "        \"conversion_func\",\n",
    "    ],\n",
    "    inplace=True,\n",
    ")\n",
    "df  # Each row is a \"release\" which has multiple SAEs which may have different configs / match different hook points in a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e78dcb37-5d5f-4eb0-84a2-29336ffcac4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "SAEs in the Gemma base model release\n",
      "SAE id: blocks.0.hook_resid_post for hook point: blocks.0.hook_resid_post\n",
      "SAE id: blocks.1.hook_resid_post for hook point: blocks.1.hook_resid_post\n",
      "SAE id: blocks.2.hook_resid_post for hook point: blocks.2.hook_resid_post\n",
      "SAE id: blocks.3.hook_resid_post for hook point: blocks.3.hook_resid_post\n",
      "SAE id: blocks.4.hook_resid_post for hook point: blocks.4.hook_resid_post\n",
      "SAE id: blocks.5.hook_resid_post for hook point: blocks.5.hook_resid_post\n",
      "SAE id: blocks.6.hook_resid_post for hook point: blocks.6.hook_resid_post\n",
      "SAE id: blocks.7.hook_resid_post for hook point: blocks.7.hook_resid_post\n",
      "SAE id: blocks.8.hook_resid_post for hook point: blocks.8.hook_resid_post\n",
      "SAE id: blocks.9.hook_resid_post for hook point: blocks.9.hook_resid_post\n",
      "SAE id: blocks.10.hook_resid_post for hook point: blocks.10.hook_resid_post\n",
      "SAE id: blocks.11.hook_resid_post for hook point: blocks.11.hook_resid_post\n",
      "SAE id: blocks.12.hook_resid_post for hook point: blocks.12.hook_resid_post\n",
      "SAE id: blocks.13.hook_resid_post for hook point: blocks.13.hook_resid_post\n",
      "SAE id: blocks.14.hook_resid_post for hook point: blocks.14.hook_resid_post\n",
      "SAE id: blocks.15.hook_resid_post for hook point: blocks.15.hook_resid_post\n",
      "SAE id: blocks.16.hook_resid_post for hook point: blocks.16.hook_resid_post\n",
      "SAE id: blocks.17.hook_resid_post for hook point: blocks.17.hook_resid_post\n",
      "SAE id: blocks.18.hook_resid_post for hook point: blocks.18.hook_resid_post\n",
      "SAE id: blocks.19.hook_resid_post for hook point: blocks.19.hook_resid_post\n",
      "SAE id: blocks.20.hook_resid_post for hook point: blocks.20.hook_resid_post\n",
      "SAE id: blocks.21.hook_resid_post for hook point: blocks.21.hook_resid_post\n",
      "SAE id: blocks.22.hook_resid_post for hook point: blocks.22.hook_resid_post\n",
      "SAE id: blocks.23.hook_resid_post for hook point: blocks.23.hook_resid_post\n",
      "SAE id: blocks.24.hook_resid_post for hook point: blocks.24.hook_resid_post\n",
      "SAE id: blocks.25.hook_resid_post for hook point: blocks.25.hook_resid_post\n",
      "SAE id: blocks.26.hook_resid_post for hook point: blocks.26.hook_resid_post\n",
      "SAE id: blocks.27.hook_resid_post for hook point: blocks.27.hook_resid_post\n",
      "SAE id: blocks.28.hook_resid_post for hook point: blocks.28.hook_resid_post\n",
      "SAE id: blocks.29.hook_resid_post for hook point: blocks.29.hook_resid_post\n",
      "SAE id: blocks.30.hook_resid_post for hook point: blocks.30.hook_resid_post\n",
      "SAE id: blocks.31.hook_resid_post for hook point: blocks.31.hook_resid_post\n",
      "SAE id: blocks.32.hook_resid_post for hook point: blocks.32.hook_resid_post\n",
      "SAE id: blocks.33.hook_resid_post for hook point: blocks.33.hook_resid_post\n",
      "SAE id: blocks.34.hook_resid_post for hook point: blocks.34.hook_resid_post\n",
      "SAE id: blocks.35.hook_resid_post for hook point: blocks.35.hook_resid_post\n",
      "SAE id: blocks.36.hook_resid_post for hook point: blocks.36.hook_resid_post\n",
      "SAE id: blocks.37.hook_resid_post for hook point: blocks.37.hook_resid_post\n",
      "SAE id: blocks.38.hook_resid_post for hook point: blocks.38.hook_resid_post\n",
      "SAE id: blocks.39.hook_resid_post for hook point: blocks.39.hook_resid_post\n",
      "SAE id: blocks.40.hook_resid_post for hook point: blocks.40.hook_resid_post\n",
      "release: gemma-scope-9b-it-res-canonical\n"
     ]
    }
   ],
   "source": [
    "# show the contents of the saes_map column for a specific row\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(\"SAEs in the Gemma base model release\")\n",
    "for k, v in df.loc[df.model == \"gemma-2-9b\", \"saes_map\"].values[0].items():\n",
    "    print(f\"SAE id: {k} for hook point: {v}\")\n",
    "r = df.loc[df.model == \"gemma-2-9b-it\", \"release\"].values[0]\n",
    "print(f\"release: {r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a89d0462-7274-459c-a5c9-60bc62b9532f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face login successful (using provided token).\n"
     ]
    }
   ],
   "source": [
    "import dotenv\n",
    "import os\n",
    "dotenv.load_dotenv(\"hf.env\")\n",
    "# @title 1.5. For access to Gemma models, log in to HuggingFace \n",
    "from huggingface_hub import login\n",
    "HUGGING_FACE_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "try:\n",
    "     login(token=HUGGING_FACE_TOKEN)\n",
    "     print(\"Hugging Face login successful (using provided token).\")\n",
    "except Exception as e:\n",
    "     print(f\"Hugging Face login failed. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96a9af7a-6bd2-4582-bb72-c228dd1abd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You tried to specify center_unembed=True for a model using logit softcap, but this can't be done! Softcapping is not invariant upon adding a constant Setting center_unembed=False instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f721a6abea1e41398ea08c1301c2a17c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gemma-2-9b into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "# from transformer_lens import HookedTransformer\n",
    "from sae_lens import SAE, HookedSAETransformer\n",
    "\n",
    "model = HookedSAETransformer.from_pretrained(\"gemma-2-9b\", device=device)\n",
    "\n",
    "# the cfg dict is returned alongside the SAE since it may contain useful information for analysing the SAE (eg: instantiating an activation store)\n",
    "# Note that this is not the same as the SAEs config dict, rather it is whatever was in the HF repo, from which we can extract the SAE config dict\n",
    "# We also return the feature sparsities which are stored in HF for convenience.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "671db57e-fefb-4497-8e33-ee82c4476c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "sae, cfg_dict, sparsity = SAE.from_pretrained(\n",
    "    release=\"gemma-scope-9b-it-res-canonical\",  # <- Release name\n",
    "    sae_id=\"layer_20/width_16k/canonical\",  # <- SAE id (not always a hook point!) layer_20/width_131k/canonical\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbffba2d-1096-4d71-aacb-fc74c99f3b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'architecture': 'jumprelu', 'd_in': 3584, 'd_sae': 16384, 'activation_fn_str': 'relu', 'apply_b_dec_to_input': False, 'finetuning_scaling_factor': False, 'context_size': 1024, 'model_name': 'gemma-2-9b-it', 'hook_name': 'blocks.20.hook_resid_post', 'hook_layer': 20, 'hook_head_index': None, 'prepend_bos': True, 'dataset_path': 'monology/pile-uncopyrighted', 'dataset_trust_remote_code': True, 'normalize_activations': None, 'dtype': 'float32', 'device': 'cuda', 'sae_lens_training_version': None, 'activation_fn_kwargs': {}, 'neuronpedia_id': 'gemma-2-9b-it/20-gemmascope-res-16k', 'model_from_pretrained_kwargs': {}, 'seqpos_slice': (None,)}\n"
     ]
    }
   ],
   "source": [
    "print(sae.cfg.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13e2f8b5-beb5-4871-93c2-e96e23813abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91b6637a1350421aa6ec8b9a8b6bbbb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/373 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c714c5eba34e47c4a39d9c262c1d7d45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/921 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6563dd73ad7d437f8c91c8293b064426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/33.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33829246c7da417a924a9cb4b7ead3a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a83efd7f27a14c76811c25663a21f5df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformer_lens.utils import tokenize_and_concatenate\n",
    "\n",
    "dataset = load_dataset(\n",
    "    path=\"NeelNanda/pile-10k\",\n",
    "    split=\"train\",\n",
    "    streaming=False,\n",
    ")\n",
    "\n",
    "token_dataset = tokenize_and_concatenate(\n",
    "    dataset=dataset,  # type: ignore\n",
    "    tokenizer=model.tokenizer,  # type: ignore\n",
    "    streaming=True,\n",
    "    max_length=sae.cfg.context_size,\n",
    "    add_bos_token=sae.cfg.prepend_bos,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d7cc104-628f-4edd-a4df-aa1f119cb03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"600\"\n",
       "            src=\"https://www.neuronpedia.org/gemma-2-9b-it/20-gemmascope-res-16k/14184?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f383e179290>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dashboard FIXED URL\n",
    "from IPython.display import IFrame\n",
    "\n",
    "# get a random feature from the SAE\n",
    "feature_idx = torch.randint(0, sae.cfg.d_sae, (1,)).item()\n",
    "\n",
    "html_template = \"https://www.neuronpedia.org/{}/{}/{}?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
    "\n",
    "\n",
    "def get_dashboard_html(sae_release=\"gemma-scope-9b-it-res-canonical\", sae_id=\"layer_20/width_16k/canonical\", feature_idx=0):\n",
    "    return html_template.format(sae_release, sae_id, feature_idx)\n",
    "\n",
    "\n",
    "html = get_dashboard_html(\n",
    "    sae_release=\"gemma-2-9b-it\", sae_id=\"20-gemmascope-res-16k\", feature_idx=feature_idx\n",
    ")\n",
    "IFrame(html, width=1200, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "675eb5a5-f76e-4ea9-a5d5-9fcb78ae5352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized prompt: ['<bos>', 'In', ' the', ' beginning', ',', ' God', ' created', ' the', ' heavens', ' and', ' the']\n",
      "Tokenized answer: [' earth']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24.30</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">85.78</span><span style=\"font-weight: bold\">% Token: | earth|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m24.30\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m85.78\u001b[0m\u001b[1m% Token: | earth|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 24.30 Prob: 85.78% Token: | earth|\n",
      "Top 1th token. Logit: 22.46 Prob: 13.61% Token: | Earth|\n",
      "Top 2th token. Logit: 17.07 Prob:  0.06% Token: | land|\n",
      "Top 3th token. Logit: 17.06 Prob:  0.06% Token: | the|\n",
      "Top 4th token. Logit: 16.87 Prob:  0.05% Token: |earth|\n",
      "Top 5th token. Logit: 16.80 Prob:  0.05% Token: | world|\n",
      "Top 6th token. Logit: 16.80 Prob:  0.05% Token: | universe|\n",
      "Top 7th token. Logit: 16.46 Prob:  0.03% Token: | |\n",
      "Top 8th token. Logit: 16.36 Prob:  0.03% Token: |\n",
      "|\n",
      "Top 9th token. Logit: 16.21 Prob:  0.03% Token: | earths|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' earth'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' earth'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformer_lens.utils import test_prompt\n",
    "\n",
    "prompt = \"In the beginning, God created the heavens and the\"\n",
    "answer = \"earth\"\n",
    "\n",
    "# Show that the model can confidently predict the next token.\n",
    "test_prompt(prompt, answer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fbf2cb4-23dc-4749-9967-0adedeaaf249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SAEs don't reconstruct activation perfectly, so if you attach an SAE and want the model to stay performant, you need to use the error term.\n",
    "# This is because the SAE will be used to modify the forward pass, and if it doesn't reconstruct the activations well, the outputs may be effected.\n",
    "# Good SAEs have small error terms but it's something to be mindful of.\n",
    "\n",
    "sae.use_error_term  # If use error term is set to false, we will modify the forward pass by using the sae."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "190daf3c-59df-403d-83f6-bd78f2997164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('blocks.20.hook_resid_post.hook_sae_input', torch.Size([1, 18, 3584])), ('blocks.20.hook_resid_post.hook_sae_acts_pre', torch.Size([1, 18, 16384])), ('blocks.20.hook_resid_post.hook_sae_acts_post', torch.Size([1, 18, 16384])), ('blocks.20.hook_resid_post.hook_sae_recons', torch.Size([1, 18, 3584])), ('blocks.20.hook_resid_post.hook_sae_output', torch.Size([1, 18, 3584]))]\n"
     ]
    }
   ],
   "source": [
    "prompt=\"A rhymed couplet:\\nWhispers of dreams dance through the still night\\n\"\n",
    "# hooked SAE Transformer will enable us to get the feature activations from the SAE\n",
    "_, cache = model.run_with_cache_with_saes(prompt, saes=[sae])\n",
    "\n",
    "print([(k, v.shape) for k, v in cache.items() if \"sae\" in k])\n",
    "\n",
    "# note there were 11 tokens in our prompt, the residual stream dimension is 768, and the number of SAE features is 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df595e5b-1ada-4e72-916b-dd49bc982547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A rhymed couplet:\n",
      "Whispers of dreams dance through the still night\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bdd22e2-aba6-46ca-aa2d-35fa0e6f7b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "light_examples=['Mountains stand majestic against the fading light',\n",
    " \"I see the sun rise, morning's gentle light\",\n",
    " 'Autumn leaves dance gracefully in golden light',\n",
    " 'The sun dips below the horizon, painting skies with light',\n",
    " 'Fireflies dance through summer meadows, tiny dots of light',\n",
    " 'Through darkest storms we find our way toward light',\n",
    " 'Stars whisper ancient stories through the velvet night light',\n",
    " 'Between shadowed branches, hope filters as dappled light',\n",
    " 'Her smile breaks through sadness like morning light',\n",
    " 'Candles flicker on birthday cakes, wishes take flight light',\n",
    " 'Ocean waves catch and scatter diamonds of light',\n",
    " 'In your eyes I see reflections of eternal light',\n",
    " 'Souls reach upward, forever seeking the divine light']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09120ab0-b39c-4840-8b3f-adc8c8854931",
   "metadata": {},
   "outputs": [],
   "source": [
    "night_examples=['The moon casts gentle shadows on this quiet night',\n",
    " 'Stars twinkle like diamonds in the velvet night',\n",
    " 'Whispers of dreams dance through the still night',\n",
    " 'Shadows stretch long across the mysterious night',\n",
    " 'Owls hoot their melancholy songs into the night',\n",
    " 'Lovers walk hand in hand beneath the starry night',\n",
    " 'Crickets sing their lullabies throughout the summer night',\n",
    " 'Ghosts of memories haunt the lonely night',\n",
    " 'Fireflies paint ephemeral patterns in the dark night',\n",
    " 'Silver moonbeams illuminate the peaceful night',\n",
    " 'Whispers of love echo in the still of night',\n",
    " 'Whispers of courage echo through the night',\n",
    " \"Stars illuminate the darkness during night\",\n",
    " 'Stars whisper ancient stories through the velvet night',\n",
    " 'Stars twinkle in the vast night',\n",
    " 'The stars in the night']\n",
    "\n",
    "bright_examples=['The sunset paints the sky with colors so bright',\n",
    " 'In the dark, her smile shines so bright',\n",
    " 'Stars twinkle in the vast night sky, ever bright',\n",
    " \"Through shadows, hope's flame burns steady and bright\",\n",
    " 'Morning sun paints the meadow golden bright',\n",
    " \"Children's laughter fills the room, joyously bright\",\n",
    " 'After rain, rainbow colors appear vividly bright',\n",
    " 'His eyes, reflecting love, sparkled incredibly bright',\n",
    " 'Autumn leaves dance in colors fiery bright',\n",
    " 'Dreams illuminate paths to futures impossibly bright',\n",
    " 'Even in despair, keep your spirit bright']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4a9470d-a872-45b1-8731-f7b2d6bed28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c55e7f0-64af-4aac-94b5-954ae09ae249",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "toplatents=Counter()\n",
    "for e in light_examples:\n",
    "    _, cache = model.run_with_cache_with_saes(e, saes=[sae])\n",
    "    toplatents.update(torch.topk(cache[\"blocks.20.hook_resid_post.hook_sae_acts_pre\"][0, -1, :],1000).indices.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3784f58c-4603-4e67-b3c1-4073b0d42cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns list of latents that are highly active (among top 1K latents) on all last word tokens in a list of texts\n",
    "def get_last_word_latents(texts):\n",
    "    latents=Counter()\n",
    "    for e in texts:\n",
    "        _, cache = model.run_with_cache_with_saes(e, saes=[sae])\n",
    "        latents.update(torch.topk(cache[\"blocks.20.hook_resid_post.hook_sae_acts_pre\"][0, -1, :],1000).indices.tolist())\n",
    "    return [k for k,v in latents.items() if v==len(texts)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08d28453-ddc6-419e-aa6c-c82a80982365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1089, 6880, 211, 14609, 7719, 438, 3064, 10281, 15226, 3899, 9922, 2999, 8953, 13709, 13013, 3994, 2271, 10718, 13248, 13045, 7212, 3400, 548, 12120, 9769, 13829, 7566, 7284, 9653, 7998, 12473, 13844, 6798, 11899, 2489, 8081, 7891, 2222, 1239, 9309, 15686, 1106, 13037, 13201, 4106, 5862, 3641, 6000, 6285, 10806, 7201, 2134, 14984, 8375, 15045, 7683, 5404, 15945, 1834, 2147, 7331, 15379, 12991, 12549]\n"
     ]
    }
   ],
   "source": [
    "#latents that are always highly active on \"night\" \n",
    "nightlatents=get_last_word_latents(night_examples)\n",
    "print(nightlatents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcb876d4-8bfd-4ce9-87be-9bdcd121546a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#latents that upon manual inspection specifically associate with the word \"light\" \n",
    "lightindices=[6482, #word \"light\"\n",
    "13013, #light, lamp, illumination related words\n",
    "15015, #word \"light\"\n",
    "10522, #sometimes \"light\", sometimes other words\n",
    "5862, # all words that rhyme with \"light\"\n",
    "15686] # letter T\n",
    "#9922 some vague semantic field including \"light\" but too non-specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e93b1309-6490-4069-bd85-e6ff4947c77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13013, 5862, 15686]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#latents that are always highly active on \"night\" but also on \"light\"\n",
    "[i for i in lightindices if i in nightlatents]\n",
    "#Answer: [13013, #light, lamp, illumination related words\n",
    "# 5862, # all words that rhyme with \"light\"\n",
    "# 15686] # letter T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e513ed52-7a33-4961-905a-8d9c1c9bdc24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6482, 5862, 15686]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#latents that are always highly active on \"bright\" \n",
    "brightlatents=get_last_word_latents(bright_examples)\n",
    "#which of the light indices are also in the bright latents?\n",
    "[i for i in lightindices if i in brightlatents]\n",
    "#Answer: [6482, \"word light\"\n",
    "# 5862, \"rhyming with light\"\n",
    "#  15686, \"letter T\"\n",
    "#]\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d4e8b363-37c5-4bcf-8736-b4fe661cb7d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6880,\n",
       " 211,\n",
       " 6482,\n",
       " 9922,\n",
       " 13013,\n",
       " 15015,\n",
       " 16159,\n",
       " 5862,\n",
       " 7681,\n",
       " 9653,\n",
       " 8081,\n",
       " 4265,\n",
       " 1831,\n",
       " 15686,\n",
       " 3064,\n",
       " 14080,\n",
       " 10522,\n",
       " 7998]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top 1K latents that are highly active on all \"light\" tokens at the end of a line\n",
    "[k for k,v in toplatents.items() if v==len(light_examples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d16832e7-3967-43fa-a49a-4a3460495a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11137,  6981,  7719, 15511,   211], device='cuda:0')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get top 5 firing latents\n",
    "torch.topk(\n",
    "    cache[\"blocks.20.hook_resid_post.hook_sae_acts_pre\"][0, -1, :], 5\n",
    ").indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "441afc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latents(firstline,latents):\n",
    "    prompt=f\"A rhymed couplet:\\n{firstline}\\n\"\n",
    "    _, cache = model.run_with_cache_with_saes(prompt, saes=[sae])\n",
    "    #indices = torch.tensor(latents, device=tensor.device)\n",
    "    # Return the values at the given indices\n",
    "    return cache[\"blocks.20.hook_resid_post.hook_sae_acts_pre\"][0, -1, :][latents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b368229-b349-4285-9d44-94e0cfff1aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function will return the ranks of the indices in the tensor\n",
    "#will be used to get ranks of latents among SAE features\n",
    "def get_ranks_of_indices(tensor, indices):\n",
    "    # Ensure tensor is 1D\n",
    "    tensor = tensor.flatten()\n",
    "\n",
    "    # Convert list of indices to tensor on the same device as input tensor\n",
    "    indices = torch.tensor(indices, device=tensor.device)\n",
    "\n",
    "    # Get sorted indices (descending: rank 1 = highest value)\n",
    "    sorted_indices = torch.argsort(tensor, descending=True)\n",
    "\n",
    "    # Allocate tensor for ranks on the same device\n",
    "    ranks = torch.empty_like(sorted_indices)\n",
    "\n",
    "    # Assign rank values (1-based)\n",
    "    ranks[sorted_indices] = torch.arange(1, len(tensor) + 1, device=tensor.device)\n",
    "\n",
    "    # Return the ranks for requested indices\n",
    "    return ranks[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "28bbbd7d-5e3a-4d64-a070-ebef853a462f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5], device='cuda:0')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ranks_of_indices(cache[\"blocks.20.hook_resid_post.hook_sae_acts_pre\"][0, -1, :],[11137,  6981,  7719, 15511,   211])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a7ae19ac-df1f-45fc-bea6-9a170faec010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([223], device='cuda:0')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ranks_of_indices(cache[\"blocks.20.hook_resid_post.hook_sae_acts_pre\"][0, -1, :],[13013])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "639d36ef-9e7f-45ec-8fb7-4e2574839eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_latents(firstline,latents):\n",
    "    prompt=f\"A rhymed couplet:\\n{firstline}\\n\"\n",
    "    _, cache = model.run_with_cache_with_saes(prompt, saes=[sae])\n",
    "    return get_ranks_of_indices(cache[\"blocks.20.hook_resid_post.hook_sae_acts_pre\"][0, -1, :],latents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "873332fa-25d9-44e3-9b42-873a9bebb328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.3867,  2.9319, -5.0579, -0.7180,  0.0660, -4.2110], device='cuda:0')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_latents('Whispers of dreams dance through the still night',lightindices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b47e3199-8336-46a9-97dc-aa6350f30cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lines that are strongly suggestive of rhyming word \"light\"\n",
    "lightlines=['Whispers of dreams dance through the still night',\n",
    " 'Shadows stretch long across the mysterious night',\n",
    " 'Crickets sing their lullabies throughout the summer night',\n",
    " 'Ghosts of memories haunt the lonely night',\n",
    " 'Mountains stand as ancient guardians of majestic height',\n",
    " 'Her confidence shines like a beacon at full height',\n",
    " 'Courage carries us through fear to newfound height',\n",
    " 'Whispers of love echo in the still of night',\n",
    " 'Whispers of courage echo through the night might',\n",
    " 'Through valleys deep, mountains rise with ancient might',\n",
    " \"Within each seed lies nature's dormant might\",\n",
    " 'The eagle soared, a symbol of majestic flight',\n",
    " 'Memories flutter like birds in sudden flight',\n",
    " 'Hearts race as love embarks on its first flight',\n",
    " 'Autumn leaves spiral downward in their final flight',\n",
    " 'Hold my hand through darkness into right',\n",
    " 'Whispers of truth echo from mountain height',\n",
    " 'Courage stands tall facing fear with might',\n",
    " 'The dawn breaks with promise, igniting will to fight',\n",
    " 'Stars align when hearts unite in righteous fight',\n",
    " 'Stars twinkle in the vast night sky, ever bright',\n",
    " 'Morning sun paints the meadow golden bright',\n",
    " 'Memories bound in a chest locked up tight',\n",
    " 'Through stormy seas, we held on fierce and tight',\n",
    " 'In silent moments, time stands perfectly still and tight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6326bfb7-0493-4325-8f11-f30733679d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lines that are strongly suggestive of rhyming word \"night\"\n",
    "nightlines=['Autumn leaves dance gracefully out of sight',\n",
    " 'Stars twinkle like diamonds in the vast cosmic sight',\n",
    " 'Dreams take flight beyond the realm of sight',\n",
    " 'As darkness falls, stars shine with celestial might',\n",
    " 'Dreams unfold where imagination takes flight might',\n",
    " 'Hope rises like a phoenix in triumphant flight',\n",
    " 'In shadows deep, your presence feels so right',\n",
    " 'Fireflies dance through summer meadows, tiny dots of light',\n",
    " 'Through darkest storms we find our way toward light',\n",
    " 'In your eyes I see reflections of eternal light',\n",
    " 'In the dark, her smile shines so bright',\n",
    " \"Through shadows, hope's flame burns steady and bright\",\n",
    " 'After rain, rainbow colors appear vividly bright',\n",
    " 'His eyes, reflecting love, sparkled incredibly bright',\n",
    " 'Autumn leaves dance in colors fiery bright',\n",
    " 'Even in despair, keep your spirit bright']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3cc85dd0-d7a2-4e39-a241-0be76e35cfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lines that are strongly suggestive of rhyming word \"sight\"\n",
    "sightlines=['Stars twinkle like diamonds in the velvet night',\n",
    " 'The sunset paints the sky with colors so bright',\n",
    " \"Butterflies dance in the garden's gentle flight\",\n",
    " 'The stars in the night sky shine incredibly tight']\n",
    "\n",
    "#lines that are strongly suggestive of rhyming word \"bright\"\n",
    "\n",
    "brightlines=['Lovers walk hand in hand beneath the starry night',\n",
    " \"Souls connect across time with love's eternal might\",\n",
    " 'Memories of fallen heroes inspire us to fight',\n",
    " 'Souls reach upward, forever seeking the divine light']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b76ccd1a-efb9-40b2-ab34-84d522438ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lines in the NIGHT family\n",
    "night_rhymes=['The moon casts gentle shadows on this quiet night',\n",
    " 'Stars twinkle like diamonds in the velvet night',\n",
    " 'Whispers of dreams dance through the still night',\n",
    " 'Shadows stretch long across the mysterious night',\n",
    " 'Owls hoot their melancholy songs into the night',\n",
    " 'Lovers walk hand in hand beneath the starry night',\n",
    " 'Crickets sing their lullabies throughout the summer night',\n",
    " 'Ghosts of memories haunt the lonely night',\n",
    " 'Fireflies paint ephemeral patterns in the dark night',\n",
    " 'Silver moonbeams illuminate the peaceful night',\n",
    " 'Whispers of dreams soaring beyond the midnight height',\n",
    " 'Mountains stand as ancient guardians of majestic height',\n",
    " 'Her confidence shines like a beacon at full height',\n",
    " 'Stars beckon us to reach for their distant height',\n",
    " 'Autumn leaves dance gracefully from their former height',\n",
    " 'Love lifts the spirit to an unexpected height',\n",
    " 'Courage carries us through fear to newfound height',\n",
    " 'The falcon watches the world from its airy height',\n",
    " 'Memories of childhood linger at an innocent height',\n",
    " 'Ambition pushes us to scale each challenging height',\n",
    " 'The sunset paints the sky with colors so bright',\n",
    " 'Whispers of love echo in the still of night',\n",
    " 'Memories linger like shadows beyond normal sight',\n",
    " 'Mountains stand majestic against the fading light sight',\n",
    " 'Autumn leaves dance gracefully out of sight',\n",
    " 'Stars twinkle like diamonds in the vast cosmic sight',\n",
    " 'Ocean waves crash with tremendous might and sight',\n",
    " \"Children's laughter fills the air with pure delight sight\",\n",
    " 'Dreams take flight beyond the realm of sight',\n",
    " 'Hidden treasures revealed to those with inner sight',\n",
    " 'As darkness falls, stars shine with celestial might',\n",
    " 'Whispers of courage echo through the night might',\n",
    " 'In silent moments, hearts discover their true might',\n",
    " 'Through valleys deep, mountains rise with ancient might',\n",
    " 'Dreams unfold where imagination takes flight might',\n",
    " 'Against all odds, small voices speak with mighty might',\n",
    " 'Gentle rivers carve stone canyons with patient might',\n",
    " \"Love's tender touch reveals its transformative might\",\n",
    " \"Within each seed lies nature's dormant might\",\n",
    " \"Souls connect across time with love's eternal might\",\n",
    " 'The eagle soared, a symbol of majestic flight',\n",
    " 'Dreams take wing and carry us to flight',\n",
    " \"Butterflies dance in the garden's gentle flight\",\n",
    " \"Stars illuminate the darkness during night's silent flight\",\n",
    " 'Memories flutter like birds in sudden flight',\n",
    " 'Time passes swiftly, moments caught in flight',\n",
    " 'Hearts race as love embarks on its first flight',\n",
    " 'Autumn leaves spiral downward in their final flight',\n",
    " 'Imagination knows no boundaries in creative flight',\n",
    " 'Hope rises like a phoenix in triumphant flight',\n",
    " \"I see the sun rise, morning's gentle light\",\n",
    " 'In shadows deep, your presence feels so right',\n",
    " 'Dreams unfold when stars align just right',\n",
    " 'Hold my hand through darkness into right',\n",
    " 'Whispers of truth echo from mountain height',\n",
    " 'Love blooms slowly, patience makes it right',\n",
    " 'Time heals wounds when hearts align just right',\n",
    " 'Autumn leaves dance gracefully in golden light',\n",
    " 'Courage stands tall facing fear with might',\n",
    " \"Silent wisdom speaks when timing's right\",\n",
    " 'The dawn breaks with promise, igniting will to fight',\n",
    " 'Shadows dance where courage meets the call to fight',\n",
    " 'Whispers of hope echo through darkness before we fight',\n",
    " 'Stars align when hearts unite in righteous fight',\n",
    " 'Silent strength builds within before the coming fight',\n",
    " 'Memories of fallen heroes inspire us to fight',\n",
    " 'Through storm and calm, we gather for the fight',\n",
    " 'Ancient wisdom guides our steps into the fight',\n",
    " \"Love's tender embrace gives reason to fight\",\n",
    " \"Freedom's song rings clear in every worthy fight\",\n",
    " 'The sun dips below the horizon, painting skies with light',\n",
    " 'Fireflies dance through summer meadows, tiny dots of light',\n",
    " 'Through darkest storms we find our way toward light',\n",
    " 'Stars whisper ancient stories through the velvet night light',\n",
    " 'Between shadowed branches, hope filters as dappled light',\n",
    " 'Her smile breaks through sadness like morning light',\n",
    " 'Candles flicker on birthday cakes, wishes take flight light',\n",
    " 'Ocean waves catch and scatter diamonds of light',\n",
    " 'In your eyes I see reflections of eternal light',\n",
    " 'Souls reach upward, forever seeking the divine light',\n",
    " 'In the dark, her smile shines so bright',\n",
    " 'Stars twinkle in the vast night sky, ever bright',\n",
    " \"Through shadows, hope's flame burns steady and bright\",\n",
    " 'Morning sun paints the meadow golden bright',\n",
    " \"Children's laughter fills the room, joyously bright\",\n",
    " 'After rain, rainbow colors appear vividly bright',\n",
    " 'His eyes, reflecting love, sparkled incredibly bright',\n",
    " 'Autumn leaves dance in colors fiery bright',\n",
    " 'Dreams illuminate paths to futures impossibly bright',\n",
    " 'Even in despair, keep your spirit bright',\n",
    " 'The stars in the night sky shine incredibly tight',\n",
    " 'Hold me close, embrace me with all your might tight',\n",
    " 'Dreams unfold as I close my eyes so tight',\n",
    " 'Her smile warmed the room, making everything feel tight',\n",
    " 'Memories bound in a chest locked up tight',\n",
    " 'Through stormy seas, we held on fierce and tight',\n",
    " 'Between whispered secrets, our friendship grew tight',\n",
    " 'Autumn leaves dance as winter draws near tight',\n",
    " 'Knots of worry slowly unravel when wound too tight',\n",
    " 'In silent moments, time stands perfectly still and tight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592c9956-a6e9-46d4-a43a-475002320029",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl=Counter()\n",
    "ll=len(lightlines)\n",
    "ln=len(nightlines)\n",
    "lb=len(brightlines)\n",
    "ls=len(sightlines)\n",
    "for l in lightlines:\n",
    "    print(\"=\"*30)\n",
    "    print(l)\n",
    "    indices=check_latents(l,lightindices).tolist()\n",
    "    for i in range(len(indices)):\n",
    "        if indices[i]<1000:\n",
    "            highindex=lightindices[i]\n",
    "            print(\"latent in top 1K:\",highindex)\n",
    "            cl[highindex]+=1/ll\n",
    "\n",
    "print(\"*\"*80)\n",
    "cs=Counter()\n",
    "for l in sightlines:\n",
    "    print(\"=\"*30)\n",
    "    print(l)\n",
    "    indices=check_latents(l,lightindices).tolist()\n",
    "    for i in range(len(indices)):\n",
    "        if indices[i]<1000:\n",
    "            highindex=lightindices[i]\n",
    "            print(\"latent in top 1K:\",highindex)\n",
    "            cs[highindex]+=1/ls\n",
    "cb=Counter()\n",
    "for l in brightlines:\n",
    "    print(\"=\"*30)\n",
    "    print(l)\n",
    "    indices=check_latents(l,lightindices).tolist()\n",
    "    for i in range(len(indices)):\n",
    "        if indices[i]<1000:\n",
    "            highindex=lightindices[i]\n",
    "            print(\"latent in top 1K:\",highindex)\n",
    "            cb[highindex]+=1/lb\n",
    "            \n",
    "print(\"*\"*80)\n",
    "cn=Counter()\n",
    "for l in nightlines:\n",
    "    print(\"=\"*30)\n",
    "    print(l)\n",
    "    indices=check_latents(l,lightindices).tolist()\n",
    "    for i in range(len(indices)):\n",
    "        if indices[i]<1000:\n",
    "            highindex=lightindices[i]\n",
    "            print(\"latent in top 1K:\",highindex)\n",
    "            cn[highindex]+=1/ln\n",
    "print(\"light latents in light inducing lines\", cl)\n",
    "print(\"light latents in night inducing lines\", cn)\n",
    "print(\"light latents in sight inducing lines\", cs)\n",
    "print(\"light latents in bright inducing lines\", cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "11de5c43-da44-48b8-81bb-641200bebc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n",
      "light latents in non-light inducing lines Counter({13013: 0.490566037735849, 5862: 0.43396226415094336})\n",
      "light latents in light inducing lines Counter({13013: 0.5599999999999999, 5862: 0.28, 10522: 0.04})\n"
     ]
    }
   ],
   "source": [
    "testnight=[l for l in night_rhymes if l not in lightlines and \"light\" not in l]\n",
    "print(len(testnight))\n",
    "call=Counter()\n",
    "lall=len(testnight)\n",
    "for l in testnight:\n",
    "    #print(\"=\"*30)\n",
    "    #print(l)\n",
    "    indices=check_latents(l,lightindices).tolist()\n",
    "    for i in range(len(indices)):\n",
    "        if indices[i]<1000:\n",
    "            highindex=lightindices[i]\n",
    "            #print(\"latent in top 1K:\",highindex)\n",
    "            call[highindex]+=1/lall\n",
    "print(\"light latents in non-light inducing lines\", call)\n",
    "print(\"light latents in light inducing lines\", cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30dab07d-0eb3-4430-9547-9c3cd09ce9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_latents(texts, inds):\n",
    "    # Get device from the first tensor\n",
    "    #device = texts[0].device\n",
    "\n",
    "    # Stack latents from all texts for the given indices\n",
    "    latents = torch.stack([get_latents(t, inds) for t in texts])\n",
    "\n",
    "    # Compute average along the 0th dimension (across texts)\n",
    "    avg_latents = latents.mean(dim=0)\n",
    "\n",
    "    # Map each index to its average value\n",
    "    return {idx: avg_latents[i].item() for i, idx in enumerate(inds)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c3e09d87-3f5e-4da2-9b74-10522a242cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************\n",
      "Light inducing lines' latent activations:\n",
      "{6482: -3.3159093856811523, 13013: 1.2844442129135132, 15015: -5.082214832305908, 10522: -0.5359411239624023, 5862: 0.9647432565689087, 15686: -3.556427478790283}\n",
      "******************************\n",
      "Night inducing lines' latent activations:\n",
      "{6482: -2.67195987701416, 13013: 1.1071678400039673, 15015: -4.829133987426758, 10522: -0.35578015446662903, 5862: 0.8474807739257812, 15686: -3.8646342754364014}\n",
      "******************************\n",
      "Sight inducing lines' latent activations:\n",
      "{6482: -2.8953628540039062, 13013: 1.0369709730148315, 15015: -5.267131328582764, 10522: -0.6561349630355835, 5862: -0.260201096534729, 15686: -4.431552886962891}\n",
      "******************************\n",
      "Bright inducing lines' latent activations:\n",
      "{6482: -2.486870288848877, 13013: 0.5072799324989319, 15015: -5.398140907287598, 10522: -0.732904314994812, 5862: 1.461120367050171, 15686: -4.480067253112793}\n",
      "******************************\n",
      "Non-Light associated lines' latent activations:\n",
      "{6482: -3.158332347869873, 13013: 1.0666873455047607, 15015: -5.2387895584106445, 10522: -0.7195772528648376, 5862: 0.8615282773971558, 15686: -3.7596442699432373}\n"
     ]
    }
   ],
   "source": [
    "print(\"*\"*30)\n",
    "print(\"Light inducing lines' latent activations:\")\n",
    "print(get_avg_latents(lightlines,lightindices))\n",
    "print(\"*\"*30)\n",
    "print(\"Night inducing lines' latent activations:\")\n",
    "print(get_avg_latents(nightlines,lightindices))\n",
    "print(\"*\"*30)\n",
    "print(\"Sight inducing lines' latent activations:\")\n",
    "print(get_avg_latents(sightlines,lightindices))\n",
    "print(\"*\"*30)\n",
    "print(\"Bright inducing lines' latent activations:\")\n",
    "print(get_avg_latents(brightlines,lightindices))\n",
    "print(\"*\"*30)\n",
    "print(\"Non-Light associated lines' latent activations:\")\n",
    "print(get_avg_latents(testnight,lightindices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ae99577-5e29-4ee3-bdd9-87d275f4c5d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the decoder weights torch.Size([16384, 3584]))\n",
      "Shape of the model unembed torch.Size([3584, 256000])\n",
      "Shape of the projection matrix torch.Size([16384, 256000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_258/2189250946.py:16: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  feature_df.applymap(lambda x: model.tokenizer.decode(x))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_6482</th>\n",
       "      <th>feature_13013</th>\n",
       "      <th>feature_15015</th>\n",
       "      <th>feature_10522</th>\n",
       "      <th>feature_5862</th>\n",
       "      <th>feature_15686</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>token_0</th>\n",
       "      <td>Light</td>\n",
       "      <td>lighting</td>\n",
       "      <td>Light</td>\n",
       "      <td>nakalista</td>\n",
       "      <td>Sight</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_1</th>\n",
       "      <td>LIGHT</td>\n",
       "      <td>Lighting</td>\n",
       "      <td>Light</td>\n",
       "      <td>aarrggbb</td>\n",
       "      <td>Might</td>\n",
       "      <td>tttt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_2</th>\n",
       "      <td>Light</td>\n",
       "      <td>lights</td>\n",
       "      <td>LIGHT</td>\n",
       "      <td>osu</td>\n",
       "      <td>sight</td>\n",
       "      <td>tt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_3</th>\n",
       "      <td>LIGHT</td>\n",
       "      <td>Lighting</td>\n",
       "      <td>light</td>\n",
       "      <td>«</td>\n",
       "      <td>ght</td>\n",
       "      <td>ttt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_4</th>\n",
       "      <td>light</td>\n",
       "      <td>illumination</td>\n",
       "      <td>light</td>\n",
       "      <td>avi</td>\n",
       "      <td>Might</td>\n",
       "      <td>tet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_5</th>\n",
       "      <td>light</td>\n",
       "      <td>LIGHTS</td>\n",
       "      <td>Heavy</td>\n",
       "      <td>而已</td>\n",
       "      <td>Sight</td>\n",
       "      <td>zt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_6</th>\n",
       "      <td>Licht</td>\n",
       "      <td>oświet</td>\n",
       "      <td>Heavy</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>right</td>\n",
       "      <td>ت</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_7</th>\n",
       "      <td>LIGHTS</td>\n",
       "      <td>lighted</td>\n",
       "      <td>LIGHT</td>\n",
       "      <td>XtraEditors</td>\n",
       "      <td>Right</td>\n",
       "      <td>lt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_8</th>\n",
       "      <td>ligh</td>\n",
       "      <td>lamps</td>\n",
       "      <td>heavy</td>\n",
       "      <td>_]</td>\n",
       "      <td>bottomRight</td>\n",
       "      <td>tert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_9</th>\n",
       "      <td>Licht</td>\n",
       "      <td>照明</td>\n",
       "      <td>Weight</td>\n",
       "      <td>fiez</td>\n",
       "      <td>pleaſure</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature_6482  feature_13013 feature_15015 feature_10522 feature_5862  \\\n",
       "token_0        Light       lighting         Light     nakalista        Sight   \n",
       "token_1        LIGHT       Lighting         Light      aarrggbb        Might   \n",
       "token_2        Light         lights         LIGHT           osu        sight   \n",
       "token_3        LIGHT       Lighting         light             «          ght   \n",
       "token_4        light   illumination         light           avi        Might   \n",
       "token_5        light         LIGHTS         Heavy            而已        Sight   \n",
       "token_6        Licht         oświet         Heavy         <eos>        right   \n",
       "token_7       LIGHTS        lighted         LIGHT   XtraEditors        Right   \n",
       "token_8         ligh          lamps         heavy            _]  bottomRight   \n",
       "token_9        Licht             照明        Weight          fiez     pleaſure   \n",
       "\n",
       "        feature_15686  \n",
       "token_0             t  \n",
       "token_1          tttt  \n",
       "token_2            tt  \n",
       "token_3           ttt  \n",
       "token_4           tet  \n",
       "token_5            zt  \n",
       "token_6             ت  \n",
       "token_7            lt  \n",
       "token_8          tert  \n",
       "token_9          test  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_list=lightindices\n",
    "print(f\"Shape of the decoder weights {sae.W_dec.shape})\")\n",
    "print(f\"Shape of the model unembed {model.W_U.shape}\")\n",
    "projection_matrix = sae.W_dec @ model.W_U\n",
    "print(f\"Shape of the projection matrix {projection_matrix.shape}\")\n",
    "\n",
    "# then we take the top_k tokens per feature and decode them\n",
    "top_k = 10\n",
    "_, top_k_tokens = torch.topk(projection_matrix[feature_list], top_k, dim=1)\n",
    "\n",
    "\n",
    "feature_df = pd.DataFrame(\n",
    "    top_k_tokens.cpu().numpy(), index=[f\"feature_{i}\" for i in feature_list]\n",
    ").T\n",
    "feature_df.index = [f\"token_{i}\" for i in range(top_k)]\n",
    "feature_df.applymap(lambda x: model.tokenizer.decode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20a52b64-0028-41c4-8362-b542fc378a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "df9df4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the decoder weights torch.Size([16384, 3584]))\n",
      "Shape of the model unembed torch.Size([3584, 256000])\n",
      "Shape of the projection matrix torch.Size([16384, 256000])\n",
      "Shape of projection matrix rows for features: torch.Size([6, 256000])\n",
      "Shape of decoder weights for features: torch.Size([6, 3584])\n"
     ]
    }
   ],
   "source": [
    "feature_list=lightindices\n",
    "print(f\"Shape of the decoder weights {sae.W_dec.shape})\")\n",
    "print(f\"Shape of the model unembed {model.W_U.shape}\")\n",
    "projection_matrix = sae.W_dec @ model.W_U\n",
    "print(f\"Shape of the projection matrix {projection_matrix.shape}\")\n",
    "\n",
    "# Get the shape of the matrices\n",
    "print(f\"Shape of projection matrix rows for features: {projection_matrix[feature_list].shape}\")\n",
    "print(f\"Shape of decoder weights for features: {sae.W_dec[feature_list].shape}\")\n",
    "\n",
    "# Create mappings from list indices to matrix rows\n",
    "feature_to_projection = {feature: projection_matrix[feature].tolist() for feature in feature_list}\n",
    "feature_to_decoder = {feature: sae.W_dec[feature].tolist() for feature in feature_list}\n",
    "\n",
    "json.dump(feature_to_projection, open(\"feature_to_projection.json\", \"w\"))\n",
    "json.dump(feature_to_decoder, open(\"feature_to_decoder.json\", \"w\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0da72565-422e-4592-b9c8-d8ca8cad64c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3584"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_to_decoder[6482])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46d0e89f-a279-4d99-9020-5e33f009a5a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16384, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nonzero(cache[\"blocks.20.hook_resid_post.hook_sae_acts_pre\"][0, -1, :]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "712a3e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def line_in_isolation(line):\n",
    "    prompt=f\"{line}\\n\"\n",
    "    _, cache = model.run_with_cache_with_saes(prompt, saes=[sae])\n",
    "    return cache[\"blocks.20.hook_resid_post.hook_sae_acts_pre\"][0, -2:, :]\n",
    "\n",
    "def line_with_prompt(line):\n",
    "    prompt=f\"A rhymed couplet:\\n{line}\\n\"\n",
    "    _, cache = model.run_with_cache_with_saes(prompt, saes=[sae])\n",
    "    return cache[\"blocks.20.hook_resid_post.hook_sae_acts_pre\"][0, -2:, :]\n",
    "\n",
    "def line_as_second_line(line,lines):\n",
    "    prompt=f\"A rhymed couplet:\\n{random.choice(lines)}\\n{line}\\n\"   \n",
    "    _, cache = model.run_with_cache_with_saes(prompt, saes=[sae])\n",
    "    return cache[\"blocks.20.hook_resid_post.hook_sae_acts_pre\"][0, -2:, :]\n",
    "\n",
    "def rhyme_latent_experiment(line,lines,latent):\n",
    "    iso=line_in_isolation(line)[:,latent]\n",
    "    prompt=line_with_prompt(line)[:,latent]\n",
    "    second=line_as_second_line(line,lines)[:,latent]\n",
    "    #return #iso,prompt,second,\n",
    "    return {idx:{\"isolation\":{\"last_word\":iso[:,i][0].item(),\n",
    "                                                \"newline\":iso[:,i][1].item()\n",
    "                                               },\n",
    "                 \"as_first_rhyming_line\":{\"last_word\":prompt[:,i][0].item(), \n",
    "                                          \"newline\":prompt[:,i][1].item()\n",
    "                                         },\n",
    "                 \"as_second_rhyming_line\": {\"last_word\":second[:,i][0].item(),\n",
    "                                            \"newline\":second[:,i][1].item()\n",
    "                                           },\n",
    "                                  }\n",
    "            for i,idx in enumerate(latent)}\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "18a11c1f-ea7c-44d3-9765-5d58091b5946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{6482: {'isolation': {'last_word': 0.9741425514221191,\n",
       "   'newline': -3.280390977859497},\n",
       "  'as_first_rhyming_line': {'last_word': 2.0334839820861816,\n",
       "   'newline': -3.386657238006592},\n",
       "  'as_second_rhyming_line': {'last_word': 3.541220188140869,\n",
       "   'newline': -3.446735382080078}},\n",
       " 13013: {'isolation': {'last_word': 3.6195836067199707,\n",
       "   'newline': 2.4652953147888184},\n",
       "  'as_first_rhyming_line': {'last_word': 2.981973648071289,\n",
       "   'newline': 2.931915760040283},\n",
       "  'as_second_rhyming_line': {'last_word': 2.5383620262145996,\n",
       "   'newline': -1.318196415901184}},\n",
       " 15015: {'isolation': {'last_word': -3.0132195949554443,\n",
       "   'newline': -6.108500957489014},\n",
       "  'as_first_rhyming_line': {'last_word': -1.8065648078918457,\n",
       "   'newline': -5.05793571472168},\n",
       "  'as_second_rhyming_line': {'last_word': -1.403393030166626,\n",
       "   'newline': -5.634247303009033}},\n",
       " 10522: {'isolation': {'last_word': 0.1568005084991455,\n",
       "   'newline': -1.8580756187438965},\n",
       "  'as_first_rhyming_line': {'last_word': -1.2240486145019531,\n",
       "   'newline': -0.7179728746414185},\n",
       "  'as_second_rhyming_line': {'last_word': -5.966663360595703,\n",
       "   'newline': 1.9537760019302368}},\n",
       " 5862: {'isolation': {'last_word': 3.2629714012145996,\n",
       "   'newline': -1.227510929107666},\n",
       "  'as_first_rhyming_line': {'last_word': 6.159430980682373,\n",
       "   'newline': 0.06599712371826172},\n",
       "  'as_second_rhyming_line': {'last_word': 5.984931468963623,\n",
       "   'newline': -1.9163670539855957}},\n",
       " 15686: {'isolation': {'last_word': 5.7537689208984375,\n",
       "   'newline': -4.994210720062256},\n",
       "  'as_first_rhyming_line': {'last_word': 7.743808746337891,\n",
       "   'newline': -4.210968017578125},\n",
       "  'as_second_rhyming_line': {'last_word': 7.363626480102539,\n",
       "   'newline': -5.079270362854004}}}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rhyme_latent_experiment(night_rhymes[2],nightlines,lightindices) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3dade311",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:10<00:00,  1.41it/s]\n"
     ]
    }
   ],
   "source": [
    "exp={}\n",
    "for line in tqdm(night_rhymes): exp[line]=rhyme_latent_experiment(line,night_rhymes,lightindices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "2dfa9164-d960-4a27-bf99-810892138329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(exp.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2dccc337",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sae_light_latents.json\", \"w\") as f:\n",
    "    json.dump(exp, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "071dcfce-d4a2-483d-9b46-35d72b10d888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"line_catalog.json\",'r') as f: \n",
    "    line_catalog=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7468d253-c516-4193-a702-3d5fb6a5cfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_rhymes=line_catalog[\"sleep_rhymes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c79a6c66-a041-4d11-ba88-84e211e3e2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_examples=[l for l in sleep_rhymes if \"keep\" in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b0b51726-3f30-49dd-9542-c09fae6222d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4631, 3064, 211, 6880, 12789, 7858, 1831, 3400, 7719, 15295, 466, 7681, 9787, 7998, 5202, 7284, 7212]\n"
     ]
    }
   ],
   "source": [
    "keeplatents=get_last_word_latents(keep_examples)\n",
    "print(keeplatents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ab3bbf-9c0f-45fc-b7d7-ed1bae5dad42",
   "metadata": {},
   "outputs": [],
   "source": [
    "keepindices=[4631, #word keep\n",
    " #3064, \n",
    " #211, \n",
    " #6880, \n",
    " 12789, #store, capture \n",
    " 7858, #keep, maintain, stay \n",
    "# 1831, \n",
    " #3400, \n",
    " #7719, \n",
    " #15295, \n",
    " #466, \n",
    " #7681, \n",
    " #9787, \n",
    " 7998, #vaguely memories \n",
    " 5202, #secrets \n",
    " #7284, #vaguely sport\n",
    " #7212\n",
    "            ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "8e5a06f6-893a-4b95-bf30-8c84ba8450a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a5151d7f-62fd-4ffe-8ab8-f6d91774d790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"600\"\n",
       "            src=\"https://www.neuronpedia.org/gemma-2-9b-it/20-gemmascope-res-16k/7212?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f78f0b4e390>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#explore latents manually\n",
    "if i<len(keeplatents)-1:\n",
    "    i+=1\n",
    "    html = get_dashboard_html(\n",
    "        sae_release=\"gemma-2-9b-it\", sae_id=\"20-gemmascope-res-16k\", feature_idx=keeplatents[i]\n",
    "    )\n",
    "IFrame(html, width=1200, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "ba51c228-af0c-4545-94e5-d35bda210b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_examples=[l for l in sleep_rhymes if \"deep\" in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6348932b-4be1-4a66-8565-9112e324fb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplatents=get_last_word_latents(deep_examples)\n",
    "deeplatents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59dd65d2-3c5b-442f-8f19-fae24de99607",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepindices=[\n",
    "    4400, #deep, profound\n",
    "#771\n",
    "#211\n",
    "#6880\n",
    "#7719\n",
    "#9922\n",
    "#8081\n",
    "#1831\n",
    "6964, #adjectives tight thick bright heavy\n",
    "14069, # candidate rhyme latent\n",
    "#3064\n",
    "14011, #depth and surface\n",
    "#7284\n",
    "#13844\n",
    "#12120\n",
    "13637, # letter d\n",
    "#9653\n",
    "#2489\n",
    "7068, # adjectives hard, raw, wild\n",
    "#12114\n",
    "#12683\n",
    "#3994\n",
    "#8288\n",
    "#7903\n",
    "8344, #up and down\n",
    "#3400\n",
    "#7051\n",
    "#2307\n",
    "#7212\n",
    "#16266\n",
    "#2743\n",
    "#1660\n",
    "#11757\n",
    "#11201    \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d593ff9d-f7cc-44a6-bf22-1744efcdd147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(deepindices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "db3ce3ee-d781-4546-9400-56cfed111409",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "477d94fe-0142-4e8a-8d8c-a8779e01f2b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"600\"\n",
       "            src=\"https://www.neuronpedia.org/gemma-2-9b-it/20-gemmascope-res-16k/11201?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f78f2575950>"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#explore latents manually\n",
    "if i<len(deeplatents)-1:\n",
    "    i+=1\n",
    "    html = get_dashboard_html(\n",
    "        sae_release=\"gemma-2-9b-it\", sae_id=\"20-gemmascope-res-16k\", feature_idx=deeplatents[i]\n",
    "    )\n",
    "IFrame(html, width=1200, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f25345fd-a554-4363-a7ef-864eddaf7932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the decoder weights torch.Size([16384, 3584]))\n",
      "Shape of the model unembed torch.Size([3584, 256000])\n",
      "Shape of the projection matrix torch.Size([16384, 256000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182/65076785.py:16: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  feature_df.applymap(lambda x: model.tokenizer.decode(x))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_4400</th>\n",
       "      <th>feature_6964</th>\n",
       "      <th>feature_14069</th>\n",
       "      <th>feature_14011</th>\n",
       "      <th>feature_13637</th>\n",
       "      <th>feature_7068</th>\n",
       "      <th>feature_8344</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>token_0</th>\n",
       "      <td>deep</td>\n",
       "      <td>Wet</td>\n",
       "      <td>lp</td>\n",
       "      <td>deep</td>\n",
       "      <td>D</td>\n",
       "      <td>Raw</td>\n",
       "      <td>########.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_1</th>\n",
       "      <td>DEEP</td>\n",
       "      <td>Heavy</td>\n",
       "      <td>Kip</td>\n",
       "      <td>deeper</td>\n",
       "      <td>d</td>\n",
       "      <td>raw</td>\n",
       "      <td>autorytatywna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_2</th>\n",
       "      <td>Deep</td>\n",
       "      <td>enough</td>\n",
       "      <td>dp</td>\n",
       "      <td>deep</td>\n",
       "      <td>DD</td>\n",
       "      <td>Raw</td>\n",
       "      <td>+#+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_3</th>\n",
       "      <td>Deep</td>\n",
       "      <td>Wet</td>\n",
       "      <td>KAP</td>\n",
       "      <td>depth</td>\n",
       "      <td>DM</td>\n",
       "      <td>Hot</td>\n",
       "      <td>ब्रेकडाउन</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_4</th>\n",
       "      <td>deep</td>\n",
       "      <td>Empty</td>\n",
       "      <td>Jep</td>\n",
       "      <td>depth</td>\n",
       "      <td>DMD</td>\n",
       "      <td>Hot</td>\n",
       "      <td>OGND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_5</th>\n",
       "      <td>profundo</td>\n",
       "      <td>WET</td>\n",
       "      <td>dp</td>\n",
       "      <td>Deeper</td>\n",
       "      <td>DT</td>\n",
       "      <td>hot</td>\n",
       "      <td>Infórmanos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_6</th>\n",
       "      <td>deeply</td>\n",
       "      <td>ymce</td>\n",
       "      <td>yp</td>\n",
       "      <td>depths</td>\n",
       "      <td>DX</td>\n",
       "      <td>wild</td>\n",
       "      <td>DockStyle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_7</th>\n",
       "      <td>profundos</td>\n",
       "      <td>Heavy</td>\n",
       "      <td>qp</td>\n",
       "      <td>deeply</td>\n",
       "      <td>DV</td>\n",
       "      <td>WILD</td>\n",
       "      <td>GenerationType</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_8</th>\n",
       "      <td>depth</td>\n",
       "      <td>Weird</td>\n",
       "      <td>Lippincott</td>\n",
       "      <td>Deep</td>\n",
       "      <td>DPM</td>\n",
       "      <td>RAW</td>\n",
       "      <td>Parcelize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_9</th>\n",
       "      <td>Depth</td>\n",
       "      <td>Enough</td>\n",
       "      <td>Kip</td>\n",
       "      <td>deepest</td>\n",
       "      <td>DAM</td>\n",
       "      <td>Hard</td>\n",
       "      <td>InputBorder</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature_4400 feature_6964 feature_14069 feature_14011 feature_13637  \\\n",
       "token_0         deep          Wet            lp          deep             D   \n",
       "token_1         DEEP        Heavy           Kip        deeper             d   \n",
       "token_2         Deep       enough            dp          deep            DD   \n",
       "token_3         Deep          Wet           KAP         depth            DM   \n",
       "token_4         deep        Empty           Jep         depth           DMD   \n",
       "token_5     profundo          WET            dp        Deeper            DT   \n",
       "token_6       deeply         ymce            yp        depths            DX   \n",
       "token_7    profundos        Heavy            qp        deeply            DV   \n",
       "token_8        depth        Weird    Lippincott          Deep           DPM   \n",
       "token_9        Depth       Enough           Kip       deepest           DAM   \n",
       "\n",
       "        feature_7068     feature_8344  \n",
       "token_0          Raw        ########.  \n",
       "token_1          raw    autorytatywna  \n",
       "token_2          Raw              +#+  \n",
       "token_3          Hot        ब्रेकडाउन  \n",
       "token_4          Hot             OGND  \n",
       "token_5          hot       Infórmanos  \n",
       "token_6         wild        DockStyle  \n",
       "token_7         WILD   GenerationType  \n",
       "token_8          RAW        Parcelize  \n",
       "token_9         Hard      InputBorder  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_list=deepindices\n",
    "print(f\"Shape of the decoder weights {sae.W_dec.shape})\")\n",
    "print(f\"Shape of the model unembed {model.W_U.shape}\")\n",
    "projection_matrix = sae.W_dec @ model.W_U\n",
    "print(f\"Shape of the projection matrix {projection_matrix.shape}\")\n",
    "\n",
    "# then we take the top_k tokens per feature and decode them\n",
    "top_k = 10\n",
    "_, top_k_tokens = torch.topk(projection_matrix[feature_list], top_k, dim=1)\n",
    "\n",
    "\n",
    "feature_df = pd.DataFrame(\n",
    "    top_k_tokens.cpu().numpy(), index=[f\"feature_{i}\" for i in feature_list]\n",
    ").T\n",
    "feature_df.index = [f\"token_{i}\" for i in range(top_k)]\n",
    "feature_df.applymap(lambda x: model.tokenizer.decode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5029ab9f-08f4-45bb-91c4-14d5cb43043a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:09<00:00,  1.43it/s]\n"
     ]
    }
   ],
   "source": [
    "exp={}\n",
    "for line in tqdm(sleep_rhymes): exp[line]=rhyme_latent_experiment(line,sleep_rhymes,deepindices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f1c8fd7-d3f6-4ae3-95b7-e1986e1fbbb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(exp.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08c20dc4-9b2c-418d-8b79-5e09f361ddac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sae_deep_latents.json\", \"w\") as f:\n",
    "    json.dump(exp, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98f6a88c-e278-4134-aea5-9ab862e1fe24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the decoder weights torch.Size([16384, 3584]))\n",
      "Shape of the model unembed torch.Size([3584, 256000])\n",
      "Shape of the projection matrix torch.Size([16384, 256000])\n",
      "Shape of projection matrix rows for features: torch.Size([7, 256000])\n",
      "Shape of decoder weights for features: torch.Size([7, 3584])\n"
     ]
    }
   ],
   "source": [
    "feature_list=deepindices\n",
    "print(f\"Shape of the decoder weights {sae.W_dec.shape})\")\n",
    "print(f\"Shape of the model unembed {model.W_U.shape}\")\n",
    "projection_matrix = sae.W_dec @ model.W_U\n",
    "print(f\"Shape of the projection matrix {projection_matrix.shape}\")\n",
    "\n",
    "# Get the shape of the matrices\n",
    "print(f\"Shape of projection matrix rows for features: {projection_matrix[feature_list].shape}\")\n",
    "print(f\"Shape of decoder weights for features: {sae.W_dec[feature_list].shape}\")\n",
    "\n",
    "# Create mappings from list indices to matrix rows\n",
    "feature_to_projection = {feature: projection_matrix[feature].tolist() for feature in feature_list}\n",
    "feature_to_decoder = {feature: sae.W_dec[feature].tolist() for feature in feature_list}\n",
    "\n",
    "json.dump(feature_to_projection, open(\"feature_to_projection_deep_rhyme_latent.json\", \"w\"))\n",
    "json.dump(feature_to_decoder, open(\"feature_to_decoder.json_deep_rhyme_latent\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff03556-c13b-4a78-9b7f-b94a4b272da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_to_projection[14069]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d21ff7c-c23a-4724-bfa4-0752ab73ca1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(\n",
    "    cache[\"blocks.20.hook_resid_post.hook_sae_acts_post\"][0, -1, :].cpu().numpy(),\n",
    "    title=\"Feature activations at the final token position\",\n",
    "    labels={\"index\": \"Feature\", \"value\": \"Activation\"},\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5f79809d-2761-4dad-ab8a-8d0921416312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5afde09cdadd466c9cd69fd1c59efd5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normal text (without steering):\n",
      "A rhymed couplet:\n",
      "Through muddy fields we trudged with walking stick\n",
      "and saw a horse, a man and a donkey kick\n",
      "They were all galloping and running fast\n",
      "With fear of being caught in the mud.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba6971bc7304448e87db28f261f6de2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steered text with latent 5862:\n",
      "<bos>A rhymed couplet:\n",
      "Through muddy fields we trudged with walking stick\n",
      "Then out of nowhere, a light appeared.\n",
      "\n",
      "It was a beautiful night.\n",
      "I sat at the table and read a book.\n",
      "The book\n",
      "****************************************\n",
      "Steered text with latent 13013:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe7b0ffb6a734455af8e9161a8364c52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steered text:\n",
      "<bos>A rhymed couplet:\n",
      "Through muddy fields we trudged with walking stick\n",
      "In a dark spot we watched the night\n",
      "We were walking along the path in a dark spot\n",
      "We were walking along the path in a dark spot\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "def find_max_activation(model, sae, activation_store, feature_idx, num_batches=100):\n",
    "    \"\"\"\n",
    "    Find the maximum activation for a given feature index. This is useful for\n",
    "    calibrating the right amount of the feature to add.\n",
    "    \"\"\"\n",
    "    max_activation = 0.0\n",
    "\n",
    "    pbar = tqdm(range(num_batches))\n",
    "    for _ in pbar:\n",
    "        tokens = activation_store.get_batch_tokens()\n",
    "\n",
    "        _, cache = model.run_with_cache(\n",
    "            tokens,\n",
    "            stop_at_layer=sae.cfg.hook_layer + 1,\n",
    "            names_filter=[sae.cfg.hook_name],\n",
    "        )\n",
    "        sae_in = cache[sae.cfg.hook_name]\n",
    "        feature_acts = sae.encode(sae_in).squeeze()\n",
    "\n",
    "        feature_acts = feature_acts.flatten(0, 1)\n",
    "        batch_max_activation = feature_acts[:, feature_idx].max().item()\n",
    "        max_activation = max(max_activation, batch_max_activation)\n",
    "\n",
    "        pbar.set_description(f\"Max activation: {max_activation:.4f}\")\n",
    "\n",
    "    return max_activation\n",
    "\n",
    "\n",
    "def steering(\n",
    "    activations, hook, steering_strength=1.0, steering_vector=None, max_act=1.0\n",
    "):\n",
    "    # Note if the feature fires anyway, we'd be adding to that here.\n",
    "    return activations + max_act * steering_strength * steering_vector\n",
    "\n",
    "\n",
    "def generate_with_steering(\n",
    "    model,\n",
    "    sae,\n",
    "    prompt,\n",
    "    steering_feature,\n",
    "    max_act,\n",
    "    steering_strength=1.0,\n",
    "    max_new_tokens=95,\n",
    "):\n",
    "    input_ids = model.to_tokens(prompt, prepend_bos=sae.cfg.prepend_bos)\n",
    "\n",
    "    steering_vector = sae.W_dec[steering_feature].to(model.cfg.device)\n",
    "\n",
    "    steering_hook = partial(\n",
    "        steering,\n",
    "        steering_vector=steering_vector,\n",
    "        steering_strength=steering_strength,\n",
    "        max_act=max_act,\n",
    "    )\n",
    "\n",
    "    # standard transformerlens syntax for a hook context for generation\n",
    "    with model.hooks(fwd_hooks=[(sae.cfg.hook_name, steering_hook)]):\n",
    "        output = model.generate(\n",
    "            input_ids,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=0.7,\n",
    "            #top_p=0.9,\n",
    "            stop_at_eos=False if device == \"mps\" else True,\n",
    "            prepend_bos=sae.cfg.prepend_bos,\n",
    "        )\n",
    "\n",
    "    return model.tokenizer.decode(output[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# note we could also get the max activation from Neuronpedia (https://www.neuronpedia.org/api-doc#tag/lookup/GET/api/feature/{modelId}/{layer}/{index})\n",
    "\n",
    "# Generate text without steering for comparison\n",
    "prompt = \"A rhymed couplet:\\nThrough muddy fields we trudged with walking stick\\n\"\n",
    "normal_text = model.generate(\n",
    "    prompt,\n",
    "    max_new_tokens=30,\n",
    "    temperature=0.7,\n",
    "    stop_at_eos=False if device == \"mps\" else True,\n",
    "    prepend_bos=sae.cfg.prepend_bos,\n",
    ")\n",
    "\n",
    "print(\"\\nNormal text (without steering):\")\n",
    "print(normal_text)\n",
    "\n",
    "# Generate text with steering\n",
    "steered_text = generate_with_steering(\n",
    "    model, sae, prompt, steering_feature, 70, steering_strength=2.0, max_new_tokens=30\n",
    ")\n",
    "\n",
    "# Choose a feature to steer\n",
    "steering_feature = lightindices[4]  # Choose a feature to steer towards\n",
    "\n",
    "print(f\"Steered text with latent {steering_feature}:\")\n",
    "print(steered_text)\n",
    "\n",
    "print(\"*\"*40)\n",
    "# Choose a feature to steer\n",
    "steering_feature = lightindices[1]  # Choose a feature to steer towards\n",
    "\n",
    "print(f\"Steered text with latent {steering_feature}:\")\n",
    "steered_text = generate_with_steering(\n",
    "    model, sae, prompt, steering_feature, 70, steering_strength=2.0, max_new_tokens=30\n",
    ")\n",
    "print(\"Steered text:\")\n",
    "print(steered_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c93e28-a5bb-4ca8-8837-20f6094dc3f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe65944-a3c2-45c4-9ba6-29e652287d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
