{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3574e96c-c144-4891-b94b-d6c6b7d30893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.8.0.dev20250319+cu128)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.8.0.87 in /usr/local/lib/python3.11/dist-packages (from torch) (9.8.0.87)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.3.14 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.3.14)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.41 in /usr/local/lib/python3.11/dist-packages (from torch) (11.3.3.41)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.55 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.9.55)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.2.55 in /usr/local/lib/python3.11/dist-packages (from torch) (11.7.2.55)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.7.53 in /usr/local/lib/python3.11/dist-packages (from torch) (12.5.7.53)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.25.1 in /usr/local/lib/python3.11/dist-packages (from torch) (2.25.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.55 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.55)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.0.11 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.0.11)\n",
      "Requirement already satisfied: pytorch-triton==3.3.0+git96316ce5 in /usr/local/lib/python3.11/dist-packages (from torch) (3.3.0+git96316ce5)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-triton==3.3.0+git96316ce5->torch) (77.0.1)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
      "Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m261.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.6.0-py3-none-any.whl (354 kB)\n",
      "Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m335.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.7/792.7 kB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m217.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, safetensors, regex, huggingface-hub, tokenizers, transformers, bitsandbytes, accelerate\n",
      "Successfully installed accelerate-1.6.0 bitsandbytes-0.45.5 huggingface-hub-0.30.2 regex-2024.11.6 safetensors-0.5.3 tokenizers-0.21.1 tqdm-4.67.1 transformers-4.51.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch transformers accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da8ba943-d649-4246-b1dc-27c3c9427024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting einops\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Installing collected packages: einops\n",
      "Successfully installed einops-0.8.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfc56b34-1337-49da-9ff5-838f1b34886e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f86c406-ad02-4853-9622-bf059dc4fdfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.8.0.dev20250319+cu128\n",
      "Transformers version: 4.51.3\n",
      "CUDA available: True\n",
      "CUDA version: 12.8\n",
      "Current device: 0\n",
      "Device name: NVIDIA A100 80GB PCIe\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import os\n",
    "import gc\n",
    "from contextlib import contextmanager\n",
    "from typing import List, Dict, Optional, Callable\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Transformers version: {transformers.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Current device: {torch.cuda.current_device()}\")\n",
    "    print(f\"Device name: {torch.cuda.get_device_name(torch.cuda.current_device())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b050ffae-a61c-4121-b557-336b62061778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face login successful (using provided token).\n"
     ]
    }
   ],
   "source": [
    "# @title 1.5. For access to Gemma models, log in to HuggingFace \n",
    "from huggingface_hub import login\n",
    "HUGGING_FACE_TOKEN = \"TOKEN\"\n",
    "try:\n",
    "     login(token=HUGGING_FACE_TOKEN)\n",
    "     print(\"Hugging Face login successful (using provided token).\")\n",
    "except Exception as e:\n",
    "     print(f\"Hugging Face login failed. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b374fa95-6a55-4a84-9e50-1411985db57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"google/gemma-2-9b-it\" # Or \"google/gemma-2-9b\" if you prefer the base model\n",
    "# Set to True if you have limited VRAM (e.g., < 24GB). Requires bitsandbytes\n",
    "USE_4BIT_QUANTIZATION = False\n",
    "\n",
    "# --- Steering Configuration ---\n",
    "# !! IMPORTANT !! Find the correct layer name for your model.\n",
    "# Example: 'model.layers[15].mlp.gate_proj' or 'model.layers[20].self_attn.o_proj'\n",
    "# Use the `print(model)` output in Section 3 to find a suitable layer name.\n",
    "TARGET_LAYER_NAME = 'model.layers.20' # <--- CHANGE THIS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02de826a-19e8-4f99-8c67-b7e10223a686",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEERING_MULTIPLIER = 1.5\n",
    "\n",
    "# --- Generation Parameters ---\n",
    "MAX_NEW_TOKENS = 150\n",
    "TEMPERATURE = 0.7\n",
    "DO_SAMPLE = True\n",
    "\n",
    "# --- Output ---\n",
    "OUTPUT_FILE = \"gemma2_steering_output.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cac79d20-d9a8-4ce0-af47-fb923fd5488c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "'''lines_that_rhyme_with_rabbit = [\n",
    "    \"The gardener tends his plants with daily habit\",\n",
    "    \"When paint spills on the floor, you need to dabbit\",\n",
    "    \"If you see something you want, just reach and grabbit\",\n",
    "    \"The monastery's leader is the wise old abbot\",\n",
    "    \"The metal alloy used in engines is called babbit\",\n",
    "    \"The chef prepared a stew with fresh green cabbage\",\n",
    "    \"The seamstress chose a silky, flowing fabric\",\n",
    "    \"The storm that passed through town caused so much havoc\",\n",
    "    \"The wizard cast a spell with ancient magic\",\n",
    "    \"The rotting food attracted many a maggot\",\n",
    "    \"The critic's harsh review was truly savage\",\n",
    "    \"The radio produced annoying static\",\n",
    "    \"The ancient message carved upon a tablet\",\n",
    "    \"Their agreement to proceed remained quite tacit\",\n",
    "    \"We sat for hours in the morning traffic\",\n",
    "    \"The ending of the play was deeply tragic\",\n",
    "]'''\n",
    "\n",
    "lines_that_rhyme_with_quick = [\n",
    "    \"The house was built with sturdy, reddish brick\",\n",
    "    \"The camera captured moments with each click\",\n",
    "    \"She turned the lights on with a simple flick\",\n",
    "    \"The soccer player gave the ball a mighty kick\",\n",
    "    \"The puppy gave my hand a gentle lick\",\n",
    "    \"The razor left a small and painful nick\",\n",
    "    \"From all the fruits available, I'll make my pick\",\n",
    "    \"The rose's thorn can cause a sudden prick\",\n",
    "    \"He stayed at home because he felt too sick\",\n",
    "    \"The rain had made the winding road quite slick\",\n",
    "    \"The child drew pictures with a charcoal stick\",\n",
    "    \"The winter fog was rolling in so thick\",\n",
    "    \"The clock marked every second with a tick\",\n",
    "    \"The magician performed an amazing trick\",\n",
    "    \"The candle slowly burned down to the wick\",\n",
    "]\n",
    "\n",
    "lines_that_rhyme_with_pain = [\n",
    "    \"The storm has passed but soon will come again\",\n",
    "    \"The wizard's knowledge was profoundly arcane\",\n",
    "    \"That constant noise became my existence's bane\",\n",
    "    \"The puzzle challenged every corner of my brain\",\n",
    "    \"The elderly man walked slowly with his cane\",\n",
    "    \"The prisoner rattled his heavy iron chain\",\n",
    "    \"The construction site had a towering crane\",\n",
    "    \"The queen would rarely to respond deign\",\n",
    "    \"The rainwater flowed down into the drain\",\n",
    "    \"She looked at the offer with obvious disdain\",\n",
    "    \"The king surveyed his vast and wealthy domain\",\n",
    "    \"The teacher took her time to clearly explain\",\n",
    "    \"He tried to hide his feelings and to feign\",\n",
    "    \"The pilgrims journeyed to the ancient fane\",\n",
    "    \"The athlete trained for months to make a gain\",\n",
    "    \"The farmer harvested the golden grain\",\n",
    "    \"The doctor's treatment was gentle and humane\",\n",
    "    \"His argument was completely inane\",\n",
    "    \"The plan they proposed was utterly insane\",\n",
    "    \"The classic novel starred a heroine named Jane\",\n",
    "    \"The car sped down the narrow country lane\",\n",
    "    \"The issue at hand was certainly the main\",\n",
    "    \"The lion shook his magnificent mane\",\n",
    "    \"The office work felt repetitive and mundane\",\n",
    "    \"The church would soon the new priest ordain\",\n",
    "    \"The sunlight streamed through the window pane\",\n",
    "    \"The message written there was crystal plain\",\n",
    "    \"The travelers boarded the waiting plane\",\n",
    "    \"His language was considered quite profane\",\n",
    "    \"The flowers bloomed after the gentle rain\",\n",
    "    \"The rider pulled firmly on the horse's rein\",\n",
    "    \"The king began his long and peaceful reign\",\n",
    "    \"Despite the chaos, she remained quite sane\",\n",
    "    \"We planned our summer holiday in Spain\",\n",
    "    \"The athlete suffered from a painful ankle sprain\",\n",
    "    \"The red wine left a permanent stain\",\n",
    "    \"The heavy lifting put his back under strain\",\n",
    "    \"Good habits help your health maintain and sustain\",\n",
    "    \"The maiden was courted by a handsome swain\",\n",
    "    \"We hurried to catch the departing train\",\n",
    "    \"The river split the land in twain\",\n",
    "    \"His manner was sophisticated and urbane\",\n",
    "    \"Her efforts to convince him were in vain\",\n",
    "    \"The wind direction showed on the weather vane\",\n",
    "    \"The nurse carefully located a suitable vein\",\n",
    "    \"As night approached, the daylight began to wane\",\n",
    "]\n",
    "\n",
    "lines_that_rhyme_with_rabbit = [\n",
    "    \"I saw something move in the garden, so I decided to grab it\", # To my surprise, it turned out to be a fluffy little rabbit.\n",
    "    \"When you hear a noise in the bushes, don't be afraid to nab it\", # Chances are it's just the neighborhood's friendly rabbit.\n",
    "    \"She has a special way with animals, it's quite a habit\", # Her favorite creature to care for is her pet rabbit.\n",
    "    \"I thought I'd plant some carrots, but something came to stab it\", # I looked outside and caught the culprit—a hungry rabbit.\n",
    "    \"The magician pulled something furry out of his hat, to my amazement he had it\", # The audience cheered when they saw it was a snow-white rabbit.\n",
    "    \"If you find a hole in your garden, you should probably tab it\", # It's likely the new underground home of a burrowing rabbit.\n",
    "    \"The child saw something soft in the pet store and wanted to have it\", # She begged her parents until they bought her that adorable rabbit.\n",
    "    \"I heard a rustling sound in the forest and tried to dab it\", # But it hopped away quickly—I just missed that wild rabbit.\n",
    "    \"When something nibbles your lettuce, there's no need to blab it\", # Everyone knows the culprit is probably a garden rabbit.\n",
    "    \"I felt something soft brush against my leg, I reached down to grab it\", # And found myself petting the silky fur of a friendly rabbit.\n",
    "]\n",
    "\n",
    "lines_that_rhyme_with_habit = [\n",
    "    \"When you see a rabbit\", # You might form a feeding habit.\n",
    "    \"He'd grab it if he could just nab it\", # That's become his daily habit.\n",
    "    \"The frog sits on the lily pad, a bit\", # Too long—it's turned into a habit.\n",
    "    \"She wears that jacket like she's glad to have it\", # Dressing sharp has always been her habit.\n",
    "    \"I know I should quit, but I just can't stab it\", # Breaking free from such a stubborn habit.\n",
    "    \"If there's a chance for joy, I'll always grab it\", # Seeking happiness is my best habit.\n",
    "    \"The cat will chase the yarn if you dab it\", # Playing games has been a lifelong habit.\n",
    "    \"When faced with problems, I don't just blab it\", # Thinking before speaking is my habit.\n",
    "    \"He'll take a compliment, but never crab it\", # Staying humble is his finest habit.\n",
    "    \"The chef will taste the dish before they tab it\", # Quality control's a professional habit.\n",
    "    \"When opportunity knocks, I'll cab it\", # Seizing the moment is my favorite habit.\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08aff8df-1620-4553-a984-cdfc016f0f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: google/gemma-2-9b-it\n",
      "Using device: cuda\n",
      "Using dtype: torch.bfloat16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af23506592e44e84b0bb8a2565fa81ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/47.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9829350890a84beaabee9476e2c135bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed0d1d90aaf441e88d5ccf4245e4e10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b64d3fee0ba487f83ebe2e18ee00c6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6175a17470e4e89943356d0abd42b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/857 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7e85e20d76c4c1ba097e90bf11d0050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/39.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b33837182cfe406dbc8e6097d688fccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa94d3bbc89f4ce3b452593f668e1e4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/3.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "621e472576f94c30bed632301d8c0e9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33dd50e2027b4568ae34aa3fa7babe43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b5e64be0835499e928aceaf16dcdfa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2044f31f7a8d43c48d1a73bb62b10a00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c6af4d24a6e491baeef07ac9e9ce548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/173 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on device(s): {'': 0}\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# ## 3. Load Model and Tokenizer\n",
    "\n",
    "# +\n",
    "# Configure quantization if needed\n",
    "quantization_config = None\n",
    "if USE_4BIT_QUANTIZATION:\n",
    "    quantization_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16 # Recommended for new models\n",
    "    )\n",
    "    print(\"Using 4-bit quantization.\")\n",
    "\n",
    "# Determine device and dtype\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.bfloat16 if torch.cuda.is_available() and torch.cuda.get_device_capability()[0] >= 8 else torch.float32 # BF16 recommended on Ampere+\n",
    "\n",
    "print(f\"Loading model: {MODEL_ID}\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Using dtype: {dtype}\")\n",
    "\n",
    "# Load Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token # Set pad token if not present\n",
    "\n",
    "# Load Model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    torch_dtype=dtype,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"auto\", # Automatically distribute across GPUs if available\n",
    "    # use_auth_token=YOUR_HF_TOKEN, # Add if model requires authentication\n",
    "    trust_remote_code=True # Gemma requires this for some versions/variants\n",
    ")\n",
    "\n",
    "print(f\"Model loaded on device(s): {model.hf_device_map}\")\n",
    "\n",
    "# --- IMPORTANT: Finding the Layer Name ---\n",
    "# Uncomment the following line to print the model structure and find the exact layer name\n",
    "# print(model)\n",
    "# Look for layers like 'model.layers[INDEX].mlp...' or 'model.layers[INDEX].self_attn...'\n",
    "\n",
    "# Ensure model is in evaluation mode\n",
    "model.eval()\n",
    "# %%\n",
    "# ## 4. Hooking and Activation Handling Functions\n",
    "\n",
    "# +\n",
    "# Global storage for captured activations\n",
    "activation_storage = {}\n",
    "\n",
    "def get_module_by_name(model, module_name):\n",
    "    \"\"\"Helper function to get a module object from its name string.\"\"\"\n",
    "    names = module_name.split('.')\n",
    "    module = model\n",
    "    for name in names:\n",
    "        module = getattr(module, name)\n",
    "    return module\n",
    "\n",
    "def capture_activation_hook(module, input, output, layer_name):\n",
    "    \"\"\"Hook function to capture the output activation of a specific layer.\"\"\"\n",
    "    # We usually care about the last token's activation for steering calculation\n",
    "    # Output shape is often (batch_size, sequence_length, hidden_dim)\n",
    "    # Store the activation corresponding to the last token position\n",
    "    if isinstance(output, torch.Tensor):\n",
    "        activation_storage[layer_name] = output[:, -1, :].detach().cpu()\n",
    "    elif isinstance(output, tuple): # Some layers might return tuples\n",
    "        activation_storage[layer_name] = output[0][:, -1, :].detach().cpu()\n",
    "    else:\n",
    "         print(f\"Warning: Unexpected output type from layer {layer_name}: {type(output)}\")\n",
    "\n",
    "\n",
    "def get_activations(model, tokenizer, prompts: List[str], layer_name: str) -> Optional[torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Runs prompts through the model and captures activations from the target layer.\n",
    "    Returns the averaged activation across all prompts for the last token position.\n",
    "    \"\"\"\n",
    "    global activation_storage\n",
    "    activation_storage = {} # Clear previous activations\n",
    "\n",
    "    target_module = get_module_by_name(model, layer_name)\n",
    "    hook_handle = target_module.register_forward_hook(\n",
    "        lambda module, input, output: capture_activation_hook(module, input, output, layer_name)\n",
    "    )\n",
    "\n",
    "    all_layer_activations = []\n",
    "    with torch.no_grad():\n",
    "        for prompt in prompts:\n",
    "            inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
    "            # We only need the forward pass, not generation here\n",
    "            _ = model(**inputs)\n",
    "\n",
    "            if layer_name in activation_storage:\n",
    "                 # Assuming batch size is 1 when processing one prompt at a time\n",
    "                last_token_activation = activation_storage[layer_name] # Shape (1, hidden_dim)\n",
    "                all_layer_activations.append(last_token_activation)\n",
    "                del activation_storage[layer_name] # Clear for next prompt\n",
    "            else:\n",
    "                print(f\"Warning: Activation for layer {layer_name} not captured for prompt: '{prompt}'\")\n",
    "\n",
    "\n",
    "    hook_handle.remove() # Clean up the hook\n",
    "\n",
    "    if not all_layer_activations:\n",
    "        print(f\"Error: No activations were captured for layer {layer_name}.\")\n",
    "        return None\n",
    "\n",
    "    # Stack and average activations across all prompts\n",
    "    # Resulting shape: (num_prompts, hidden_dim) -> (hidden_dim)\n",
    "    avg_activation = torch.stack(all_layer_activations).mean(dim=0).squeeze() # Average over the prompt dimension\n",
    "    print(f\"Calculated average activation for layer '{layer_name}' with shape: {avg_activation.shape}\")\n",
    "    return avg_activation\n",
    "# %%\n",
    " # --- Steering Hook during Generation ---\n",
    "\n",
    "# Global variable to hold the steering vector during generation\n",
    "steering_vector_internal = None\n",
    "steering_multiplier_internal = 1.0\n",
    "\n",
    "def steering_hook(module, input, output):\n",
    "    \"\"\"Hook function to modify activations during generation.\"\"\"\n",
    "    global steering_vector_internal, steering_multiplier_internal\n",
    "    if steering_vector_internal is not None:\n",
    "        if isinstance(output, torch.Tensor):\n",
    "            # Add steering vector (broadcasts across sequence length)\n",
    "            # Shape adjustment might be needed depending on layer output structure\n",
    "            # Assuming output is (batch_size, seq_len, hidden_dim)\n",
    "            # and steering_vector is (hidden_dim)\n",
    "            modified_output = output + (steering_vector_internal.to(output.device, dtype=output.dtype) * steering_multiplier_internal)\n",
    "            return modified_output\n",
    "        elif isinstance(output, tuple): # Handle layers returning tuples\n",
    "             # Assuming the tensor to modify is the first element\n",
    "            modified_tensor = output[0] + (steering_vector_internal.to(output[0].device, dtype=output[0].dtype) * steering_multiplier_internal)\n",
    "            return (modified_tensor,) + output[1:]\n",
    "        else:\n",
    "            print(f\"Warning: Steering hook encountered unexpected output type: {type(output)}\")\n",
    "            return output # Return original if type is unknown\n",
    "    return output # Return original if no steering vector\n",
    "\n",
    "@contextmanager\n",
    "def apply_steering(model, layer_name, steering_vector, multiplier):\n",
    "    \"\"\"Context manager to temporarily apply the steering hook.\"\"\"\n",
    "    global steering_vector_internal, steering_multiplier_internal\n",
    "\n",
    "    # Ensure previous hook (if any) on the same layer is removed\n",
    "    # This basic implementation assumes only one steering hook at a time on this layer\n",
    "    # More robust solutions might track handles explicitly.\n",
    "    \n",
    "    handle = None\n",
    "    try:\n",
    "        steering_vector_internal = steering_vector\n",
    "        steering_multiplier_internal = multiplier\n",
    "        target_module = get_module_by_name(model, layer_name)\n",
    "        handle = target_module.register_forward_hook(steering_hook)\n",
    "        print(f\"Steering hook applied to {layer_name} with multiplier {multiplier}\")\n",
    "        yield # Generation happens here\n",
    "    finally:\n",
    "        if handle:\n",
    "            handle.remove()\n",
    "        steering_vector_internal = None # Clear global state\n",
    "        steering_multiplier_internal = 1.0\n",
    "        print(f\"Steering hook removed from {layer_name}\")\n",
    "        gc.collect() # Suggest garbage collection\n",
    "        torch.cuda.empty_cache() # Clear cache if using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a555671-ca82-4174-b2f5-5b55e6b090d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "POSITIVE_PROMPTS = [f'A rhymed couplet:\\n{line}\\n' for line in lines_that_rhyme_with_quick]\n",
    "NEGATIVE_PROMPTS = [f'A rhymed couplet:\\n{line}\\n' for line in lines_that_rhyme_with_pain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67e348a5-640b-44cd-b093-cc724524b00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATION_PROMPT=f'A rhymed couplet:\\n{lines_that_rhyme_with_quick[0]}\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65644726-d099-4631-94e2-a90253506840",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating activations for POSITIVE prompts...\n",
      "Calculated average activation for layer 'model.layers.20' with shape: torch.Size([3584])\n",
      "\n",
      "Calculating activations for NEGATIVE prompts...\n",
      "Calculated average activation for layer 'model.layers.20' with shape: torch.Size([3584])\n",
      "\n",
      "Steering vector computed successfully. Shape: torch.Size([3584])\n"
     ]
    }
   ],
   "source": [
    "# +\n",
    "print(\"Calculating activations for POSITIVE prompts...\")\n",
    "avg_pos_activation = get_activations(model, tokenizer, POSITIVE_PROMPTS, TARGET_LAYER_NAME)\n",
    "\n",
    "print(\"\\nCalculating activations for NEGATIVE prompts...\")\n",
    "avg_neg_activation = get_activations(model, tokenizer, NEGATIVE_PROMPTS, TARGET_LAYER_NAME)\n",
    "\n",
    "steering_vector = None\n",
    "if avg_pos_activation is not None and avg_neg_activation is not None:\n",
    "    steering_vector = avg_pos_activation - avg_neg_activation\n",
    "    print(f\"\\nSteering vector computed successfully. Shape: {steering_vector.shape}\")\n",
    "    # Optional: Normalize the steering vector (can sometimes help)\n",
    "    # steering_vector = steering_vector / torch.norm(steering_vector)\n",
    "    # print(\"Steering vector normalized.\")\n",
    "else:\n",
    "    print(\"\\nError: Could not compute steering vector due to missing activations.\")\n",
    "\n",
    "# Clean up memory\n",
    "del avg_pos_activation\n",
    "del avg_neg_activation\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "# %%\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6de46460-d3d5-4dff-a9e9-60dd65f166b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3584])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steering_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3d05b6ab-b103-4f12-b520-ce7d1f53522e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldim=3584"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e013c68b-89ba-40c1-8815-535e74a7aa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(steering_vector,\"steering_vector_from_quick_to_pain.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2cde7932-45a0-4ff9-ae3d-ec1ebd0c915d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steering_vector.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92ab4f54-c85b-465a-916a-cbfacdce4442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9fe7a62b-e504-4ab1-a352-dfec456053cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1094, 0.6250, 1.0312,  ..., 0.2266, 0.1875, 0.4473], device='cuda:0',\n",
       "       dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steering_vector.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1eaa9c2-29e9-4189-bbb8-6dcc9699f646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0510,  0.0106, -0.0422,  ..., -0.0294, -0.0352,  0.0127],\n",
       "        [-0.0007,  0.0127,  0.0083,  ...,  0.0049, -0.0027, -0.0275],\n",
       "        [-0.0112,  0.0026,  0.0081,  ..., -0.0006,  0.0043,  0.0033],\n",
       "        ...,\n",
       "        [-0.0264,  0.0157,  0.0041,  ..., -0.0588, -0.0361, -0.0080],\n",
       "        [-0.0522,  0.0139, -0.0004,  ..., -0.0061, -0.0491, -0.0109],\n",
       "        [-0.0413,  0.0264, -0.0249,  ...,  0.0015, -0.0315, -0.0033]],\n",
       "       device='cuda:0', dtype=torch.bfloat16, requires_grad=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.lm_head.weight.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4dc44886-c893-4e58-8120-4a8290b59aa5",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat in method wrapper_CUDA_addmv_)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlm_head\u001b[49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43msteering_vector\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat in method wrapper_CUDA_addmv_)"
     ]
    }
   ],
   "source": [
    "torch.matmul(model.lm_head.weight,steering_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1291e607-d766-4736-8be0-e5705ebdf368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('unable to open database file')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from typing import List, Tuple, Union, Optional, Dict, Any\n",
    "\n",
    "def unembed_vector(\n",
    "    vector: Union[torch.Tensor, np.ndarray],\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    use_transpose: bool = False,\n",
    "    top_k: int = 10,\n",
    "    token_list: Optional[List[str]] = None,\n",
    "    device: Optional[str] = None,\n",
    "    dtype: Optional[torch.dtype] = None\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Unembed a vector using either the unembedding matrix or the transpose of the embedding matrix.\n",
    "    \n",
    "    Args:\n",
    "        vector: The vector to unembed (1D tensor or numpy array)\n",
    "        model_name: The Gemma model name\n",
    "        use_transpose: If True, use the transpose of the embedding matrix; if False, use the unembedding matrix\n",
    "        top_k: Number of top tokens to return\n",
    "        token_list: List of specific tokens to compute logits for\n",
    "        device: Device to run computation on ('cuda', 'cpu'). If None, will use CUDA if available.\n",
    "        dtype: Data type to use for computation. If None, will match the model's dtype.\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing:\n",
    "            - top_tokens: List of (token, score) pairs for top tokens\n",
    "            - specific_logits: Dictionary mapping tokens to their logits (if token_list provided)\n",
    "    \"\"\"\n",
    "    # Determine device\n",
    "    if device is None:\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    \n",
    "    # Determine dtype to use (match the model's dtype if not specified)\n",
    "    if dtype is None:\n",
    "        # Get model's dtype from embedding weights\n",
    "        model_dtype = model.get_input_embeddings().weight.dtype\n",
    "        dtype = model_dtype\n",
    "    \n",
    "    # Ensure vector is a torch tensor with correct dtype and device\n",
    "    if isinstance(vector, np.ndarray):\n",
    "        vector = torch.tensor(vector, dtype=dtype, device=device)\n",
    "    else:\n",
    "        vector = vector.to(device=device, dtype=dtype)\n",
    "    \n",
    "    if vector.dim() > 1:\n",
    "        # Flatten if needed - assuming the input might be a 2D embedding\n",
    "        vector = vector.squeeze()\n",
    "    \n",
    "    # Get the appropriate matrix for unembedding\n",
    "    with torch.no_grad():\n",
    "        if use_transpose:\n",
    "            # Use the transpose of the embedding matrix\n",
    "            embedding_matrix = model.get_input_embeddings().weight\n",
    "            unembedding_matrix = embedding_matrix.transpose(0, 1)\n",
    "        else:\n",
    "            # Use the unembedding matrix (lm_head)\n",
    "            unembedding_matrix = model.lm_head.weight.transpose(0, 1)\n",
    "    \n",
    "    # Ensure the vector has the correct shape to match the unembedding matrix\n",
    "    if vector.shape[0] != unembedding_matrix.shape[0]:\n",
    "        raise ValueError(f\"Vector dimension ({vector.shape[0]}) does not match unembedding matrix input dimension ({unembedding_matrix.shape[0]})\")\n",
    "    \n",
    "    # Compute the unembedded logits (using matrix-vector multiplication)\n",
    "    with torch.no_grad():  # No need to track gradients for inference\n",
    "        logits = torch.matmul(vector, unembedding_matrix)\n",
    "    \n",
    "    # Get the top-k token IDs based on logits\n",
    "    top_values, top_indices = torch.topk(logits, k=top_k)\n",
    "    \n",
    "    # Convert to tokens and build result list\n",
    "    top_tokens = []\n",
    "    for idx, (token_id, score) in enumerate(zip(top_indices.tolist(), top_values.tolist())):\n",
    "        token = tokenizer.decode(token_id)\n",
    "        top_tokens.append((token, score))\n",
    "    \n",
    "    result = {\n",
    "        \"top_tokens\": top_tokens,\n",
    "    }\n",
    "    \n",
    "    # Calculate logits for specific tokens if provided\n",
    "    if token_list is not None:\n",
    "        specific_logits = {}\n",
    "        for token in token_list:\n",
    "            # Get token ID for the token\n",
    "            token_ids = tokenizer.encode(token, add_special_tokens=False)\n",
    "            if token_ids:  # Make sure we got a token ID\n",
    "                token_id = token_ids[0]\n",
    "                # Get the logit for this token\n",
    "                token_logit = logits[token_id].item()\n",
    "                specific_logits[token] = token_logit\n",
    "            else:\n",
    "                specific_logits[token] = float('nan')  # Token not found\n",
    "        \n",
    "        result[\"specific_logits\"] = specific_logits\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "def example_usage():\n",
    "    # Define device - will use CUDA if available\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # This would be your vector in the embedding space\n",
    "    # Here we're just creating a random vector with the correct dimensions for Gemma\n",
    "    vector = torch.randn(modle)  # Assuming Gemma 2 9b has a 4096-dimensional embedding space\n",
    "    \n",
    "    # Unembed using the unembedding matrix\n",
    "    result1 = unembed_vector(\n",
    "        vector=vector,\n",
    "        use_transpose=False,\n",
    "        top_k=5,\n",
    "        token_list=[\"quick\", \"thick\", \"trick\"],\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    print(\"Using unembedding matrix:\")\n",
    "    print(\"Top tokens:\")\n",
    "    for token, score in result1[\"top_tokens\"]:\n",
    "        print(f\"  {token}: {score:.4f}\")\n",
    "    print(\"Specific token logits:\")\n",
    "    for token, logit in result1[\"specific_logits\"].items():\n",
    "        print(f\"  {token}: {logit:.4f}\")\n",
    "    \n",
    "    # Unembed using the transpose of the embedding matrix\n",
    "    result2 = unembed_vector(\n",
    "        vector=vector,\n",
    "        use_transpose=True,\n",
    "        top_k=5,\n",
    "        token_list=[\"quick\", \"thick\", \"trick\"],\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    print(\"\\nUsing transpose of embedding matrix:\")\n",
    "    print(\"Top tokens:\")\n",
    "    for token, score in result2[\"top_tokens\"]:\n",
    "        print(f\"  {token}: {score:.4f}\")\n",
    "    print(\"Specific token logits:\")\n",
    "    for token, logit in result2[\"specific_logits\"].items():\n",
    "        print(f\"  {token}: {logit:.4f}\")\n",
    "\n",
    "# For use with specific dtype\n",
    "def example_with_bfloat16():\n",
    "    # Using BFloat16 explicitly\n",
    "    vector = torch.randn(modeldim)\n",
    "    \n",
    "    result = unembed_vector(\n",
    "        vector=vector,\n",
    "        top_k=5,\n",
    "        token_list=[\"quick\", \"thick\", \"trick\"],\n",
    "        dtype=torch.bfloat16  # Explicitly use BFloat16\n",
    "    )\n",
    "    \n",
    "    print(\"Results with BFloat16:\")\n",
    "    print(\"Top tokens:\")\n",
    "    for token, score in result[\"top_tokens\"]:\n",
    "        print(f\"  {token}: {score:.4f}\")\n",
    "\n",
    "# For memory management (helpful when working with large models)\n",
    "def clean_up_gpu_memory():\n",
    "    \"\"\"Free up GPU memory after using the model\"\"\"\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c324b551-e6f6-4569-b4d4-9585dd718b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'top_tokens': [(' BorderRadius', 8.125), ('YourGuide', 8.0625), ('BufferException', 7.96875), ('الإنجليزية', 7.875), ('DialogComponent', 7.6875)], 'specific_logits': {'quick': 1.609375, 'thick': 0.53125, 'trick': 0.54296875}}\n"
     ]
    }
   ],
   "source": [
    "vector = torch.randn(modeldim)\n",
    "result_random = unembed_vector(\n",
    "        vector=vector,\n",
    "        top_k=5,\n",
    "        token_list=[\"quick\", \"thick\", \"trick\"],\n",
    "        dtype=torch.bfloat16,  # Explicitly use BFloat16\n",
    "        use_transpose=True\n",
    "    )\n",
    "print(result_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3f7217e9-06ed-49d4-b450-ce637871ec26",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_Wu = unembed_vector(\n",
    "        vector=steering_vector,\n",
    "        top_k=5,\n",
    "        token_list=[\"quick\", \"thick\", \"trick\"],\n",
    "        dtype=torch.bfloat16,  # Explicitly use BFloat16\n",
    "        use_transpose=False\n",
    "    )\n",
    "\n",
    "result_We = unembed_vector(\n",
    "        vector=steering_vector,\n",
    "        top_k=5,\n",
    "        token_list=[\"quick\", \"thick\", \"trick\"],\n",
    "        dtype=torch.bfloat16,  # Explicitly use BFloat16\n",
    "        use_transpose=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b5965f38-0e5c-418a-9370-3b71999fee95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'top_tokens': [('shop', 7.03125), ('<bos>', 7.03125), (' виправивши', 6.59375), ('copg', 6.4375), ('Coc', 6.4375)], 'specific_logits': {'quick': 3.625, 'thick': 1.9375, 'trick': 3.265625}} {'top_tokens': [('shop', 7.03125), ('<bos>', 7.03125), (' виправивши', 6.59375), ('copg', 6.4375), ('Coc', 6.4375)], 'specific_logits': {'quick': 3.625, 'thick': 1.9375, 'trick': 3.265625}}\n"
     ]
    }
   ],
   "source": [
    "print(result_Wu,result_We)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "71a08f31-efa0-4143-b823-68fb05b5c6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'top_tokens': [(' senescence', 9.0625), ('volezza', 8.8125), ('amem', 8.75), (' ThemeData', 8.625), (' NgModule', 8.1875)], 'specific_logits': {'pain': 1.8515625, 'rain': 2.09375, 'refrain': 2.953125}} {'top_tokens': [(' senescence', 9.0625), ('volezza', 8.8125), ('amem', 8.75), (' ThemeData', 8.625), (' NgModule', 8.1875)], 'specific_logits': {'pain': 1.8515625, 'rain': 2.09375, 'refrain': 2.953125}}\n"
     ]
    }
   ],
   "source": [
    "result_Wu_2pain = unembed_vector(\n",
    "        vector=-steering_vector,\n",
    "        top_k=5,\n",
    "        token_list=[\"pain\", \"rain\", \"refrain\"],\n",
    "        dtype=torch.bfloat16,  # Explicitly use BFloat16\n",
    "        use_transpose=False\n",
    "    )\n",
    "\n",
    "result_We_2pain = unembed_vector(\n",
    "        vector=-steering_vector,\n",
    "        top_k=5,\n",
    "        token_list=[\"pain\", \"rain\", \"refrain\"],\n",
    "        dtype=torch.bfloat16,  # Explicitly use BFloat16\n",
    "        use_transpose=True\n",
    "    )\n",
    "\n",
    "print(result_Wu_2pain,result_We_2pain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4d5dd45-3e6b-47f4-abff-80913e1c237f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 18])\n",
      "\n",
      "--- Generating Steered Output (Multiplier: 1.5) ---\n",
      "Steering hook applied to model.layers.20 with multiplier 1.5\n",
      "Steering hook removed from model.layers.20\n",
      "\n",
      "--- Generating Steered Output (Multiplier: -1.5) ---\n",
      "Steering hook applied to model.layers.20 with multiplier -1.5\n",
      "Steering hook removed from model.layers.20\n",
      "A rhymed couplet:\n",
      "The house was built with sturdy, reddish brick\n",
      "And stood for years, a landmark, strong and thick.\n",
      "\n",
      "\n",
      "\n",
      "Here are some more rhyming couplets:\n",
      "\n",
      "* The moon shone bright, a silver\n",
      "A rhymed couplet:\n",
      "The house was built with sturdy, reddish brick\n",
      "And stood for years against a blizzard's kick.\n",
      "\n",
      "\n",
      "Let me know if you'd like me to write more!\n",
      "\n",
      "A rhymed couplet:\n",
      "The house was built with sturdy, reddish brick\n",
      "And stood upon a hill, crowned with the rain.\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "* **Rhymed couplet:**  The two lines rhyme at the\n",
      "['trick.', 'thick.', 'trick.', 'trick.', 'stick.', 'thick.', 'thick.', 'quick.', 'quick.', 'thick.', 'trick.', 'click.', 'trick.', 'quick.', 'trick.', 'thick.', 'trick.', 'quick.', 'trick.', 'trick.', 'trick.', 'pick.', 'quick.', 'quick.', 'thick.', 'slick.', 'quick.', 'trick.', 'slick.', 'sick.', 'thick.', 'click.', 'tick.', 'thick.', 'trick.', 'thick.', 'trick.', 'trick.', 'thick.', 'slick.', 'trick.', 'trick.', 'pick.', 'trick.', 'quick', 'trick.', 'pick.', 'tick.', 'thick.', 'trick.']\n",
      "['creek.', 'kick.', 'quick.', 'trick.', 'pick.', 'click.', 'quick.', 'pick.', 'time.', 'thick.', 'flip.', 'wick.', 'thick.', 'flick.', 'trick.', 'trick.', 'thick', 'fix.', 'kick.', 'kick.', 'quick.', 'slick.', 'trick.', 'thick.', 'trick.', 'kids.', 'trick.', 'hill.', 'flick.', 'tick.', 'trick.', 'trick.', 'quick.', 'magic.', 'trick.', 'trick.', 'light.', 'stick.', 'trick.', 'slick.', 'flick.', 'pick.', 'kick.', 'quick.', 'lick', 'quick.', 'slick.', 'hill.', 'pick.', 'quick.']\n",
      "['rain.', 'rain.', 'rain.', 'stain.', 'reign.', 'renowned.', 'reign.', 'rain.', 'reign.', 'rain.', 'remain.', 'stain.', 'rain.', 'rain.', 'rain.', 'rain.', 'stain.', 'stain.', 'pane.', 'rain.', 'rain.', 'rain.', 'rain.', 'gain.', 'rain.', 'rain.', 'plain.', 'strain.', 'rain.', 'rain.', 'rain.', 'unfeigned.', 'strain.', 'rain.', 'rain.', 'pain.', 'pain.', 'refrain.', 'reign.', 'rain.', 'rain.', 'rain.**', 'rain.', 'rain.', 'stain.', 'rain.', 'rain.', 'stain.', 'rain.', 'strain.']\n"
     ]
    }
   ],
   "source": [
    "# ## 6. Generate Text (Baseline vs. Steered)\n",
    "import einops\n",
    "STEERING_MULTIPLIER = 1.5\n",
    "\n",
    "def generate_steered_output(steering_vector, model, tokenizer, generation_prompt, batch_size,steering_multiplier, max_new_tokens, temperature, do_sample):\n",
    "    if steering_vector is None:\n",
    "        return None\n",
    "    inputs = tokenizer([generation_prompt] * batch_size, return_tensors=\"pt\", padding=True).to(model.device)\n",
    "    # inputs.input_ids = einops.repeat(inputs.input_ids, \"1 p-> b p\", b=batch_size)\n",
    "    # tokens = model.to_tokens(generation_prompt)\n",
    "    # tokens = einops.repeat(tokens, \"1 p-> b p\", b=batch_size)\n",
    "    # print(tokens.shape)\n",
    "    print(inputs.input_ids.shape)\n",
    "    with torch.no_grad():\n",
    "        outputs_baseline = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=temperature,\n",
    "            do_sample=do_sample,\n",
    "            pad_token_id=tokenizer.eos_token_id # Important for generation\n",
    "        )\n",
    "\n",
    "    # print(outputs_baseline.shape)\n",
    "    text_baseline = tokenizer.batch_decode(outputs_baseline, skip_special_tokens=True)\n",
    "    # text_baseline = [tokenizer.decode(outputs_baseline[i], skip_special_tokens=True) for i in range(batch_size)]\n",
    "\n",
    "    print(f\"\\n--- Generating Steered Output (Multiplier: {steering_multiplier}) ---\")\n",
    "    with torch.no_grad():\n",
    "         # Apply the steering hook using the context manager\n",
    "        with apply_steering(model, TARGET_LAYER_NAME, steering_vector, steering_multiplier):\n",
    "            outputs_steered = model.generate(\n",
    "                **inputs, # Use the same input tokens\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                temperature=temperature,\n",
    "                do_sample=do_sample,\n",
    "                pad_token_id=tokenizer.eos_token_id,\n",
    "            )\n",
    "    text_steered = tokenizer.batch_decode(outputs_steered, skip_special_tokens=True)\n",
    "\n",
    "    print(f\"\\n--- Generating Steered Output (Multiplier: {-steering_multiplier}) ---\")\n",
    "    with torch.no_grad():\n",
    "         # Apply the steering hook using the context manager\n",
    "        with apply_steering(model, TARGET_LAYER_NAME, steering_vector, -steering_multiplier):\n",
    "            outputs_steered = model.generate(\n",
    "                **inputs, # Use the same input tokens\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                temperature=temperature,\n",
    "                do_sample=do_sample,\n",
    "                pad_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "    text_negsteered = tokenizer.batch_decode(outputs_steered, skip_special_tokens=True)\n",
    "\n",
    "    # Clean up generation outputs\n",
    "    del outputs_baseline, outputs_steered, inputs\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    return text_baseline, text_steered, text_negsteered\n",
    "\n",
    "MAX_NEW_TOKENS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8000b64-009d-4838-90e0-03e26bc8bf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_word(text):\n",
    "    second_line = text.split(\"\\n\")[2]\n",
    "    second_line_words = second_line.split(\" \")\n",
    "    last_word = second_line_words[-1]\n",
    "    if last_word == \"\":\n",
    "        last_word = second_line_words[-2]\n",
    "    return last_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff07253f-067c-4606-81f2-13f34eb03967",
   "metadata": {},
   "outputs": [],
   "source": [
    "for GENERATION_PROMPT in [f'A rhymed couplet:\\n{line}\\n' for lines_that_rhyme_with_quick]:\n",
    "    text_baseline, text_steered, text_negsteered = generate_steered_output(steering_vector, model, tokenizer, GENERATION_PROMPT, 50, STEERING_MULTIPLIER, MAX_NEW_TOKENS, TEMPERATURE, DO_SAMPLE)\n",
    "#print(text_baseline[1])\n",
    "#print(text_steered[1])\n",
    "#print(text_negsteered[1])\n",
    "# %%\n",
    "\n",
    "last_words_baseline = [get_last_word(line) for line in text_baseline]\n",
    "last_words_steered = [get_last_word(line) for line in text_steered]\n",
    "last_words_negsteered = [get_last_word(line) for line in text_negsteered]\n",
    "print(last_words_baseline)\n",
    "print(last_words_steered)\n",
    "print(last_words_negsteered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b892c34-df40-4a6e-b98c-b3029a848665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick fraction baseline: 0.16, pain: 0.0\n",
      "Quick fraction steered: 0.14, pain: 0.0\n",
      "Quick fraction negsteered: 0.0, pain: 0.04\n"
     ]
    }
   ],
   "source": [
    "quick_fraction_baseline = len([word for word in last_words_baseline if 'quick' in word.lower()]) / len(last_words_baseline)\n",
    "quick_fraction_steered = len([word for word in last_words_steered if 'quick' in word.lower()]) / len(last_words_steered)\n",
    "quick_fraction_negsteered = len([word for word in last_words_negsteered if 'quick' in word.lower()]) / len(last_words_negsteered)\n",
    "pain_fraction_baseline = len([word for word in last_words_baseline if 'pain' in word.lower()]) / len(last_words_baseline)\n",
    "pain_fraction_steered = len([word for word in last_words_steered if 'pain' in word.lower()]) / len(last_words_steered)\n",
    "pain_fraction_negsteered = len([word for word in last_words_negsteered if 'pain' in word.lower()]) / len(last_words_negsteered)\n",
    "print(f\"Quick fraction baseline: {quick_fraction_baseline}, pain: {pain_fraction_baseline}\")\n",
    "print(f\"Quick fraction steered: {quick_fraction_steered}, pain: {pain_fraction_steered}\")\n",
    "print(f\"Quick fraction negsteered: {quick_fraction_negsteered}, pain: {pain_fraction_negsteered}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62afdc6e-26ad-4045-9c89-172574229712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(last_words_negsteered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e320f1ca-6529-469b-8ec2-1f03b457a49d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([word for word in last_words_baseline if 'thick' in word.lower()]) / len(last_words_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6d507ac-ace0-4c6b-b090-de98928d22d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([word for word in last_words_baseline if 'trick' in word.lower()]) / len(last_words_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0813310e-51f1-41ff-9bc5-e2079ed8147e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([word for word in last_words_negsteered if 'rain' in word.lower()]) / len(last_words_negsteered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6fc3d41b-8f53-4a94-bacb-5fd3fff998dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, a steadfast, silent trick. \\n\\nLet me know if you'd like to see more! I can write more couple\",\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, a landmark, strong and thick.\\n\\n\\n\\nHere are some more rhyming couplets:\\n\\n* The moon shone bright, a silver',\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for centuries, a time-worn trick. \\n\\n\\nLet me know if you'd like to see some more! \\n\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for ages, weathering every trick. \\n\\n\\nLet me know if you'd like more examples or have a specific theme in mind!\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood against the wind, a stalwart stick.\\n\\nLet me know if you'd like to see more! I can write couplets about different\",\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, a haven, strong and thick.\\n\\nThis is a good example of a rhymed couplet because:\\n\\n* **Two',\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, a monument so thick.\\n\\n\\nLet me know if you'd like me to write more!  I can try different themes\",\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood against the elements, thick and quick.\\n\\nWhat are the rhyming words in this couplet?\\n\\n* **brick and quick** \\n\\n\\n',\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nA testament to years gone by, so quick.\\n\\n\\n\\n',\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, a monument so thick. \\n\\n\\nLet me know if you'd like more examples or have a specific theme in mind!\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood against the storm, a steadfast trick. \\n\\n\\nLet me know if you'd like more! I can write about different topics or use\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nA testament to time, that wouldn't quickly click.\\n\\n\\n\\n\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for centuries, a stalwart trick. \\n\\nLet me know if you'd like to explore other rhyming possibilities!\\n\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for ages, strong against the quick.\\n\\nLet me know if you'd like another one! 😊\\n\",\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for centuries, a timeless trick.\\n\\n\\n\\n',\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood against the ages, strong and thick.\\n\\n\\nHere\\'s a breakdown of why this works:\\n\\n* **Rhyme:** The words \"',\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, a steadfast, noble trick.\\n\\n\\nLet me know if you'd like more! I can write more couplets on a\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood, a sentinel, against the quick.\\n\\nLet me know if you'd like more! I can write more couplets about this house\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood against the wind, a steadfast trick.\\n\\n\\nLet me know if you'd like to see more! 😊\\n\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nA testament to time, a craftsman's trick. \\n\\n\\nLet me know if you'd like to see more!  I enjoy writing poetry\",\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for ages, weathering every trick.\\n\\n\\n\\n',\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood on high, a welcome, lasting pick. \\n\\n\\nHere's a poem about a red brick house:\\n\\nThe Red Brick House\\n\\n\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, a beacon, strong and quick. \\n\\n\\nLet me know if you'd like to explore other rhyming couplets on a\",\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood, a sentinel, against the quick.\\n\\nExplanation:\\n\\n* **Rhymed Couplet:** This consists of two consecutive lines that rhyme.',\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, a landmark, strong and thick. \\n\\n\\n',\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, a beacon, strong and slick.\\n\\nIs this a good example of a rhymed couplet? \\n\\nIt meets the',\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood against the storms, both fierce and quick.\\n\\n\\nThe first line tells us about the house's material and color, while the second line\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, enduring every trick.\\n\\n\\nLet me know if you'd like to see more! \\n\\n\",\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nA place of warmth, a haven, quick and slick.\\n\\nThis is a rhyming couplet because it consists of two lines that rhyme at the end',\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, against the wind and sick.\\n\\n\\nLet me know if you'd like to see more! \\n\\n\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, a monument so thick.\\n\\n\\nLet me know if you'd like more!\\n\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd shone like jewels when sunlight did it click. \\n\\n\\nHere's a breakdown of the poem:\\n\\n* **Form:** It's a\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for decades, strong against the tick.\\n\\nLet me know if you'd like to see more!\\n\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, a beacon, strong and thick. \\n\\n\\nLet me know if you'd like more! I can write about a specific\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood there proud, a timeless, lasting trick.\\n\\n\\nI'm glad you liked the couplet! Do you have any other word prompts for\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood against the weather, strong and thick. \\n\\n\\nLet me know if you'd like to see more! 😊 \\n\",\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for ages, strong against the trick.\\n\\n\\nLet me know if you want to see more! I can write more rhymes about the house,',\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for centuries, a timeless trick.\\n\\nThis couplet uses several literary devices to add depth and meaning:\\n\\n* **Rhyme:** The',\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood as solid as a mountain's thick.\\n\\nLet me know if you'd like more!\\n\",\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, against the wind and slick.\\n\\n\\n\\n',\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, a stately, handsome trick.\\n\\nLet me know if you'd like me to write another one!\\n\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for ages, weathering every trick. \\n\\n\\nLet me know if you'd like more! 😊  \\n\\n\",\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for decades, a proud, enduring pick.\\n\\nA haiku:\\nRed bricks, strong and warm,\\nA house built to weather time',\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, against the elements' trick. \\n\\n\\nLet me know if you'd like more!\\n\",\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nIts windows gleamed, like jewels, shining quick\\n\\nA couplet is two lines of verse that rhyme, typically with the same meter.  \\n\\n',\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, a steadfast, silent trick. \\n\\n\\nLet me know if you'd like more couplets, or if you have a\",\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood against the wind, a watchful pick. \\n\\n\\nLet me know if you want more couplets! \\n',\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nA charming cottage, quick to make you tick. \\n\\n\\nLet me know if you'd like to see some more!\\n\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, a beacon, strong and thick. \\n\\n\\nLet me know if you'd like more!\\n\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nA symbol of strength, a steady, lasting trick. \\n\\n\\nLet me know if you'd like me to write another one! \\n\"]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3279d6a-ccd4-4e99-96c9-57740277befa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood beside a winding, wooded creek.\\n\\n\\nIs that good? \\n\\nI think it's good! It paints a clear image in the\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years against a blizzard's kick.\\n\\n\\nLet me know if you'd like me to write more!\\n\",\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood so proud, against the wind and quick. \\n\\n\\n\\nLet me know if you want me to write more!\\n',\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood so tall, a handsome, friendly trick. \\n\\n\\n',\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nWhere shadows dance and memories I pick. \\n\\n\\nLet me know if you'd like me to write more!\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood on land where wildflowers sweetly click. \\n\\n\\nLet me know if you'd like a longer poem or a poem on a different theme!\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd shone with pride, a beacon in the quick. \\n\\nLet me know if you'd like me to write more!\\n\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd dreamed of stories that it wouldn't pick.\\n\\nLet me know if you'd like more!\\n\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, resistant to the tick of time. \\n\\n\\n\\nLet me know if you'd like another one! \\n\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood proud, a beacon, through the winter's thick. \\n\\n\\nLet me know if you'd like me to write another one on\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood so strong, it wouldn't ever flip. \\n\\n\\n\\nLet me know if you'd like another one!\\n\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood so tall, a beacon on the wick.\\n\\nLet me know if you'd like to see more!\\n\",\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood so tall, it seemed to touch the thick. \\n\\n\\nLet me know what you think!  \\n\\n',\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood so strong, it wouldn't ever flick.\\n\\nLet me know if you'd like me to write more!\\n\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd every window gleamed with sunlit trick. \\n\\n\\nLet me know if you'd like more!  I can write more about the house\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood so strong, it weathered any trick.\\n\\n\\nLet me know if you'd like me to write another one!\\n\",\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood so tall, it seemed to touch the thick\\n\\nPlease provide the next line of the poem, continuing the theme of what the house might look',\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, with ninks and cracks, quick fix. \\n\\n\\nLet me know if you'd like more!\\n\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood unmoving, even after a quick, hard kick. \\n\\n\\n\\nIt's a simple example, but I hope it gets you started!\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, defying time’s swift kick.\\n\\n\\nLet me know if you'd like to explore more rhyming couplets! 😊 \",\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood so tall, it seemed to touch the quick.\\n\\n\\n\\n**Explanation:**\\n\\n* **Rhyme:** The words \"brick\" and \"quick',\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, defying wind and slick. \\n\\n\\nLet me know if you'd like more!\\n\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd held within, a lifetime's sweet, small trick. \\n\\n\\nLet me know if you'd like me to write another one or develop\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, a landmark, strong and thick.\\n\\n\\nLet me know what you think. I can try to write another one if you'\",\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood so strong, it weathered every trick. \\n\\n\\n\\n',\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd echoed with the laughter of the kids.\\n\\nThis is a good example of a rhymed couplet because:\\n\\n* **It has two lines',\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, despite the storms and trick.\\n\\nWould you like to add another couplet or extend the poem further?\\n',\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, a beacon on the hill. \\n\\n\\n\\n\\nLet me know if you'd like more! I can try different themes or styles\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, a landmark, quick as a flick. \\n\\n\\nLet me know if you'd like me to write more couplets or\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood there strong, defying time's quick tick. \\n\\nLet me know if you'd like me to write another one!  \\n\",\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nBut the paint was peeling, a sorry-looking trick. \\n\\n\\n',\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood upon a hill, a cozy trick.\\n\\nI tried to write a haiku about a  house built with bricks:\\nRed bricks stacked so',\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood there proud, a beacon in the quick.\\n\\n\\n\\nHere are a few more rhyming couplets:\\n\\n* The sun dipped low, a fiery',\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood so tall, it felt like magic. \\n\\n\\nI'm a fairly new writer. \\n\\nThis couplet reminds me of a place\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood so strong, it defied every trick. \\n\\nLet me know if you'd like to see more!\\n\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd sat upon a hill, a charming trick.\\n\\n\\nLet me know if you'd like another one!\\n\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd sunlight through the window made a lick of light. \\n\\n\\n\\nDo you think it's any good? Any suggestions? \\n\\n\\n\\n\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood against the wind, a sturdy stick. \\n\\n\\nLet me know if you'd like to see more!\\n\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood so proud, a charming, cozy trick. \\n\\n\\n\\nLet me know if you'd like me to write more!  \\n\",\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, a beacon strong and slick. \\n\\n\\nLet me know what you think!  I tried to use imagery to paint a picture',\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd held a warmth, a welcome, just a flick.\\n\\nI hope this inspires you to write more!\\n',\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd sat upon a hill, a welcome pick. \\n\\nLet me know if you'd like to see more!\\n\",\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd had a yard where kids could climb and kick.\\n\\nLet me know if you want me to write another one!\\n',\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood so tall, it almost touched the quick.\\n\\n\\nThis couplet describes a house built from red brick.  It's designed to be\",\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood so proud, it never seemed to lick\\n\\nPlease give me a couplet that uses a similar structure and rhyme scheme. \\n\\n**Your',\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood so tall, it seemed to touch the quick.\\n\\n\\n',\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood there proud, defying wind and slick.\\n\\n\\nLet me know if you want more! 😊\\n',\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood so tall, a landmark, on the hill. \\n\\n\\nLet me know if you'd like me to write another one!\\n\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, a silent, sturdy pick. \\n\\n\\nLet me know if you'd like more!\\n\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, a steadfast, warm and quick.\\n\\nLet me know if you'd like to see more!\\n\"]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_steered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bbf8e5be-054d-456f-a069-8b1834ba992a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, enduring sun and rain. \\n\\nLet me know if you'd like to see more! \\n\\n\",\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood upon a hill, crowned with the rain.\\n\\n**Explanation:**\\n\\n* **Rhymed couplet:**  The two lines rhyme at the',\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood there proud, untouched by sun or rain.\\n\\nThis couplet follows the rhyme scheme of AB, as the words \"brick\" and \"',\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for centuries, untouched by stain.\\n\\n**Explanation:**\\n\\n* **Rhymed Couple:** The lines rhyme with each other (\"brick\" and',\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood against the elements, a regal reign.\\n\\n\\nLet me know if you'd like more!  \\n\",\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nA testament to craftsmanship, renowned.\\n\\n\\n',\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nA testament to skill and timeless reign. \\n\\n\\n\\nDo you want to explore this further? Perhaps develop a story or poem around this house? Or perhaps',\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for centuries, defying rain.\\n\\nWould you like to continue this poem? What kind of house is it, and what are its secrets?',\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood against the elements, a steadfast reign. \\n\\n\\nLet me know if you'd like to see more couplets! I can explore different\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for centuries, untouched by rain.\\n\\n\\nLet me know if you'd like more! \\n\\n\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nWhere history whispers, and stories remain. \\n\\n\\nLet me know if you'd like more! \\n\\n\",\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd ivy crept, a verdant, living stain.\\n\\nPlease provide a rhyme scheme for these lines.\\n\\nThe rhyme scheme is **AA**. ',\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood in grandeur through the driving rain.\\n\\n\\nGive me another couplet, using the same rhyme scheme.\\n\\nHere's one:\\n\\nThe\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nA monument to strength, against the rain. \\n\\nLet me know if you'd like more! \\n\",\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood through years, unyielding to the rain.\\n\\n\\n\\n',\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nA place of comfort, free from wind and rain. \\n\\n\\nLet me know if you'd like some more! \\n\\n\",\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for centuries, untouched by stain.\\n\\nIs this a good example of a couplet?\\n\\nIt is a good example of a couplet',\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd ivy climbed its walls, a verdant stain.\\n\\n\\nLet me know if you'd like another.\\n\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd ivy crept along its weathered pane.\\n\\n\\nLet me know if you'd like more! I can create different types of poems, sonnets,\",\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood, serene, through sunshine and through rain. \\n\\n\\nThe couplet follows a strict structure:\\n\\n* **Rhyme:** The words \"',\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood majestic, weathering sun and rain. \\n\\nYou can find more examples of couplets in classic poetry, such as Shakespeare's plays and\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, resisting wind and rain. \\n\\nLet me know if you'd like me to write more!\\n\",\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nA beacon strong, against the wind and rain.\\n\\nPlease provide me with a rhyming couplet about a mountain range.\\n\\n**Your response:**\\n\\n',\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nA testament to artistry and gain.\\n\\nLet me know if you'd like more! \\n\\n\",\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood unyielding through the storms of rain.\\n\\n\\n\\n',\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nA steadfast home, through sun and wind and rain. \\n\\n\\nLet me know if you'd like to see more!\\n\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood proud, where sunshine kissed its plain.\\n\\n\\nLet me know if you'd like to see more! \\n\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for centuries, defying strain. \\n\\n\\nLet me know if you'd like more!  \\n\\n\",\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nA beacon, strong and proud, against the rain. \\n\\n\\nGive me a different rhyming couplet about a different subject. \\n\\n \\n',\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nA testament to strength, through sun and rain.\\n\\nHere's how to create a rhymed couplet:\\n\\n* **Choose a rhyme scheme\",\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for centuries, through sunshine and rain.\\n\\nHere are some ways to use this couplet in a story or poem:\\n\\n* **Setting',\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nBy hands that toiled with skill and strength unfeigned. \\n\\n\\nLet me know if you'd like to explore more couplets!  \",\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood through storms, a constant, noble strain. \\n\\n\\nPlease provide another couplet that would follow this, maintaining the style, rhyme scheme,',\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nIts history whispered, etched in every rain.\\n\\nA sonnet:\\n\\nThe house stood proud, a fortress 'gainst the storm,\\nBuilt with\",\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood against the storms, defying rain. \\n\\nHere\\'s a breakdown of the elements:\\n\\n* **Rhyme:** \"brick\" and',\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for centuries, untouched by pain.\\n\\n##  A few more couplets  \\n* I wandered through the forest, green and deep,',\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nWhere echoes whispered tales of love and pain. \\n\\n\\nLet me know if you'd like me to continue this.  What kind of story would\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nA masterpiece, untouched by time's refrain.\\n\\n\\nLet me know if you'd like more couplets! \\n\\n\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nA bastion 'gainst the wind, and winter's reign.\\n\\n\\nPlease let me know if you'd like more. I can write in\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, enduring wind and rain. \\n\\n\\nLet me know if you'd like more!  I enjoy coming up with them.\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nA fortress against wind, a haven from rain. \\n\\nLet me know if you'd like to explore more!  I can help you craft\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\n**And stood for centuries, defying rain.** \\n\\nLet me know if you'd like me to continue the poem!\\n\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for centuries, defying rain.\\n\\n\\n\\nLet me know if you'd like to see more couplets! \\n\\n\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood in silence, soaked in autumn rain.\\n\\n\\nLet me know if you'd like to see more! \\n\\n\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood in beauty, free from worldly stain.\\n\\nLet me know if you'd like more!\\n\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood proud, amidst the sun, and wind, and rain. \\n\\n\\nLet me know if you'd like another one! \\n\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood, a fortress, 'gainst the driving rain.\\n\\n\\nLet me know if you'd like more!  I can create couplets\",\n",
       " 'A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nIts beauty, time could never truly stain.\\n\\nThis is a rhymed couplet because it consists of two lines of verse with rhyming words at the',\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nAnd stood for years, defying wind and rain.\\n\\nThis is an example of a **rhymed couplet**. \\n\\nHere's why:\",\n",
       " \"A rhymed couplet:\\nThe house was built with sturdy, reddish brick\\nA fortress against life's relentless strain. \\n\\nWhat is the effect of using a rhymed couplet? It adds a sense of:\\n\"]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_negsteered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b480185-f952-4f93-8b21-91135eceeefb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
